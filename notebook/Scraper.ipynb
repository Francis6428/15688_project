{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import re, time\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_html(url):\n",
    "    \"\"\"\n",
    "    Return the raw HTML at the specified URL.\n",
    "\n",
    "    Args:\n",
    "        url (string): \n",
    "\n",
    "    Returns:\n",
    "        status_code (integer):\n",
    "        raw_html (string): the raw HTML content of the response, properly encoded according to the HTTP headers.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    return (response.status_code, response.text)\n",
    "    pass\n",
    "def get_people_list_data(url, key_words):\n",
    "    code, text = retrieve_html(url)\n",
    "    soup = BeautifulSoup(text,'html.parser')\n",
    "    next_page = set()\n",
    "    for link in soup.find('div',{'id':'bodyContent'}).find_all('a', href=True):\n",
    "        p = link.parent\n",
    "        pp = p.parent\n",
    "        if p != None:\n",
    "            print(p.text)\n",
    "            if ('faculty' in p.text or 'office' in p.text):\n",
    "                flag = False\n",
    "                break\n",
    "            p = p.parent\n",
    "        if (not flag):\n",
    "            continue\n",
    "        tar_url=link.attrs['href']\n",
    "        if tar_url.startswith('/wiki/') and tar_url.find(':') == -1:\n",
    "            next_page.add(tar_url)\n",
    "    print(next_page)\n",
    "    return next_page\n",
    "    data = dict()\n",
    "    for url in tqdm(next_page):\n",
    "        time.sleep(0.1)\n",
    "        code, html = retrieve_html(\"https://en.wikipedia.org\"+url)\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        if html.find('<th scope=\"row\">Born</th>') != -1 and any(key_word in html for key_word in key_words):\n",
    "            div = soup.find('div', {\"class\": \"mw-parser-output\"})\n",
    "            text = \"\"\n",
    "            for p in div.find_all(\"p\", recursive=False):\n",
    "                tmp = re.sub(\"(\\[[0-9]+\\])\", \"\", p.text)\n",
    "                tmp = re.sub(\"(\\(.*\\))\", \"\", tmp).rstrip().strip()\n",
    "                text += tmp\n",
    "            data[url[6:]] = text\n",
    "    return data\n",
    "def get_all_data(universities, append=False):\n",
    "    data = dict()\n",
    "    if (append):\n",
    "        with open('data.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "    for key, value in universities.items():\n",
    "        print(key)\n",
    "        data[key] = get_people_list_data(value[0], value[1])\n",
    "    with open('data.json', 'w') as fp:\n",
    "        json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:09<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCLA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [08:30<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2123/2123 [10:48<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harvard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2828/2828 [15:19<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berklee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:41<00:00,  3.65it/s]\n"
     ]
    }
   ],
   "source": [
    "universities = dict()\n",
    "universities['CMU'] = (\"https://en.wikipedia.org/wiki/List_of_Carnegie_Mellon_University_people\", \\\n",
    "                       ['Carnegie_Mellon_University', 'CMU'])\n",
    "universities['UCLA'] = (\"https://en.wikipedia.org/wiki/List_of_University_of_California,_Los_Angeles_people\", \\\n",
    "                       ['University_of_California,_Los_Angeles', 'University of California at Los Angeles', 'UCLA'])\n",
    "universities['Stanford'] = (\"https://en.wikipedia.org/wiki/List_of_Stanford_University_people\", \\\n",
    "                       ['Stanford_University'])\n",
    "universities['Harvard'] = (\"https://en.wikipedia.org/wiki/List_of_Harvard_University_people\", \\\n",
    "                           ['Harvard_University'])\n",
    "universities['Berklee'] = (\"https://en.wikipedia.org/wiki/List_of_Berklee_College_of_Music_alumni\", \\\n",
    "                           ['Berklee_College_of_Music', 'Berklee'])\n",
    "get_all_data(universities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scrap Academic Disciplines\n",
    "outline_url = \"https://en.wikipedia.org/wiki/Outline_of_academic_disciplines\"\n",
    "code, html = retrieve_html(outline_url)\n",
    "soup = BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arts': ['/wiki/The_arts'], 'History': ['/wiki/History'], 'Languages and literature': ['/wiki/Language', '/wiki/Literature'], 'Philosophy': ['/wiki/Philosophy'], 'Theology': ['/wiki/Theology'], 'Anthropology': ['/wiki/Anthropology'], 'Economics': ['/wiki/Economics'], 'Human geography': ['/wiki/Human_geography'], 'Law': ['/wiki/Law'], 'Political science': ['/wiki/Politics', '/wiki/Political_science'], 'Psychology': ['/wiki/Psychology', '/wiki/List_of_psychology_disciplines'], 'Sociology': ['/wiki/Sociology'], 'Biology': ['/wiki/List_of_life_sciences'], 'Chemistry': ['/wiki/Chemistry'], 'Earth sciences': ['/wiki/Earth_science'], 'Space sciences': [], 'Physics': ['/wiki/Physics'], 'Computer Science': ['/wiki/Computer_science'], 'Mathematics': ['/wiki/Mathematics'], 'Statistics': ['/wiki/Statistics'], 'Engineering and technology': ['/wiki/Engineering'], 'Medicine and health': ['/wiki/Medicine', '/wiki/Healthcare_science']}\n"
     ]
    }
   ],
   "source": [
    "body = soup.find('div',{'id':'bodyContent'})\n",
    "disciplines = dict()\n",
    "for h3 in body.find_all('h3'):\n",
    "    dis_name = h3.text[:-6]\n",
    "    note = h3.next_sibling.next_sibling\n",
    "    disciplines[dis_name] = []\n",
    "    if (dis_name == 'Human geography'):\n",
    "        disciplines[dis_name].append('/wiki/Human_geography')\n",
    "        continue\n",
    "    for link in note.find_all('a', href=True):\n",
    "        url = link.attrs['href']\n",
    "        if (url.find('Outline')==-1):\n",
    "            disciplines[dis_name].append(url)\n",
    "print(disciplines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:10<00:00,  2.10it/s]\n"
     ]
    }
   ],
   "source": [
    "data = dict()\n",
    "for discipline, p_urls in tqdm(disciplines.items()):\n",
    "    data[discipline] = []\n",
    "    for url in p_urls:\n",
    "        time.sleep(0.1)\n",
    "        code, html = retrieve_html(\"https://en.wikipedia.org\"+url)\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        div = soup.find('div', {\"class\": \"mw-parser-output\"})\n",
    "        text = \"\"\n",
    "        for p in div.find_all(\"p\", recursive=False):\n",
    "            tmp = re.sub(\"(\\[[.*]+\\])\", \"\", p.text)\n",
    "            tmp = re.sub(\"(\\(.*\\))\", \"\", tmp).rstrip().strip()\n",
    "            text += tmp\n",
    "        data[discipline].append(text)\n",
    "with open('disciplines.json', 'w') as fp:\n",
    "        json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "universities = dict()\n",
    "universities['Yale'] = (\"https://en.wikipedia.org/wiki/List_of_Yale_University_people\", \\\n",
    "                        ['Yale', 'Yale_University'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [10:24<00:00,  3.14it/s]\n"
     ]
    }
   ],
   "source": [
    "get_all_data(universities, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "universities = dict()\n",
    "universities['UM'] = (\"https://en.wikipedia.org/wiki/List_of_University_of_Michigan_alumni\", \\\n",
    "                      ['University_of_Michigan', 'UM'])\n",
    "universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
