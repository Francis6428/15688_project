{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re, time\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import string\n",
    "import sklearn\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    \"\"\"\n",
    "    This function takes a a string of text. Then tokenize it.\n",
    "    \n",
    "    Args:\n",
    "        text: a text string\n",
    "    Returns:\n",
    "        a list of tokens(words)\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    proc = ''\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        c = text[i]\n",
    "        #remove punctuation\n",
    "        if c not in string.punctuation:\n",
    "            proc+=c\n",
    "        elif c == \"'\":\n",
    "            if i == (len(text)-1):\n",
    "                break\n",
    "            if text[i+1] == 's' and (i+2) == len(text):\n",
    "                break\n",
    "            if text[i+1] == 's' and text[i+2] == ' ':\n",
    "                i+=1\n",
    "        else:\n",
    "            proc+=' '\n",
    "        i+=1  \n",
    "    tokens = nltk.word_tokenize(proc)\n",
    "    stopwords=nltk.corpus.stopwords.words('english')\n",
    "    result = []\n",
    "    for word in tokens:\n",
    "        if word not in stopwords:\n",
    "            result.append(str(lemmatizer.lemmatize(word)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU\n",
      "[('university', 1002), ('film', 790), ('carnegie', 738), ('also', 723), ('new', 672), ('award', 668), ('role', 623), ('year', 577), ('mellon', 564), ('work', 524), ('first', 520), ('science', 516), ('art', 500), ('series', 485), ('american', 481), ('school', 464), ('one', 462), ('york', 398), ('time', 385), ('received', 371), ('two', 364), ('research', 354), ('show', 348), ('television', 319), ('computer', 312), ('pittsburgh', 298), ('professor', 287), ('broadway', 283), ('drama', 281), ('state', 277), ('appeared', 273), ('production', 271), ('played', 268), ('episode', 266), ('born', 264), ('actor', 264), ('became', 261), ('co', 261), ('national', 259), ('later', 257), ('director', 257), ('well', 249), ('best', 246), ('made', 245), ('company', 244), ('including', 236), ('book', 234), ('technology', 233), ('institute', 229), ('city', 229), ('john', 228), ('college', 223), ('performance', 218), ('starred', 218), ('member', 217), ('warhol', 217), ('would', 214), ('season', 213), ('musical', 208), ('known', 207), ('three', 205), ('theatre', 204), ('engineering', 203), ('high', 202), ('president', 197), ('play', 190), ('child', 189), ('world', 188), ('life', 188), ('character', 187), ('theory', 186), ('served', 183), ('degree', 182), ('academy', 182), ('star', 181), ('’', 181), ('war', 179), ('business', 175), ('worked', 174), ('student', 173), ('system', 166), ('2011', 166), ('wrote', 165), ('married', 165), ('many', 165), ('u', 162), ('united', 161), ('california', 160), ('several', 159), ('program', 157), ('2012', 157), ('early', 157), ('began', 156), ('second', 155), ('public', 155), ('based', 155), ('part', 153), ('may', 153), ('project', 153), ('actress', 152)]\n",
      "UCLA\n",
      "[('year', 2179), ('also', 1972), ('first', 1968), ('film', 1935), ('time', 1558), ('ucla', 1474), ('school', 1472), ('california', 1442), ('team', 1421), ('university', 1406), ('los', 1374), ('angeles', 1364), ('season', 1346), ('one', 1321), ('state', 1305), ('american', 1267), ('new', 1253), ('game', 1249), ('two', 1193), ('would', 935), ('coach', 905), ('high', 903), ('award', 869), ('series', 860), ('role', 860), ('later', 840), ('point', 835), ('national', 829), ('work', 818), ('three', 795), ('u', 792), ('became', 767), ('world', 752), ('career', 729), ('member', 724), ('second', 704), ('played', 699), ('show', 688), ('player', 681), ('record', 662), ('said', 644), ('college', 643), ('made', 629), ('received', 627), ('basketball', 613), ('championship', 601), ('city', 601), ('united', 596), ('named', 567), ('including', 562), ('woman', 560), ('born', 550), ('television', 550), ('final', 547), ('star', 539), ('york', 519), ('appeared', 514), ('family', 512), ('art', 512), ('child', 512), ('book', 511), ('nba', 506), ('2012', 500), ('life', 499), ('president', 492), ('director', 490), ('well', 488), ('since', 486), ('best', 482), ('’', 477), ('four', 469), ('day', 468), ('co', 466), ('1', 465), ('served', 459), ('began', 458), ('john', 458), ('father', 455), ('2008', 445), ('10', 445), ('part', 441), ('science', 439), ('win', 436), ('head', 433), ('program', 428), ('former', 417), ('known', 416), ('2010', 414), ('worked', 413), ('2011', 409), ('2014', 409), ('many', 407), ('several', 405), ('episode', 404), ('2009', 402), ('play', 397), ('music', 394), ('2013', 392), ('2', 388), ('title', 384)]\n",
      "Stanford\n",
      "[('university', 3330), ('state', 2525), ('stanford', 2256), ('also', 2122), ('year', 2057), ('first', 1877), ('school', 1847), ('american', 1630), ('time', 1604), ('new', 1595), ('california', 1560), ('president', 1548), ('one', 1519), ('u', 1437), ('united', 1298), ('science', 1204), ('would', 1146), ('national', 1142), ('two', 1125), ('work', 1120), ('member', 1067), ('became', 1046), ('world', 1040), ('served', 1012), ('received', 987), ('law', 987), ('research', 981), ('award', 920), ('professor', 918), ('company', 856), ('later', 856), ('team', 828), ('high', 826), ('court', 816), ('board', 775), ('including', 728), ('election', 720), ('born', 715), ('said', 708), ('college', 691), ('degree', 688), ('film', 666), ('director', 656), ('book', 646), ('made', 642), ('public', 642), ('program', 638), ('three', 628), ('computer', 625), ('’', 624), ('student', 621), ('second', 615), ('senate', 611), ('co', 610), ('2008', 610), ('2012', 606), ('worked', 593), ('republican', 589), ('government', 583), ('million', 583), ('system', 578), ('many', 577), ('business', 575), ('committee', 574), ('family', 573), ('engineering', 570), ('study', 569), ('child', 568), ('1', 567), ('well', 565), ('institute', 564), ('former', 558), ('war', 557), ('group', 550), ('technology', 549), ('international', 545), ('career', 544), ('day', 541), ('san', 541), ('2013', 537), ('may', 534), ('york', 534), ('named', 531), ('policy', 527), ('2009', 522), ('people', 521), ('2010', 518), ('city', 516), ('role', 514), ('game', 505), ('january', 504), ('house', 502), ('woman', 501), ('political', 500), ('district', 499), ('john', 498), ('term', 497), ('2006', 497), ('education', 494), ('record', 494)]\n",
      "Harvard\n",
      "[('state', 7042), ('new', 5118), ('president', 4566), ('also', 4503), ('year', 4464), ('university', 4241), ('first', 4002), ('american', 3834), ('united', 3709), ('school', 3618), ('u', 3597), ('one', 3557), ('time', 3451), ('would', 3400), ('harvard', 3304), ('law', 3270), ('served', 2907), ('member', 2751), ('election', 2613), ('two', 2463), ('national', 2380), ('republican', 2379), ('government', 2365), ('war', 2321), ('became', 2315), ('later', 2298), ('house', 2219), ('public', 2206), ('court', 2197), ('massachusetts', 2195), ('york', 2193), ('work', 2093), ('general', 2052), ('party', 2030), ('kennedy', 1996), ('said', 1992), ('john', 1861), ('world', 1861), ('senate', 1838), ('political', 1817), ('city', 1768), ('governor', 1757), ('congress', 1666), ('office', 1609), ('received', 1608), ('campaign', 1595), ('college', 1581), ('elected', 1580), ('committee', 1566), ('democratic', 1552), ('many', 1532), ('family', 1532), ('term', 1523), ('born', 1499), ('including', 1497), ('book', 1488), ('made', 1482), ('right', 1462), ('vote', 1444), ('bush', 1377), ('former', 1373), ('policy', 1358), ('support', 1351), ('three', 1349), ('secretary', 1349), ('may', 1318), ('act', 1317), ('child', 1309), ('people', 1309), ('administration', 1308), ('wrote', 1284), ('life', 1276), ('well', 1273), ('board', 1272), ('program', 1257), ('justice', 1254), ('father', 1249), ('day', 1249), ('service', 1243), ('federal', 1238), ('senator', 1234), ('washington', 1216), ('boston', 1214), ('several', 1206), ('international', 1195), ('obama', 1193), ('representative', 1192), ('company', 1189), ('science', 1187), ('january', 1176), ('presidential', 1173), ('march', 1166), ('million', 1164), ('position', 1162), ('award', 1153), ('since', 1149), ('department', 1148), ('high', 1145), ('called', 1141), ('district', 1135)]\n",
      "Berklee\n",
      "[('album', 1101), ('music', 769), ('song', 512), ('released', 478), ('band', 462), ('also', 410), ('jazz', 374), ('guitar', 337), ('new', 334), ('first', 333), ('year', 322), ('award', 318), ('record', 272), ('one', 258), ('two', 223), ('berklee', 216), ('time', 213), ('tour', 205), ('film', 194), ('recorded', 193), ('show', 192), ('college', 190), ('best', 190), ('single', 187), ('rock', 182), ('vai', 172), ('live', 172), ('performed', 166), ('grammy', 165), ('played', 158), ('recording', 156), ('guitarist', 149), ('school', 149), ('musician', 149), ('artist', 149), ('mayer', 148), ('began', 146), ('american', 145), ('including', 145), ('john', 145), ('jones', 145), ('playing', 142), ('chart', 141), ('york', 138), ('drummer', 136), ('singer', 136), ('release', 136), ('play', 135), ('work', 132), ('solo', 130), ('billboard', 128), ('bass', 127), ('track', 127), ('studio', 126), ('featured', 124), ('vocal', 121), ('well', 120), ('received', 120), ('2012', 120), ('boston', 118), ('three', 117), ('performance', 116), ('group', 115), ('second', 115), ('concert', 114), ('video', 113), ('love', 110), ('number', 110), ('2011', 109), ('musical', 108), ('made', 105), ('became', 103), ('world', 103), ('career', 103), ('member', 102), ('score', 101), ('2010', 101), ('etheridge', 101), ('age', 100), ('born', 100), ('later', 100), ('produced', 100), ('2014', 100), ('debut', 99), ('sound', 99), ('drum', 97), ('2007', 97), ('said', 96), ('u', 95), ('high', 93), ('2009', 93), ('life', 93), ('2006', 92), ('series', 90), ('would', 90), ('welch', 90), ('appeared', 90), ('city', 88), ('like', 88), ('since', 86)]\n"
     ]
    }
   ],
   "source": [
    "word_count = dict()\n",
    "for key, value in data.items():\n",
    "    all_words = []\n",
    "    for name, text in value.items():\n",
    "        all_words.extend(tokenization(text))\n",
    "    word_count[key] = Counter(all_words)\n",
    "    print(key)\n",
    "    print(word_count[key].most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Den%C3%A9e_Benton', 'Denée Benton  is an American actress and singer.Benton is best known for her Tony-nominated performance as Natasha Rostova in the 2016 musical Natasha, Pierre, & The Great Comet of 1812 on Broadway. On television she is best known for her featured role on the Lifetime series, UnREAL.Benton attended Trinity Preparatory School in Winter Park, Florida, before graduating from Carnegie Mellon University in 2014.Her first big break was being cast as Nabulungi in the West End and U.S. national tour of The Book of Mormon. Later she was cast in the titular role of Natasha in Natasha, Pierre & The Great Comet of 1812 with the American Repertory Theatre; she made her Broadway debut when that show opened at the Imperial Theatre on November 14, 2016. She appeared on The Late Show with Stephen Colbert on December 12, 2016 to discuss the role.She is best known to television audiences for her memorable role as Ruby Carter in the second season of the Lifetime series, UnREAL.'), ('Kathleen_Carley', \"Kathleen M. Carley is an American social scientist specializing in dynamic network analysis. She is a professor in the School of Computer Science in the Institute for Software Research International at Carnegie Mellon University and also holds appointments in the Tepper School of Business, the Heinz College, the Department of Engineering and Public Policy, and the Department of Social and Decision Sciences.Kathleen Carley was born in Pueblo, Colorado in 1956. At High School her interest in social modeling was inspired by Isaac Asimov's Foundation series. Artificial intelligence was not a career path at that time and she was dissuaded from studying Mathematics because of gender stereotyping. Instead she studied for an S.B. in Economics and an S.B. in Political Science from the Massachusetts Institute of Technology in 1978. She received her Ph.D. in Sociology from Harvard University in 1984. Her Ph.D. advisor was Harrison White and her thesis was entitled Consensus Construction.On leaving Harvard in 1984, Carley secured a position as Associate Professor of Sociology and Information Systems at Carnegie Mellon University where she remains based. In 1990 she became Associate Professor of Sociology and Organizations, in 1998 Professor of Sociology, Organizations and IT, and in 2002 attained her current role as Professor of Computation, Organization and Society. Since 1998 she has also held appointments in other CMU schools and departments; the Department of Social and Decision Sciences, Heinz College, Tepper School of Business and Department of Engineering and Public Policy.Carley's research combines cognitive science, sociology and computer science to address complex social and organizational problems. Her most notable research contribution was the establishment of Dynamic network analysis . In addition, she has also contributed to research on computational social and organization theory, adaptation and evolution, text mining, and the impact of telecommunication technologies and policy on communication, information diffusion, disease contagion and response within and among groups particularly in disaster or crisis situations, and dynamic network methods.She is the director of the Center for Computational Analysis of Social and Organizational Systems .Carley is the founding co-editor, and co-editor-in-chief of the journal Computational and Mathematical Organization Theory. She has co-edited several books in the computational organizations and dynamic network area.Carley, Kathleen M.; Prietula, MJ . Lawrence Erlbaum. ISBN\\xa00-8058-1406-X. Retrieved 2011-04-08.Carley, Kathleen M.\")]\n"
     ]
    }
   ],
   "source": [
    "print(list(data['CMU'].items())[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
