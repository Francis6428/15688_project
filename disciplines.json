{"Arts": ["The arts refers to the theory and physical expression of creativity found in human societies and cultures. Major constituents of the arts include literature \u2013 including poetry, prose and drama, performing arts \u2013 among them music, dance, and theatre; and visual arts \u2013 including drawing, painting, photography, ceramics, sculpting, and architecture \u2013 the art of designing and constructing buildings.Some art forms combine a visual element with performance . From prehistoric cave paintings to modern day films, art serves as a vessel for storytelling and conveying humankind's relationship with the environment.In its most basic abstract definition, art is a documented expression of a sentient being through or on an accessible medium so that anyone can view, hear or experience it. The act itself of producing an expression can also be referred to as a certain art, or as art in general. If this solidified expression, or the act of producing it, is \"good\" or has value depends on those who access and rate it and this public rating is dependent on various subjective factors. Merriam-Webster defines \"the arts\" as \"painting, sculpture, music, theater, literature, etc., considered as a group of activities done by people with skill and imagination.\"[1] Similarly, the United States Congress, in the National Foundation on the Arts and Humanities Act, defined \"the arts\" as follows:[2]In Ancient Greece, all art and craft was referred to by the same word, techne. Thus, there was no distinction between the arts. Ancient Greek art brought the veneration of the animal form and the development of equivalent skills to show musculature, poise, beauty, and anatomically correct proportions. Ancient Roman art depicted gods as idealized humans, shown with characteristic distinguishing features . This is evident in, for example, the art of India, Tibet and Japan. Religious Islamic art forbids iconography, and expresses religious ideas through geometry instead.In the Middle Ages, the Artes Liberales [5] were practised and developed in guild environments. The modern distinction between \"artistic\" and \"non-artistic\" skills did not develop until the Renaissance. In modern academia, the arts are usually grouped with or as a subset of the humanities. Some subjects in the humanities are history, linguistics, literature, theology, philosophy, and logic.The arts have also been classified as seven: Literature, painting, sculpture, and music comprise the main four arts, of which the other three are derivative; drama is literature with acting, dance is music expressed through motion, and song is music with literature and voice.[6]Drawing is a means of making an image, using any of a wide variety of tools and techniques. It generally involves making marks on a surface by applying pressure from a tool, or moving a tool across a surface. Common tools are graphite pencils, pen and ink, inked brushes, wax colour pencils, crayons, charcoals, pastels, and markers. Digital tools which can simulate the effects of these are also used. The main techniques used in drawing are line drawing, hatching, crosshatching, random hatching, scribbling, stippling, and blending. An artist who excels in drawing is referred to as a drafter, draftswoman, or draughtsman.[7] Drawing can be used to create art used in cultural industries such as illustrations, comics and animation.Colour is the essence of painting as sound is of music.[citation needed] Colour is highly subjective, but has observable psychological effects[citation needed], although these can differ from one culture to the next. Black is associated with mourning in the West, but elsewhere white may be. Some painters, theoreticians, writers and scientists, including Goethe,[8] Kandinsky,[9] and Newton,[10] have written their own colour theory. Moreover, the use of language is only an abstraction for a colour equivalent. The word \"red,\" for example, can cover a wide range of variations on the pure red of the spectrum. There is not a formalized register of different colours in the way that there is agreement on different notes in music, such as C or C#, although the Pantone system is widely used in the printing and design industry for this purpose.Modern painters have extended the practice considerably to include, for example, collage. Collage is not painting in the strict sense since it includes other materials. Some modern painters incorporate different materials such as sand, cement, straw, wood or strands of hair for their artwork texture. Examples of this are the works of Elito Circa, Jean Dubuffet or Anselm Kiefer. Broadly speaking, Modern and contemporary painting seems to move away from the historic value of craft in favour of concept;[citation needed] which becomes more apparent from early-twentieth century onwards. This transition has led some to say that painting, as a serious art form, is dead,[citation needed] although this has not deterred the majority of artists from continuing to practise it either as whole or part of their work.[citation needed] Indigenouism is also considered as Modern and contemporary Art in early 20th Century.Ceramic art is art made from ceramic materials , which may take forms such as pottery, tile, figurines, sculpture, and tableware. While some ceramic products are considered fine art, some are considered to be decorative, industrial, or applied art objects. Ceramics may also be considered artefacts in archaeology.Ceramic art can be made by one person or by a group of people. In a pottery or ceramic factory, a group of people design, manufacture, and decorate the pottery. Products from a pottery are sometimes referred to as \"art pottery.\" In a one-person pottery studio, ceramists or potters produce studio pottery. In modern ceramic engineering usage, \"ceramics\" is the art and science of making objects from inorganic, non-metallic materials by the action of heat. It excludes glass and mosaic made from glass tesserae.Photography as an art form refers to photographs that are created in accordance with the creative vision of the photographer. Art photography stands in contrast to photojournalism, which provides a visual account for news events, and commercial photography, the primary focus of which is to advertise products or services.Architecture is the art and science of designing buildings and structures. The word architecture comes from the Greek arkhitekton, \"master builder, director of works,\" from \u03b1\u03c1\u03c7\u03b9-  \"builder, carpenter\".[11] A wider definition would include the design of the built environment, from the macrolevel of town planning, urban design, and landscape architecture to the microlevel of creating furniture. Architectural design usually must address both feasibility and cost for the builder, as well as function and aesthetics for the user.In modern usage, architecture is the art and discipline of creating, or inferring an implied or apparent plan of, a complex object or system. The term can be used to connote the implied architecture of abstract things such as music or mathematics, the apparent architecture of natural things, such as geological formations or the structure of biological cells, or explicitly planned architectures of human-made things such as software, computers, enterprises, and databases, in addition to buildings. In every usage, an architecture may be seen as a subjective mapping from a human perspective  to the elements or components of some kind of structure or system, which preserves the relationships among the elements or components. Planned architecture manipulates space, volume, texture, light, shadow, or abstract elements in order to achieve pleasing aesthetics. This distinguishes it from applied science or engineering, which usually concentrate more on the functional and feasibility aspects of the design of constructions or structures.In the field of building architecture, the skills demanded of an architect range from the more complex, such as for a hospital or a stadium, to the apparently simpler, such as planning residential houses. Many architectural works may be seen also as cultural and political symbols, or works of art. The role of the architect, though changing, has been central to the successful  design and implementation of pleasingly built environments in which people live.Sculpture is the branch of the visual arts that operates in three dimensions. It is one of the plastic arts. Durable sculptural processes originally used carving , in stone, metal, ceramics, wood and other materials; but since modernism, shifts in sculptural process led to an almost complete freedom of materials and process. A wide variety of materials may be worked by removal such as carving, assembled by welding or modelling, or moulded, or cast.Conceptual art is art in which the concept involved in the work takes precedence over traditional aesthetic and material concerns. The inception of the term in the 1960s referred to a strict and focused practice of idea-based art that often defied traditional visual criteria associated with the visual arts in its presentation as text.[12] Through its association with the Young British Artists and the Turner Prize during the 1990s,[citation needed] its popular usage, particularly in the UK, developed as a synonym for all contemporary art that does not practise the traditional skills of painting and sculpture.Literature is literally \"acquaintance with letters\" as in the first sense given in the Oxford English Dictionary. The noun \"literature\" comes from the Latin word littera meaning \"an individual written character  in Francophone scholarship.[13]Performing arts comprise dance, music, theatre, opera, mime, and other art forms in which a human performance is the principal product. Performing arts are distinguished by this performance element in contrast with disciplines such as visual and literary arts where the product is an object that does not require a performance to be observed and experienced. Each discipline in the performing arts is temporal in nature, meaning the product is performed over a period of time. Products are broadly categorized as being either repeatable  or improvised for each performance.[14] Artists who participate in these arts in front of an audience are called performers, including actors, magicians, comedians, dancers, musicians, and singers. Performing arts are also supported by the services of other artists or essential workers, such as songwriting and stagecraft. Performers often adapt their appearance with tools such as costume and stage makeup.Music is an art form whose medium is sound and silence, occurring in time. Common elements of music are pitch  through improvisational music to aleatoric pieces. Music can be divided into genres and subgenres, although the dividing lines and relationships between music genres are often subtle, sometimes open to individual interpretation, and occasionally controversial. Within \"the arts,\" music may be classified as a performing art, a fine art, and auditory art.Theatre or theater [15] is the branch of the performing arts concerned with acting out stories in front of an audience using combinations of speech, gesture, music, dance, sound and spectacle \u2013 indeed, any one or more elements of the other performing arts. In addition to the standard narrative dialogue style, theatre takes such forms as opera, ballet, mime, kabuki, classical Indian dance, Chinese opera and mummers' plays.Dance  to codified, virtuoso techniques such as ballet. In sports, gymnastics, figure skating and synchronized swimming are dance disciplines while Martial arts \"kata\" are often compared to dances.Areas exist in which artistic works incorporate multiple artistic fields, such as film, opera and performance art. While opera is often categorized in the performing arts of music, the word itself is Italian for \"works,\" because opera combines several artistic disciplines in a singular artistic experience. In a typical traditional opera, the entire work utilizes the following: the sets .The composer Richard Wagner recognized the fusion of so many disciplines into a single work of opera, exemplified by his cycle Der Ring des Nibelungen , sometimes referred to as \"Music Drama\" in English, emphasizing the literary and theatrical components which were as important as the music. Classical ballet is another form which emerged in the 17th century in which orchestral music is combined with dance.Other works in the late 19th, 20th and 21st centuries have fused other disciplines in unique and creative ways, such as performance art. Performance art is a performance over time which combines any number of instruments, objects, and art within a predefined or less well-defined structure, some of which can be improvised. Performance art may be scripted, unscripted, random or carefully organized; even audience participation may occur. John Cage is regarded by many as a performance artist rather than a composer, although he preferred the latter term. He did not compose for traditional ensembles. Cage's composition Living Room Music composed in 1940 is a \"quartet\" for unspecified instruments, really non-melodic objects, which can be found in a living room of a typical house, hence the title.There is no clear line between art and culture. Cultural fields like gastronomy are sometimes considered as arts.[17]The applied arts are the application of design and decoration to everyday, functional, objects to make them aesthetically pleasing.[18] The applied arts includes fields such as industrial design, illustration, and commercial art.[19] The term \"applied art\" is used in distinction to the fine arts, where the latter is defined as arts that aims to produce objects which are beautiful or provide intellectual stimulation but have no primary everyday function. In practice, the two often overlap.A debate exists in the fine arts and video game cultures over whether video games can be counted as an art form.[20] Game designer Hideo Kojima professes that video games are a type of service, not an art form, because they are meant to entertain and attempt to entertain as many people as possible, rather than being a single artistic voice , game designers could be considered museum curators \u2013 not creating artistic pieces, but arranging them in a way that displays their artistry and sells tickets.Within social sciences, cultural economists show how video games playing is conducive to the involvement in more traditional art forms and cultural practices, which suggests the complementarity between video games and the arts.[21]In May 2011, the National Endowment of the Arts included video games in its redefinition of what is considered a \"work of art\" when applying of a grant.[22] In 2012, the Smithsonian American Art Museum presented an exhibit, The Art of the Video Game.[20] Reviews of the exhibit were mixed, including questioning whether video games belong in an art museum."], "History": ["History [2] is the study of the past as it is described in written documents.[3][4] Events occurring before written record are considered prehistory. It is an umbrella term that relates to past events as well as the memory, discovery, collection, organization, presentation, and interpretation of information about these events. Scholars who write about history are called historians.History can also refer to the academic discipline which uses a narrative to examine and analyse a sequence of past events, and objectively determine the patterns of cause and effect that determine them.[5][6] Historians sometimes debate the nature of history and its usefulness by discussing the study of the discipline as an end in itself and as a way of providing \"perspective\" on the problems of the present.[5][7][8][9]Stories common to a particular culture, but not supported by external sources , are usually classified as cultural heritage or legends, because they do not show the \"disinterested investigation\" required of the discipline of history.[10][11] Herodotus, a 5th-century BC Greek historian is considered within the Western tradition to be the \"father of history\", and, along with his contemporary Thucydides, helped form the foundations for the modern study of human history. Their works continue to be read today, and the gap between the culture-focused Herodotus and the military-focused Thucydides remains a point of contention or approach in modern historical writing. In Asia, a state chronicle, the Spring and Autumn Annals was known to be compiled from as early as 722 BC although only 2nd-century BC texts survived.Ancient influences have helped spawn variant interpretations of the nature of history which have evolved over the centuries and continue to change today. The modern study of history is wide-ranging, and includes the study of specific regions and the study of certain topical or thematical elements of historical investigation. Often history is taught as part of primary and secondary education, and the academic study of history is a major discipline in university studies.The word history comes ultimately from Ancient Greek \u1f31\u03c3\u03c4\u03bf\u03c1\u03af\u03b1[12] .The Greek word was borrowed into Classical Latin as historia, meaning \"investigation, inquiry, research, account, description, written account of past events, writing of history, historical narrative, recorded knowledge of past events, story, narrative\". History was borrowed from Latin , but this word fell out of use in the late Old English period.[14]Meanwhile, as Latin became Old French \".[14]It was from Anglo-Norman that history was borrowed into Middle English, and this time the loan stuck. It appears in the thirteenth-century Ancrene Wisse, but seems to have become a common word in the late fourteenth century, with an early attestation appearing in John Gower's Confessio Amantis of the 1390s : \"I finde in a bok compiled | To this matiere an old histoire, | The which comth nou to mi memoire\". In Middle English, the meaning of history was \"story\" in general. The restriction to the meaning \"the branch of knowledge that deals with past events; the formal record or study of past events, esp. human affairs\" arose in the mid-fifteenth century.[14]With the Renaissance, older senses of the word were revived, and it was in the Greek sense that Francis Bacon used the term in the late sixteenth century, when he wrote about \"Natural History\". For him, historia was \"the knowledge of objects determined by space and time\", that sort of knowledge provided by memory .[15]In an expression of the linguistic synthetic vs. analytic/isolating dichotomy, English like Chinese  now designates separate words for human history and storytelling in general. In modern German, French, and most Germanic and Romance languages, which are solidly synthetic and highly inflected, the same word is still used to mean both \"history\" and \"story\".The adjective historical is attested from 1661, and historic from 1669.[16]Historian in the sense of a \"researcher of history\" is attested from 1531. In all European languages, the substantive \"history\" is still used to mean both \"what happened with men\", and \"the scholarly study of the happened\", the latter sense sometimes distinguished with a capital letter, \"History\", or the word historiography.[13]Historians write in the context of their own time, and with due regard to the current dominant ideas of how to interpret the past, and sometimes write to provide lessons for their own society. In the words of Benedetto Croce, \"All history is contemporary history\". History is facilitated by the formation of a \"true discourse of past\" through the production of narrative and analysis of past events relating to the human race.[17] The modern discipline of history is dedicated to the institutional production of this discourse.All events that are remembered and preserved in some authentic form constitute the historical record.[18] The task of historical discourse is to identify the sources which can most usefully contribute to the production of accurate accounts of past. Therefore, the constitution of the historian's archive is a result of circumscribing a more general archive by invalidating the usage of certain texts and documents .The study of history has sometimes been classified as part of the humanities and at other times as part of the social sciences.[19] It can also be seen as a bridge between those two broad areas, incorporating methodologies from both. Some individual historians strongly support one or the other classification.[20] In the 20th century, French historian Fernand Braudel revolutionized the study of history, by using such outside disciplines as economics, anthropology, and geography in the study of global history.Traditionally, historians have recorded events of the past, either in writing or by passing on an oral tradition, and have attempted to answer historical questions through the study of written documents and oral accounts. From the beginning, historians have also used such sources as monuments, inscriptions, and pictures. In general, the sources of historical knowledge can be separated into three categories: what is written, what is said, and what is physically preserved, and historians often consult all three.[21] But writing is the marker that separates history from what comes before.Archaeology is a discipline that is especially helpful in dealing with buried sites and objects, which, once unearthed, contribute to the study of history. But archaeology rarely stands alone. It uses narrative sources to complement its discoveries. However, archaeology is constituted by a range of methodologies and approaches which are independent from history; that is to say, archaeology does not \"fill the gaps\" within textual sources. Indeed, \"historical archaeology\" is a specific branch of archaeology, often contrasting its conclusions against those of contemporary textual sources. For example, Mark Leone, the excavator and interpreter of historical Annapolis, Maryland, USA; has sought to understand the contradiction between textual documents and the material record, demonstrating the possession of slaves and the inequalities of wealth apparent via the study of the total historical environment, despite the ideology of \"liberty\" inherent in written documents at this time.There are varieties of ways in which history can be organized, including chronologically, culturally, territorially, and thematically. These divisions are not mutually exclusive, and significant overlaps are often present, as in \"The International Women's Movement in an Age of Transition, 1830\u20131975.\" It is possible for historians to concern themselves with both the very specific and the very general, although the modern trend has been toward specialization. The area called Big History resists this specialization, and searches for universal patterns or trends. History has often been studied with some practical or theoretical aim, but also may be studied out of simple intellectual curiosity.[22]The history of the world is the memory of the past experience of Homo sapiens sapiens around the world, as that experience has been preserved, largely in written records. By \"prehistory\", historians mean the recovery of knowledge of the past in an area where no written records exist, or where the writing of a culture is not understood. By studying painting, drawings, carvings, and other artifacts, some information can be recovered even in the absence of a written record. Since the 20th century, the study of prehistory is considered essential to avoid history's implicit exclusion of certain civilizations, such as those of Sub-Saharan Africa and pre-Columbian America. Historians in the West have been criticized for focusing disproportionately on the Western world.[23] In 1961, British historian E. H. Carr wrote:This definition includes within the scope of history the strong interests of peoples, such as Indigenous Australians and New Zealand M\u0101ori in the past, and the oral records maintained and transmitted to succeeding generations, even before their contact with European civilization.Historiography has a number of related meanings. Firstly, it can refer to how history has been produced: the story of the development of methodology and practices . Thirdly, it may refer to why history is produced: the Philosophy of history. As a meta-level analysis of descriptions of the past, this third conception can relate to the first two in that the analysis usually focuses on the narratives, interpretations, world view, use of evidence, or method of presentation of other historians. Professional historians also debate the question of whether history can be taught as a single coherent narrative or a series of competing narratives.[25][26]Philosophy of history is a branch of philosophy concerning the eventual significance, if any, of human history. Furthermore, it speculates as to a possible teleological end to its development\u2014that is, it asks if there is a design, purpose, directive principle, or finality in the processes of human history. Philosophy of history should not be confused with historiography, which is the study of history as an academic discipline, and thus concerns its methods and practices, and its development as a discipline over time. Nor should philosophy of history be confused with the history of philosophy, which is the study of the development of philosophical ideas through time.The historical method comprises the techniques and guidelines by which historians use primary sources and other evidence to research and then to write history.Herodotus of Halicarnassus  is credited with having first approached history with a well-developed historical method in his work the History of the Peloponnesian War. Thucydides, unlike Herodotus, regarded history as being the product of the choices and actions of human beings, and looked at cause and effect, rather than as the result of divine intervention.[27] In his historical method, Thucydides emphasized chronology, a neutral point of view, and that the human world was the result of the actions of human beings. Greek historians also viewed history as cyclical, with events regularly recurring.[28]There were historical traditions and sophisticated use of historical method in ancient and medieval China. The groundwork for professional historiography in East Asia was established by the Han dynasty court historian known as Sima Qian . For the quality of his written work, Sima Qian is posthumously known as the Father of Chinese historiography. Chinese historians of subsequent dynastic periods in China used his Shiji as the official format for historical texts, as well as for biographical literature.[citation needed]Saint Augustine was influential in Christian and Western thought at the beginning of the medieval period. Through the Medieval and Renaissance periods, history was often studied through a sacred or religious perspective. Around 1800, German philosopher and historian Georg Wilhelm Friedrich Hegel brought philosophy and a more secular approach in historical study.[22]In the preface to his book, the Muqaddimah , the Arab historian and early sociologist, Ibn Khaldun, warned of seven mistakes that he thought that historians regularly committed. In this criticism, he approached the past as strange and in need of interpretation. The originality of Ibn Khaldun was to claim that the cultural difference of another age must govern the evaluation of relevant historical material, to distinguish the principles according to which it might be possible to attempt the evaluation, and lastly, to feel the need for experience, in addition to rational principles, in order to assess a culture of the past. Ibn Khaldun often criticized \"idle superstition and uncritical acceptance of historical data.\" As a result, he introduced a scientific method to the study of history, and he often referred to it as his \"new science\".[29] His historical method also laid the groundwork for the observation of the role of state, communication, propaganda and systematic bias in history,[30] and he is thus considered to be the \"father of historiography\"[31][32] or the \"father of the philosophy of history\".[33]In the West, historians developed modern methods of historiography in the 17th and 18th centuries, especially in France and Germany. The 19th-century historian with greatest influence on methods was Leopold von Ranke in Germany.In the 20th century, academic historians focused less on epic nationalistic narratives, which often tended to glorify the nation or great men, to more objective and complex analyses of social and intellectual forces. A major trend of historical methodology in the 20th century was a tendency to treat history more as a social science rather than as an art, which traditionally had been the case. Some of the leading advocates of history as a social science were a diverse collection of scholars which included Fernand Braudel, E. H. Carr, Fritz Fischer, Emmanuel Le Roy Ladurie, Hans-Ulrich Wehler, Bruce Trigger, Marc Bloch, Karl Dietrich Bracher, Peter Gay, Robert Fogel, Lucien Febvre and Lawrence Stone. Many of the advocates of history as a social science were or are noted for their multi-disciplinary approach. Braudel combined history with geography, Bracher history with political science, Fogel history with economics, Gay history with psychology, Trigger history with archaeology while Wehler, Bloch, Fischer, Stone, Febvre and Le Roy Ladurie have in varying and differing ways amalgamated history with sociology, geography, anthropology, and economics. More recently, the field of digital history has begun to address ways of using computer technology to pose new questions to historical data and generate digital scholarship.In opposition to the claims of history as a social science, historians such as Hugh Trevor-Roper, John Lukacs, Donald Creighton, Gertrude Himmelfarb and Gerhard Ritter argued that the key to the historians' work was the power of the imagination, and hence contended that history should be understood as an art. French historians associated with the Annales School introduced quantitative history, using raw data to track the lives of typical individuals, and were prominent in the establishment of cultural history . Scholars such as Martin Broszat, Ian Kershaw and Detlev Peukert sought to examine what everyday life was like for ordinary people in 20th-century Germany, especially in the Nazi period.Marxist historians such as Eric Hobsbawm, E. P. Thompson, Rodney Hilton, Georges Lefebvre, Eugene Genovese, Isaac Deutscher, C. L. R. James, Timothy Mason, Herbert Aptheker, Arno J. Mayer and Christopher Hill have sought to validate Karl Marx's theories by analyzing history from a Marxist perspective. In response to the Marxist interpretation of history, historians such as Fran\u00e7ois Furet, Richard Pipes, J. C. D. Clark, Roland Mousnier, Henry Ashby Turner and Robert Conquest have offered anti-Marxist interpretations of history. Feminist historians such as Joan Wallach Scott, Claudia Koonz, Natalie Zemon Davis, Sheila Rowbotham, Gisela Bock, Gerda Lerner, Elizabeth Fox-Genovese, and Lynn Hunt have argued for the importance of studying the experience of women in the past. In recent years, postmodernists have challenged the validity and need for the study of history on the basis that all history is based on the personal interpretation of sources. In his 1997 book In Defence of History, Richard J. Evans defended the worth of history. Another defence of history from post-modernist criticism was the Australian historian Keith Windschuttle's 1994 book, The Killing of History.The Marxist theory of historical materialism theorises that society is fundamentally determined by the material conditions at any given time\u00a0\u2013 in other words, the relationships which people have with each other in order to fulfill basic needs such as feeding, clothing and housing themselves and their families.[34] Overall, Marx and Engels claimed to have identified five successive stages of the development of these material conditions in Western Europe.[35] Marxist historiography was once orthodoxy in the Soviet Union, but since the collapse of communism there in 1991, Mikhail Krom says it has been reduced to the margins of scholarship.[36]Historical study often focuses on events and developments that occur in particular blocks of time. Historians give these periods of time names in order to allow \"organising ideas and classificatory generalisations\" to be used by historians.[37] The names given to a period can vary with geographical location, as can the dates of the beginning and end of a particular period. Centuries and decades are commonly used periods and the time they represent depends on the dating system used. Most periods are constructed retrospectively and so reflect value judgments made about the past. The way periods are constructed and the names given to them can affect the way they are viewed and studied.[38]The field of history generally leaves prehistory to the archaeologists, who have entirely different sets of tools and theories. The usual method for periodisation of the distant prehistoric past, in archaeology is to rely on changes in material culture and technology, such as the Stone Age, Bronze Age and Iron Age and their sub-divisions also based on different styles of material remains. Despite the development over recent decades of the ability through radiocarbon dating and other scientific methods to give actual dates for many sites or artefacts, these long-established schemes seem likely to remain in use. In many cases neighbouring cultures with writing have left some history of cultures without it, which may be used.Particular geographical locations can form the basis of historical study, for example, continents, countries and cities. Understanding why historic events took place is important. To do this, historians often turn to geography. Weather patterns, the water supply, and the landscape of a place all affect the lives of the people who live there. For example, to explain why the ancient Egyptians developed a successful civilization, studying the geography of Egypt is essential. Egyptian civilization was built on the banks of the Nile River, which flooded each year, depositing soil on its banks. The rich soil could help farmers grow enough crops to feed the people in the cities. That meant everyone did not have to farm, so some people could perform other jobs that helped develop the civilization.Military history concerns warfare, strategies, battles, weapons, and the psychology of combat. The \"new military history\" since the 1970s has been concerned with soldiers more than generals, with psychology more than tactics, and with the broader impact of warfare on society and culture.[39]The history of religion has been a main theme for both secular and religious historians for centuries, and continues to be taught in seminaries and academe. Leading journals include Church History, The Catholic Historical Review, and History of Religions. Topics range widely from political and cultural and artistic dimensions, to theology and liturgy.[40] This subject studies religions from all regions and areas of the world where humans have lived.[41]Social history, sometimes called the new social history, is the field that includes history of ordinary people and their strategies and institutions for coping with life.[42] In its \"golden age\" it was a major growth field in the 1960s and 1970s among scholars, and still is well represented in history departments. In two decades from 1975 to 1995, the proportion of professors of history in American universities identifying with social history rose from 31% to 41%, while the proportion of political historians fell from 40% to 30%.[43] In the history departments of British universities in 2007, of the 5723 faculty members, 1644 .[44] The \"old\" social history before the 1960s was a hodgepodge of topics without a central theme, and it often included political movements, like Populism, that were \"social\" in the sense of being outside the elite system. Social history was contrasted with political history, intellectual history and the history of great men. English historian G. M. Trevelyan saw it as the bridging point between economic and political history, reflecting that, \"Without social history, economic history is barren and political history unintelligible.\"[45] While the field has often been viewed negatively as history with the politics left out, it has also been defended as \"history with the people put back in.\"[46]The chief subfields of social history include:Smaller specialties include:Cultural history replaced social history as the dominant form in the 1980s and 1990s. It typically combines the approaches of anthropology and history to look at language, popular cultural traditions and cultural interpretations of historical experience. It examines the records and narrative descriptions of past knowledge, customs, and arts of a group of people. How peoples constructed their memory of the past is a major topic. Cultural history includes the study of art in society as well is the study of images and human visual production .[47]Diplomatic history focuses on the relationships between nations, primarily regarding diplomacy and the causes of wars. More recently it looks at the causes of peace and human rights. It typically presents the viewpoints of the foreign office, and long-term strategic values, as the driving force of continuity and change in history. This type of political history is the study of the conduct of international relations between states or across state boundaries over time. Historian Muriel Chamberlain notes that after the First World War, \"diplomatic history replaced constitutional history as the flagship of historical investigation, at once the most important, most exact and most sophisticated of historical studies.\"[48] She adds that after 1945, the trend reversed, allowing social history to replace it.Although economic history has been well established since the late 19th century, in recent years academic studies have shifted more and more toward economics departments and away from traditional history departments.[49] Business history deals with the history of individual business organizations, business methods, government regulation, labour relations, and impact on society. It also includes biographies of individual companies, executives, and entrepreneurs. It is related to economic history; Business history is most often taught in business schools.[50]Environmental history is a new field that emerged in the 1980s to look at the history of the environment, especially in the long run, and the impact of human activities upon it.[51]World history is the study of major civilizations over the last 3000 years or so. World history is primarily a teaching field, rather than a research field. It gained popularity in the United States,[52] Japan[53] and other countries after the 1980s with the realization that students need a broader exposure to the world as globalization proceeds.It has led to highly controversial interpretations by Oswald Spengler and Arnold J. Toynbee, among others.The World History Association publishes the Journal of World History every quarter since 1990.[54] The H-World discussion list[55] serves as a network of communication among practitioners of world history, with discussions among scholars, announcements, syllabi, bibliographies and book reviews.A people's history is a type of historical work which attempts to account for historical events from the perspective of common people. A people's history is the history of the world that is the story of mass movements and of the outsiders. Individuals or groups not included in the past in other type of writing about history are the primary focus, which includes the disenfranchised, the oppressed, the poor, the nonconformists, and the otherwise forgotten people. The authors are typically on the left and have a socialist model in mind, as in the approach of the History Workshop movement in Britain in the 1960s.[56]Intellectual history and the history of ideas emerged in the mid-20th century, with the focus on the intellectuals and their books on the one hand, and on the other the study of ideas as disembodied objects with a career of their own.[57][58]Gender history is a sub-field of History and Gender studies, which looks at the past from the perspective of gender. It is in many ways, an outgrowth of women's history. Despite its relatively short life, Gender History  has had a rather significant effect on the general study of history. Since the 1960s, when the initially small field first achieved a measure of acceptance, it has gone through a number of different phases, each with its own challenges and outcomes. Although some of the changes to the study of history have been quite obvious, such as increased numbers of books on famous women or simply the admission of greater numbers of women into the historical profession, other influences are more subtle.Public history describes the broad range of activities undertaken by people with some training in the discipline of history who are generally working outside of specialized academic settings. Public history practice has quite deep roots in the areas of historic preservation, archival science, oral history, museum curatorship, and other related fields. The term itself began to be used in the U.S. and Canada in the late 1970s, and the field has become increasingly professionalized since that time. Some of the most common settings for public history are museums, historic homes and historic sites, parks, battlefields, archives, film and television companies, and all levels of government.[59]Professional and amateur historians discover, collect, organize, and present information about past events.They discover this information through archaeological evidence, written primary sources from the past and other various means such as place names. In lists of historians, historians can be grouped by order of the historical period in which they were writing, which is not necessarily the same as the period in which they specialized. Chroniclers and annalists, though they are not historians in the true sense, are also frequently included.Since the 20th century, Western historians have disavowed the aspiration to provide the \"judgement of history.\"[60] The goals of historical judgements or interpretations are separate to those of legal judgements, that need to be formulated quickly after the events and be final.[61] A related issue to that of the judgement of history is that of collective memory.Pseudohistory is a term applied to texts which purport to be historical in nature but which depart from standard historiographical conventions in a way which undermines their conclusions. Closely related to deceptive historical revisionism, works which draw controversial conclusions from new, speculative, or disputed historical evidence, particularly in the fields of national, political, military, and religious affairs, are often rejected as pseudohistory.A major intellectual battle took place in Britain in the early twentieth century regarding the place of history teaching in the universities. At Oxford and Cambridge, scholarship was downplayed. Professor Charles Harding Firth, Oxford's Regius Professor of history in 1904 ridiculed the system as best suited to produce superficial journalists. The Oxford tutors, who had more votes than the professors, fought back in defence of their system saying that it successfully produced Britain's outstanding statesmen, administrators, prelates, and diplomats, and that mission was as valuable as training scholars. The tutors dominated the debate until after the Second World War. It forced aspiring young scholars to teach at outlying schools, such as Manchester University, where Thomas Frederick Tout was professionalizing the History undergraduate programme by introducing the study of original sources and requiring the writing of a thesis.[62][63]In the United States, scholarship was concentrated at the major PhD-producing universities, while the large number of other colleges and universities focused on undergraduate teaching. A tendency in the 21st century was for the latter schools to increasingly demand scholarly productivity of their younger tenure-track faculty. Furthermore, universities have increasingly relied on inexpensive part-time adjuncts to do most of the classroom teaching.[64]From the origins of national school systems in the 19th century, the teaching of history to promote national sentiment has been a high priority. In the United States after World War I, a strong movement emerged at the university level to teach courses in Western Civilization, so as to give students a common heritage with Europe. In the U.S. after 1980, attention increasingly moved toward teaching world history or requiring students to take courses in non-western cultures, to prepare students for life in a globalized economy.[65]At the university level, historians debate the question of whether history belongs more to social science or to the humanities. Many view the field from both perspectives.The teaching of history in French schools was influenced by the Nouvelle histoire as disseminated after the 1960s by Cahiers p\u00e9dagogiques and Enseignement and other journals for teachers. Also influential was the Institut national de recherche et de documentation p\u00e9dagogique, . Joseph Leif, the Inspector-general of teacher training, said pupils children should learn about historians' approaches as well as facts and dates. Louis Fran\u00e7ois, Dean of the History/Geography group in the Inspectorate of National Education advised that teachers should provide historic documents and promote \"active methods\" which would give pupils \"the immense happiness of discovery.\" Proponents said it was a reaction against the memorization of names and dates that characterized teaching and left the students bored. Traditionalists protested loudly it was a postmodern innovation that threatened to leave the youth ignorant of French patriotism and national identity.[66]In most countries history textbook are tools to foster nationalism and patriotism, and give students the official line about national enemies.[67]In many countries, history textbooks are sponsored by the national government and are written to put the national heritage in the most favourable light. For example, in Japan, mention of the Nanking Massacre has been removed from textbooks and the entire Second World War is given cursory treatment. Other countries have complained.[68] It was standard policy in communist countries to present only a rigid Marxist historiography.[69][70]Academic historians have often fought against the politicization of the textbooks, sometimes with success.[71][72]In 21st-century Germany, the history curriculum is controlled by the 16 states, and is characterized not by superpatriotism but rather by an \"almost pacifistic and deliberately unpatriotic undertone\" and reflects \"principles formulated by international organizations such as UNESCO or the Council of Europe, thus oriented towards human rights, democracy and peace.\" The result is that \"German textbooks usually downplay national pride and ambitions and aim to develop an understanding of citizenship centred on democracy, progress, human rights, peace, tolerance and Europeanness.\"[73]"], "Languages and literature": ["Language is a system that consists of the development, acquisition, maintenance and use of complex systems of communication, particularly the human ability to do so; and a language is any specific example of such a system.The scientific study of language is called linguistics. Questions concerning the philosophy of language, such as whether words can represent experience, have been debated at least since Gorgias and Plato in ancient Greece. Thinkers such as Rousseau have argued that language originated from emotions while others like Kant have held that it originated from rational and logical thought. 20th-century philosophers such as Wittgenstein argued that philosophy is really the study of language. Major figures in linguistics include Ferdinand de Saussure and Noam Chomsky.Estimates of the number of human languages in the world vary between 5,000 and 7,000. However, any precise estimate depends on a partly arbitrary distinction between languages and dialects. Natural languages are spoken or signed, but any language can be encoded into secondary media using auditory, visual, or tactile stimuli\u00a0\u2013 for example, in whistling, signed, or braille. This is because human language is modality-independent. Depending on philosophical perspectives regarding the definition of language and meaning, when used as a general concept, \"language\" may refer to the cognitive ability to learn and use systems of complex communication, or to describe the set of rules that makes up these systems, or the set of utterances that can be produced from those rules. All languages rely on the process of semiosis to relate signs to particular meanings. Oral, manual and tactile languages contain a phonological system that governs how symbols are used to form sequences known as words or morphemes, and a syntactic system that governs how words and morphemes are combined to form phrases and utterances.Human language has the properties of productivity and displacement, and relies entirely on social convention and learning. Its complex structure affords a much wider range of expressions than any known system of animal communication. Language is thought to have originated when early hominins started gradually changing their primate communication systems, acquiring the ability to form a theory of other minds and a shared intentionality.[1][2] This development is sometimes thought to have coincided with an increase in brain volume, and many linguists see the structures of language as having evolved to serve specific communicative and social functions. Language is processed in many different locations in the human brain, but especially in Broca's and Wernicke's areas. Humans acquire language through social interaction in early childhood, and children generally speak fluently by approximately three years old. The use of language is deeply entrenched in human culture. Therefore, in addition to its strictly communicative uses, language also has many social and cultural uses, such as signifying group identity, social stratification, as well as social grooming and entertainment.Languages evolve and diversify over time, and the history of their evolution can be reconstructed by comparing modern languages to determine which traits their ancestral languages must have had in order for the later developmental stages to occur. A group of languages that descend from a common ancestor is known as a language family. The Indo-European family is the most widely spoken and includes languages as diverse as English, Russian and Hindi; the Sino-Tibetan family, which includes Mandarin, Bodo and the other Chinese languages, and Tibetan; the Afro-Asiatic family, which includes Arabic, Somali, and Hebrew; the Bantu languages, which include Swahili, and Zulu, and hundreds of other languages spoken throughout Africa; and the Malayo-Polynesian languages, which include Indonesian, Malay, Tagalog, and hundreds of other languages spoken throughout the Pacific. The languages of the Dravidian family that are spoken mostly in Southern India include Tamil and Telugu. Academic consensus holds that between 50% and 90% of languages spoken at the beginning of the 21st century will probably have become extinct by the year 2100.The English word language derives ultimately from Proto-Indo-European *dn\u0325\u01f5\u02b0w\u00e9h\u2082s \"tongue, speech, language\" through Latin lingua, \"language; tongue\", and Old French language.[3] The word is sometimes used to refer to codes, ciphers, and other kinds of artificially constructed communication systems such as formally defined computer languages used for computer programming. Unlike conventional human languages, a formal language in this sense is a system of signs for encoding and decoding information. This article specifically concerns the properties of natural human language as it is studied in the discipline of linguistics.As an object of linguistic study, \"language\" has two primary meanings: an abstract concept, and a specific linguistic system, e.g. \"French\". The Swiss linguist Ferdinand de Saussure, who defined the modern discipline of linguistics, first explicitly formulated the distinction using the French word langage for language as a concept, langue as a specific instance of a language system, and parole for the concrete usage of speech in a particular language.[4]When speaking of language as a general concept, definitions can be used which stress different aspects of the phenomenon.[5] These definitions also entail different approaches and understandings of language, and they also inform different and often incompatible schools of linguistic theory.[6] Debates about the nature and origin of language go back to the ancient world. Greek philosophers such as Gorgias and Plato debated the relation between words, concepts and reality. Gorgias argued that language could represent neither the objective experience nor human experience, and that communication and truth were therefore impossible. Plato maintained that communication is possible because language represents ideas and concepts that exist independently of, and prior to, language.[7]During the Enlightenment and its debates about human origins, it became fashionable to speculate about the origin of language. Thinkers such as Rousseau and Herder argued that language had originated in the instinctive expression of emotions, and that it was originally closer to music and poetry than to the logical expression of rational thought. Rationalist philosophers such as Kant and Descartes held the opposite view. Around the turn of the 20th century, thinkers began to wonder about the role of language in shaping our experiences of the world\u00a0\u2013 asking whether language simply reflects the objective structure of the world, or whether it creates concepts that it in turn imposes on our experience of the objective world. This led to the question of whether philosophical problems are really firstly linguistic problems. The resurgence of the view that language plays a significant role in the creation and circulation of concepts, and that the study of philosophy is essentially the study of language, is associated with what has been called the linguistic turn and philosophers such as Wittgenstein in 20th-century philosophy. These debates about language in relation to meaning and reference, cognition and consciousness remain active today.[8]One definition sees language primarily as the mental faculty that allows humans to undertake linguistic behaviour: to learn languages and to produce and understand utterances. This definition stresses the universality of language to all humans, and it emphasizes the biological basis for the human capacity for language as a unique development of the human brain. Proponents of the view that the drive to language acquisition is innate in humans argue that this is supported by the fact that all cognitively normal children raised in an environment where language is accessible will acquire language without formal instruction. Languages may even develop spontaneously in environments where people live or grow up together without a common language; for example, creole languages and spontaneously developed sign languages such as Nicaraguan Sign Language. This view, which can be traced back to the philosophers Kant and Descartes, understands language to be largely innate, for example, in Chomsky's theory of Universal Grammar, or American philosopher Jerry Fodor's extreme innatist theory. These kinds of definitions are often applied in studies of language within a cognitive science framework and in neurolinguistics.[9][10]Another definition sees language as a formal system of signs governed by grammatical rules of combination to communicate meaning. This definition stresses that human languages can be described as closed structural systems consisting of rules that relate particular signs to particular meanings.[11] This structuralist view of language was first introduced by Ferdinand de Saussure,[12] and his structuralism remains foundational for many approaches to language.[13]Some proponents of Saussure's view of language have advocated a formal approach which studies language structure by identifying its basic elements and then by presenting a formal account of the rules according to which the elements combine in order to form words and sentences. The main proponent of such a theory is Noam Chomsky, the originator of the generative theory of grammar, who has defined language as the construction of sentences that can be generated using transformational grammars.[14] Chomsky considers these rules to be an innate feature of the human mind and to constitute the rudiments of what language is.[15] By way of contrast, such transformational grammars are also commonly used to provide formal definitions of language are commonly used in formal logic, in formal theories of grammar, and in applied computational linguistics.[16][17] In the philosophy of language, the view of linguistic meaning as residing in the logical relations between propositions and reality was developed by philosophers such as Alfred Tarski, Bertrand Russell, and other formal logicians.Yet another definition sees language as a system of communication that enables humans to exchange verbal or symbolic utterances. This definition stresses the social functions of language and the fact that humans use it to express themselves and to manipulate objects in their environment. Functional theories of grammar explain grammatical structures by their communicative functions, and understand the grammatical structures of language to be the result of an adaptive process by which grammar was \"tailored\" to serve the communicative needs of its users.[18][19]This view of language is associated with the study of language in pragmatic, cognitive, and interactive frameworks, as well as in sociolinguistics and linguistic anthropology. Functionalist theories tend to study grammar as dynamic phenomena, as structures that are always in the process of changing as they are employed by their speakers. This view places importance on the study of linguistic typology, or the classification of languages according to structural features, as it can be shown that processes of grammaticalization tend to follow trajectories that are partly dependent on typology.[17] In the philosophy of language, the view of pragmatics as being central to language and meaning is often associated with Wittgenstein's later works and with ordinary language philosophers such as J. L. Austin, Paul Grice, John Searle, and W. O. Quine.[20]A number of features, many of which were described by Charles Hockett and called design features[21] set human language apart from other known systems of communication, such as those used by non-human animals.Communication systems used by other animals such as bees or apes are closed systems that consist of a finite, usually very limited, number of possible ideas that can be expressed.[22] In contrast, human language is open-ended and productive, meaning that it allows humans to produce a vast range of utterances from a finite set of elements, and to create new words and sentences. This is possible because human language is based on a dual code, in which a finite number of elements which are meaningless in themselves .[23] However, one study has demonstrated that an Australian bird, the chestnut-crowned babbler, is capable of using the same acoustic elements in different arrangements to create two functionally distinct vocalizations.[24] Additionally, pied babblers have demonstrated the ability to generate two functionally distinct vocalisations composed of the same sound type, which can only be distinguished by the number of repeated elements.[25]Several species of animals have proved to be able to acquire forms of communication through social learning: for instance a bonobo named Kanzi learned to express itself using a set of symbolic lexigrams. Similarly, many species of birds and whales learn their songs by imitating other members of their species. However, while some animals may acquire large numbers of words and symbols,[note 1] none have been able to learn as many different signs as are generally known by an average 4 year old human, nor have any acquired anything resembling the complex grammar of human language.[26]Human languages also differ from animal communication systems in that they employ grammatical and semantic categories, such as noun and verb, present and past, which may be used to express exceedingly complex meanings.[26] Human language is also unique in having the property of recursivity: for example, a noun phrase can contain another noun phrase .[2] Human language is also the only known natural communication system whose adaptability may be referred to as modality independent. This means that it can be used not only for communication through one channel or medium, but through several. For example, spoken language uses the auditive modality, whereas sign languages and writing use the visual modality, and braille writing uses the tactile modality.[27]Human language is also unique in being able to refer to abstract concepts and to imagined or hypothetical events as well as events that took place in the past or may happen in the future. This ability to refer to events that are not at the same time or place as the speech event is called displacement, and while some animal communication systems can use displacement , the degree to which it is used in human language is also considered unique.[23]Theories about the origin of language differ in regard to their basic assumptions about what language is. Some theories are based on the idea that language is so complex that one cannot imagine it simply appearing from nothing in its final form, but that it must have evolved from earlier pre-linguistic systems among our pre-human ancestors. These theories can be called continuity-based theories. The opposite viewpoint is that language is such a unique human trait that it cannot be compared to anything found among non-humans and that it must therefore have appeared suddenly in the transition from pre-hominids to early man. These theories can be defined as discontinuity-based. Similarly, theories based on Chomsky's generative view of language see language mostly as an innate faculty that is largely genetically encoded, whereas functionalist theories see it as a system that is largely cultural, learned through social interaction.[29]One prominent proponent of a discontinuity-based theory of human language origins is linguist and philosopher Noam Chomsky.[29] Chomsky proposes that \"some random mutation took place, maybe after some strange cosmic ray shower, and it reorganized the brain, implanting a language organ in an otherwise primate brain.\"[30] Though cautioning against taking this story too literally, Chomsky insists that \"it may be closer to reality than many other fairy tales that are told about evolutionary processes, including language.\"[30]Continuity-based theories are held by a majority of scholars, but they vary in how they envision this development. Those who see language as being mostly innate, for example psychologist Steven Pinker, hold the precedents to be animal cognition,[10] whereas those who see language as a socially learned tool of communication, such as psychologist Michael Tomasello, see it as having developed from animal communication in primates: either gestural or vocal communication to assist in cooperation.[31] Other continuity-based models see language as having developed from music, a view already espoused by Rousseau, Herder, Humboldt, and Charles Darwin. A prominent proponent of this view is archaeologist Steven Mithen.[32] Stephen Anderson states that the age of spoken languages is estimated at 60,000 to 100,000 years[33] and that:Because language emerged in the early prehistory of man, before the existence of any written records, its early development has left no historical traces, and it is believed that no comparable processes can be observed today. Theories that stress continuity often look at animals to see if, for example, primates display any traits that can be seen as analogous to what pre-human language must have been like. And early human fossils can be inspected for traces of physical adaptation to language use or pre-linguistic forms of symbolic behaviour. Among the signs in human fossils that may suggest linguistic abilities are: the size of the brain relative to body mass, the presence of a larynx capable of advanced sound production and the nature of tools and other manufactured artifacts.[35]It was mostly undisputed that pre-human australopithecines did not have communication systems significantly different from those found in great apes in general. However, a 2017 study on Ardipithecus ramidus challenges this belief.[36] Scholarly opinions vary as to the developments since the appearance of the genus Homo some 2.5 million years ago. Some scholars assume the development of primitive language-like systems , and the development of language proper with Anatomically Modern Homo sapiens with the Upper Paleolithic revolution less than 100,000 years ago.[37][38]The study of language, linguistics, has been developing into a science since the first grammatical descriptions of particular languages in India more than 2000 years ago, after the development of the Brahmi script. Modern linguistics is a science that concerns itself with all aspects of language, examining it from all of the theoretical viewpoints described above.[39]The academic study of language is conducted within many different disciplinary areas and from different theoretical angles, all of which inform modern approaches to linguistics. For example, descriptive linguistics examines the grammar of single languages, theoretical linguistics develops theories on how best to conceptualize and define the nature of language based on data from the various extant human languages, sociolinguistics studies how languages are used for social purposes informing in turn the study of the social functions of language and grammatical description, neurolinguistics studies how language is processed in the human brain and allows the experimental testing of theories, computational linguistics builds on theoretical and descriptive linguistics to construct computational models of language often aimed at processing natural language or at testing linguistic hypotheses, and historical linguistics relies on grammatical and lexical descriptions of languages to trace their individual histories and reconstruct trees of language families by using the comparative method.[40]The formal study of language is often considered to have started in India with P\u0101\u1e47ini, the 5th century BC grammarian who formulated 3,959 rules of Sanskrit morphology. However, Sumerian scribes already studied the differences between Sumerian and Akkadian grammar around 1900 BC. Subsequent grammatical traditions developed in all of the ancient cultures that adopted writing.[41]In the 17th century AD, the French Port-Royal Grammarians developed the idea that the grammars of all languages were a reflection of the universal basics of thought, and therefore that grammar was universal. In the 18th century, the first use of the comparative method by British philologist and expert on ancient India William Jones sparked the rise of comparative linguistics.[42] The scientific study of language was broadened from Indo-European to language in general by Wilhelm von Humboldt. Early in the 20th century, Ferdinand de Saussure introduced the idea of language as a static system of interconnected units, defined through the oppositions between them.[12]By introducing a distinction between diachronic and synchronic analyses of language, he laid the foundation of the modern discipline of linguistics. Saussure also introduced several basic dimensions of linguistic analysis that are still fundamental in many contemporary linguistic theories, such as the distinctions between syntagm and paradigm, and the Langue-parole distinction, distinguishing language as an abstract system .[43]In the 1960s, Noam Chomsky formulated the generative theory of language. According to this theory, the most basic form of language is a set of syntactic rules that is universal for all humans and which underlies the grammars of all human languages. This set of rules is called Universal Grammar; for Chomsky, describing it is the primary objective of the discipline of linguistics. Thus, he considered that the grammars of individual languages are only of importance to linguistics insofar as they allow us to deduce the universal underlying rules from which the observable linguistic variability is generated.[44]In opposition to the formal theories of the generative school, functional theories of language propose that since language is fundamentally a tool, its structures are best analyzed and understood by reference to their functions. Formal theories of grammar seek to define the different elements of language and describe the way they relate to each other as systems of formal rules or operations, while functional theories seek to define the functions performed by language and then relate them to the linguistic elements that carry them out.[17][note 2] The framework of cognitive linguistics interprets language in terms of the concepts  which underlie its forms. Cognitive linguistics is primarily concerned with how the mind creates meaning through language.[45]Speaking is the default modality for language in all cultures. The production of spoken language depends on sophisticated capacities for controlling the lips, tongue and other components of the vocal apparatus, the ability to acoustically decode speech sounds, and the neurological apparatus required for acquiring and producing language.[46] The study of the genetic bases for human language is at an early stage: the only gene that has definitely been implicated in language production is FOXP2, which may cause a kind of congenital language disorder if affected by mutations.[47]The brain is the coordinating center of all linguistic activity; it controls both the production of linguistic cognition and of meaning and the mechanics of speech production. Nonetheless, our knowledge of the neurological bases for language is quite limited, though it has advanced considerably with the use of modern imaging techniques. The discipline of linguistics dedicated to studying the neurological aspects of language is called neurolinguistics.[48]Early work in neurolinguistics involved the study of language in people with brain lesions, to see how lesions in specific areas affect language and speech. In this way, neuroscientists in the 19th century discovered that two areas in the brain are crucially implicated in language processing. The first area is Wernicke's area, which is in the posterior section of the superior temporal gyrus in the dominant cerebral hemisphere. People with a lesion in this area of the brain develop receptive aphasia, a condition in which there is a major impairment of language comprehension, while speech retains a natural-sounding rhythm and a relatively normal sentence structure. The second area is Broca's area, in the posterior inferior frontal gyrus of the dominant hemisphere. People with a lesion to this area develop expressive aphasia, meaning that they know what they want to say, they just cannot get it out.[49] They are typically able to understand what is being said to them, but unable to speak fluently. Other symptoms that may be present in expressive aphasia include problems with fluency, articulation, word-finding, word repetition, and producing and comprehending complex grammatical sentences, both orally and in writing. Those with this aphasia also exhibit ungrammatical speech and show inability to use syntactic information to determine the meaning of sentences. Both expressive and receptive aphasia also affect the use of sign language, in analogous ways to how they affect speech, with expressive aphasia causing signers to sign slowly and with incorrect grammar, whereas a signer with receptive aphasia will sign fluently, but make little sense to others and have difficulties comprehending others' signs. This shows that the impairment is specific to the ability to use language, not to the physiology used for speech production.[50][51]With technological advances in the late 20th century, neurolinguists have also incorporated non-invasive techniques such as functional magnetic resonance imaging  and electrophysiology to study language processing in individuals without impairments.[48]Spoken language relies on human physical ability to produce sound, which is a longitudinal wave propagated through the air at a frequency capable of vibrating the ear drum. This ability depends on the physiology of the human speech organs. These organs consist of the lungs, the voice box , and the upper vocal tract\u00a0\u2013 the throat, the mouth, and the nose. By controlling the different parts of the speech apparatus, the airstream can be manipulated to produce different speech sounds.[52]The sound of speech can be analyzed into a combination of segmental and suprasegmental elements. The segmental elements are those that follow each other in sequences, which are usually represented by distinct letters in alphabetic scripts, such as the Roman script. In free flowing speech, there are no clear boundaries between one segment and the next, nor usually are there any audible pauses between words. Segments therefore are distinguished by their distinct sounds which are a result of their different articulations, and they can be either vowels or consonants. Suprasegmental phenomena encompass such elements as stress, phonation type, voice timbre, and prosody or intonation, all of which may have effects across multiple segments.[53]Consonants and vowel segments combine to form syllables, which in turn combine to form utterances; these can be distinguished phonetically as the space between two inhalations. Acoustically, these different segments are characterized by different formant structures, that are visible in a spectrogram of the recorded sound wave . Formants are the amplitude peaks in the frequency spectrum of a specific sound.[53][54]Vowels are those sounds that have no audible friction caused by the narrowing or obstruction of some part of the upper vocal tract. They vary in quality according to the degree of lip aperture and the placement of the tongue within the oral cavity.[53] Vowels are called close when the lips are relatively closed, as in the pronunciation of the vowel [i] .[55]Consonants are those sounds that have audible friction or closure at some point within the upper vocal tract. Consonant sounds vary by place of articulation, i.e. the place in the vocal tract where the airflow is obstructed, commonly at the lips, teeth, alveolar ridge, palate, velum, uvula, or glottis. Each place of articulation produces a different set of consonant sounds, which are further distinguished by manner of articulation, or the kind of friction, whether full closure, in which case the consonant is called occlusive or stop, or different degrees of aperture creating fricatives and approximants. Consonants can also be either voiced or unvoiced, depending on whether the vocal cords are set in vibration by airflow during the production of the sound. Voicing is what separates English [s] in bus .[56]Some speech sounds, both vowels and consonants, involve release of air flow through the nasal cavity, and these are called nasals or nasalized sounds. Other sounds are defined by the way the tongue moves within the mouth: such as the l-sounds  that are characterized by how the tongue is positioned relative to the air stream.[54]By using these speech organs, humans can produce hundreds of distinct sounds: some appear very often in the world's languages, whereas others are much more common in certain language families, language areas, or even specific to a single language.[57]When described as a system of symbolic communication, language is traditionally seen as consisting of three parts: signs, meanings, and a code connecting signs with their meanings. The study of the process of semiosis, how signs and meanings are combined, used, and interpreted is called semiotics. Signs can be composed of sounds, gestures, letters, or symbols, depending on whether the language is spoken, signed, or written, and they can be combined into complex signs, such as words and phrases. When used in communication, a sign is encoded and transmitted by a sender through a channel to a receiver who decodes it.[58]Some of the properties that define human language as opposed to other communication systems are: the arbitrariness of the linguistic sign, meaning that there is no predictable connection between a linguistic sign and its meaning; the duality of the linguistic system, meaning that linguistic structures are built by combining elements into larger structures that can be seen as layered, e.g. how sounds build words and words build phrases; the discreteness of the elements of language, meaning that the elements out of which linguistic signs are constructed are discrete units, e.g. sounds and words, that can be distinguished from each other and rearranged in different patterns; and the productivity of the linguistic system, meaning that the finite number of linguistic elements can be combined into a theoretically infinite number of combinations.[58]The rules by which signs can be combined to form words and phrases are called syntax or grammar. The meaning that is connected to individual signs, morphemes, words, phrases, and texts is called semantics.[59] The division of language into separate but connected systems of sign and meaning goes back to the first linguistic studies of de Saussure and is now used in almost all branches of linguistics.[60]Languages express meaning by relating a sign form to a meaning, or its content. Sign forms must be something that can be perceived, for example, in sounds, images, or gestures, and then related to a specific meaning by social convention. Because the basic relation of meaning for most linguistic signs is based on social convention, linguistic signs can be considered arbitrary, in the sense that the convention is established socially and historically, rather than by means of a natural relation between a specific sign form and its meaning.Thus, languages must have a vocabulary of signs related to specific meaning. The English sign \"dog\" denotes, for example, a member of the species Canis familiaris. In a language, the array of arbitrary signs connected to specific meanings is called the lexicon, and a single sign connected to a meaning is called a lexeme. Not all meanings in a language are represented by single words. Often, semantic concepts are embedded in the morphology or syntax of the language in the form of grammatical categories.[61]All languages contain the semantic structure of predication: a structure that predicates a property, state, or action. Traditionally, semantics has been understood to be the study of how speakers and interpreters assign truth values to statements, so that meaning is understood to be the process by which a predicate can be said to be true or false about an entity, e.g. \"[x [is y]]\" or \"[x [does y]]\". Recently, this model of semantics has been complemented with more dynamic models of meaning that incorporate shared knowledge about the context in which a sign is interpreted into the production of meaning. Such models of meaning are explored in the field of pragmatics.[61]Depending on modality, language structure can be based on systems of sounds . The ways in which languages use sounds or signs to construct meaning are studied in phonology.[62] The study of how humans produce and perceive vocal sounds is called phonetics.[63] In spoken language, meaning is produced when sounds become part of a system in which some sounds can contribute to expressing meaning and others do not. In any given language, only a limited number of the many distinct sounds that can be created by the human vocal apparatus contribute to constructing meaning.[57]Sounds as part of a linguistic system are called phonemes.[64] Phonemes are abstract units of sound, defined as the smallest units in a language that can serve to distinguish between the meaning of a pair of minimally different words, a so-called minimal pair. In English, for example, the words bat [b\u00e6t] and pat [p\u02b0\u00e6t] form a minimal pair, in which the distinction between /b/ and /p/ differentiates the two words, which have different meanings. However, each language contrasts sounds in different ways. For example, in a language that does not distinguish between voiced and unvoiced consonants, the sounds [p] and [b] .[65]All spoken languages have phonemes of at least two different categories, vowels and consonants, that can be combined to form syllables.[53] As well as segments such as consonants and vowels, some languages also use sound in other ways to convey meaning. Many languages, for example, use stress, pitch, duration, and tone to distinguish meaning. Because these phenomena operate outside of the level of single segments, they are called suprasegmental.[66] Some languages have only a few phonemes, for example, Rotokas and Pirah\u00e3 language with 11 and 10 phonemes respectively, whereas languages like Taa may have as many as 141 phonemes.[65] In sign languages, the equivalent to phonemes  are defined by the basic elements of gestures, such as hand shape, orientation, location, and motion, which correspond to manners of articulation in spoken language.[67][68][69]Writing systems represent language using visual symbols, which may or may not correspond to the sounds of spoken language. The Latin alphabet  was originally based on the representation of single sounds, so that words were constructed from letters that generally denote a single consonant or vowel in the structure of the word. In syllabic scripts, such as the Inuktitut syllabary, each sign represents a whole syllable. In logographic scripts, each sign represents an entire word,[70] and will generally bear no relation to the sound of that word in spoken language.Because all languages have a very large number of words, no purely logographic scripts are known to exist. Written language represents the way spoken sounds and words follow one after another by arranging symbols according to a pattern that follows a certain direction. The direction used in a writing system is entirely arbitrary and established by convention. Some writing systems use the horizontal axis . A few writing systems use opposite directions for alternating lines, and others, such as the ancient Maya script, can be written in either direction and rely on graphic cues to show the reader the direction of reading.[71]In order to represent the sounds of the world's languages in writing, linguists have developed the International Phonetic Alphabet, designed to represent all of the discrete sounds that are known to contribute to meaning in human languages.[72]Grammar is the study of how meaningful elements called morphemes within a language can be combined into utterances. Morphemes can either be free or bound. If they are free to be moved around within an utterance, they are usually called words, and if they are bound to other words or morphemes, they are called affixes. The way in which meaningful elements can be combined within a language is governed by rules. The rules for the internal structure of words are called morphology. The rules of the internal structure of phrases and sentences are called syntax.[73]Grammar can be described as a system of categories and a set of rules that determine how categories combine to form different aspects of meaning.[74] Languages differ widely in whether they are encoded through the use of categories or lexical units. However, several categories are so common as to be nearly universal. Such universal categories include the encoding of the grammatical relations of participants and predicates by grammatically distinguishing between their relations to a predicate, the encoding of temporal and spatial relations on predicates, and a system of grammatical person governing reference to and distinction between speakers and addressees and those about whom they are speaking.[75]Languages organize their parts of speech into classes according to their functions and positions relative to other parts. All languages, for instance, make a basic distinction between a group of words that prototypically denotes things and concepts and a group of words that prototypically denotes actions and events. The first group, which includes English words such as \"dog\" and \"song\", are usually called nouns. The second, which includes \"run\" and \"sing\", are called verbs. Another common category is the adjective: words that describe properties or qualities of nouns, such as \"red\" or \"big\". Word classes can be \"open\" if new words can continuously be added to the class, or relatively \"closed\" if there is a fixed number of words in a class. In English, the class of pronouns is closed, whereas the class of adjectives is open, since an infinite number of adjectives can be constructed from verbs . In other languages such as Korean, the situation is the opposite, and new pronouns can be constructed, whereas the number of adjectives is fixed.[76]Word classes also carry out differing functions in grammar. Prototypically, verbs are used to construct predicates, while nouns are used as arguments of predicates. In a sentence such as \"Sally runs\", the predicate is \"runs\", because it is the word that predicates a specific state about its argument \"Sally\". Some verbs such as \"curse\" can take two arguments, e.g. \"Sally cursed John\". A predicate that can only take a single argument is called intransitive, while a predicate that can take two arguments is called transitive.[77]Many other word classes exist in different languages, such as conjunctions like \"and\" that serve to join two sentences, articles that introduce a noun, interjections such as \"wow!\", or ideophones like \"splash\" that mimic the sound of some event. Some languages have positionals that describe the spatial position of an event or entity. Many languages have classifiers that identify countable nouns as belonging to a particular type or having a particular shape. For instance, in Japanese, the general noun classifier for humans is nin , and it is used for counting humans, whatever they are called:[78]For trees, it would be:In linguistics, the study of the internal structure of complex words and the processes by which words are formed is called morphology. In most languages, it is possible to construct complex words that are built of several morphemes. For instance, the English word \"unexpected\" can be analyzed as being composed of the three morphemes \"un-\", \"expect\" and \"-ed\".[79]Morphemes can be classified according to whether they are independent morphemes, so-called roots, or whether they can only co-occur attached to other morphemes. These bound morphemes or affixes can be classified according to their position in relation to the root: prefixes precede the root, suffixes follow the root, and infixes are inserted in the middle of a root. Affixes serve to modify or elaborate the meaning of the root. Some languages change the meaning of words by changing the phonological structure of a word, for example, the English word \"run\", which in the past tense is \"ran\". This process is called ablaut. Furthermore, morphology distinguishes between the process of inflection, which modifies or elaborates on a word, and the process of derivation, which creates a new word from an existing one. In English, the verb \"sing\" has the inflectional forms \"singing\" and \"sung\", which are both verbs, and the derivational form \"singer\", which is a noun derived from the verb with the agentive suffix \"-er\".[80]Languages differ widely in how much they rely on morphological processes of word formation. In some languages, for example, Chinese, there are no morphological processes, and all grammatical information is encoded syntactically by forming strings of single words. This type of morpho-syntax is often called isolating, or analytic, because there is almost a full correspondence between a single word and a single aspect of meaning. Most languages have words consisting of several morphemes, but they vary in the degree to which morphemes are discrete units. In many languages, notably in most Indo-European languages, single morphemes may have several distinct meanings that cannot be analyzed into smaller segments. For example, in Latin, the word bonus, or \"good\", consists of the root bon-, meaning \"good\", and the suffix -us, which indicates masculine gender, singular number, and nominative case. These languages are called fusional languages, because several meanings may be fused into a single morpheme. The opposite of fusional languages are agglutinative languages which construct words by stringing morphemes together in chains, but with each morpheme as a discrete semantic unit. An example of such a language is Turkish, where for example, the word evlerinizden, or \"from your houses\", consists of the morphemes, ev-ler-iniz-den with the meanings house-plural-your-from. The languages that rely on morphology to the greatest extent are traditionally called polysynthetic languages. They may express the equivalent of an entire English sentence in a single word. For example, in Persian the single word nafahmidamesh means I didn't understand it consisting of morphemes na-fahm-id-am-esh with the meanings, \"negation.understand.past.I.it\". As another example with more complexity, in the Yupik word tuntussuqatarniksatengqiggtuq, which means \"He had not yet said again that he was going to hunt reindeer\", the word consists of the morphemes tuntu-ssur-qatar-ni-ksaite-ngqiggte-uq with the meanings, \"reindeer-hunt-future-say-negation-again-third.person.singular.indicative\", and except for the morpheme tuntu  none of the other morphemes can appear in isolation.[81]Many languages use morphology to cross-reference words within a sentence. This is sometimes called agreement. For example, in many Indo-European languages, adjectives must cross-reference the noun they modify in terms of number, case, and gender, so that the Latin adjective bonus, or \"good\", is inflected to agree with a noun that is masculine gender, singular number, and nominative case. In many polysynthetic languages, verbs cross-reference their subjects and objects. In these types of languages, a single verb may include information that would require an entire sentence in English. For example, in the Basque phrase ikusi nauzu, or \"you saw me\", the past tense auxiliary verb n-au-zu  expressed by the \u2013 zu suffix. The sentence could be directly transliterated as \"see you-did-me\"[82]Another way in which languages convey meaning is through the order of words within a sentence. The grammatical rules for how to produce new sentences from words that are already known is called syntax. The syntactical rules of a language determine why a sentence in English such as \"I love you\" is meaningful, but \"*love you I\" is not.[note 3] Syntactical rules determine how word order and sentence structure is constrained, and how those constraints contribute to meaning.[83] For example, in English, the two sentences \"the slaves were cursing the master\" and \"the master was cursing the slaves\" mean different things, because the role of the grammatical subject is encoded by the noun being in front of the verb, and the role of object is encoded by the noun appearing after the verb. Conversely, in Latin, both Dominus servos vituperabat and Servos vituperabat dominus mean \"the master was reprimanding the slaves\", because servos, or \"slaves\", is in the accusative case, showing that they are the grammatical object of the sentence, and dominus, or \"master\", is in the nominative case, showing that he is the subject.[84]Latin uses morphology to express the distinction between subject and object, whereas English uses word order. Another example of how syntactic rules contribute to meaning is the rule of inverse word order in questions, which exists in many languages. This rule explains why when in English, the phrase \"John is talking to Lucy\" is turned into a question, it becomes \"Who is John talking to?\", and not \"John is talking to who?\". The latter example may be used as a way of placing special emphasis on \"who\", thereby slightly altering the meaning of the question. Syntax also includes the rules for how complex sentences are structured by grouping words together in units, called phrases, that can occupy different places in a larger syntactic structure. Sentences can be described as consisting of phrases connected in a tree structure, connecting the phrases to each other at different levels.[85] To the right is a graphic representation of the syntactic analysis of the English sentence \"the cat sat on the mat\". The sentence is analyzed as being constituted by a noun phrase, a verb, and a prepositional phrase; the prepositional phrase is further divided into a preposition and a noun phrase, and the noun phrases consist of an article and a noun.[86]The reason sentences can be seen as being composed of phrases is because each phrase would be moved around as a single element if syntactic operations were carried out. For example, \"the cat\" is one phrase, and \"on the mat\" is another, because they would be treated as single units if a decision was made to emphasize the location by moving forward the prepositional phrase: \"[And] on the mat, the cat sat\".[86] There are many different formalist and functionalist frameworks that propose theories for describing syntactic structures, based on different assumptions about what language is and how it should be described. Each of them would analyze a sentence such as this in a different manner.[17]Languages can be classified in relation to their grammatical types. Languages that belong to different families nonetheless often have features in common, and these shared features tend to correlate.[87] For example, languages can be classified on the basis of their basic word order, the relative order of the verb, and its constituents in a normal indicative sentence. In English, the basic order is SVO: \"The snake languages that are of the SOV type have postpositions rather than prepositions, and have adjectives before nouns.[90]All languages structure sentences into Subject, Verb, and Object, but languages differ in the way they classify the relations between actors and actions. English uses the nominative-accusative word typology: in English transitive clauses, the subjects of both intransitive sentences  or even making each of the three roles differently, which is called the tripartite type.[91]The shared features of languages which belong to the same typological class type may have arisen completely independently. Their co-occurrence might be due to universal laws governing the structure of natural languages, \"language universals\", or they might be the result of languages evolving convergent solutions to the recurring communicative problems that humans use language to solve.[18]While humans have the ability to learn any language, they only do so if they grow up in an environment in which language exists and is used by others. Language is therefore dependent on communities of speakers in which children learn language from their elders and peers and themselves transmit language to their own children. Languages are used by those who speak them to communicate and to solve a plethora of social tasks. Many aspects of language use can be seen to be adapted specifically to these purposes.[18] Due to the way in which language is transmitted between generations and within communities, language perpetually changes, diversifying into new languages or converging due to language contact. The process is similar to the process of evolution, where the process of descent with modification leads to the formation of a phylogenetic tree.[93]However, languages differ from biological organisms in that they readily incorporate elements from other languages through the process of diffusion, as speakers of different languages come into contact. Humans also frequently speak more than one language, acquiring their first language or languages as children, or learning new languages as they grow up. Because of the increased language contact in the globalizing world, many small languages are becoming endangered as their speakers shift to other languages that afford the possibility to participate in larger and more influential speech communities.[94]The semantic study of meaning assumes that meaning is in a relation between signs and meanings that are firmly established through social convention. However, semantics does not study the way in which social conventions are made and affect language. Rather, when studying the way in which words and signs are used, it is often the case that words have different meanings, depending on the social context of use. An important example of this is the process called deixis, which describes the way in which certain words refer to entities through their relation between a specific point in time and space when the word is uttered. Such words are, for example, the word, \"I\" . Signs also change their meanings over time, as the conventions governing their usage gradually change. The study of how the meaning of linguistic expressions changes depending on context is called pragmatics. Deixis is an important part of the way that we use language to point out entities in the world.[95] Pragmatics is concerned with the ways in which language use is patterned and how these patterns contribute to meaning. For example, in all languages, linguistic expressions can be used not just to transmit information, but to perform actions. Certain actions are made only through language, but nonetheless have tangible effects, e.g. the act of \"naming\", which creates a new name for some entity, or the act of \"pronouncing someone man and wife\", which creates a social contract of marriage. These types of acts are called speech acts, although they can also be carried out through writing or hand signing.[96]The form of linguistic expression often does not correspond to the meaning that it actually has in a social context. For example, if at a dinner table a person asks, \"Can you reach the salt?\", that is, in fact, not a question about the length of the arms of the one being addressed, but a request to pass the salt across the table. This meaning is implied by the context in which it is spoken; these kinds of effects of meaning are called conversational implicatures. These social rules for which ways of using language are considered appropriate in certain situations and how utterances are to be understood in relation to their context vary between communities, and learning them is a large part of acquiring communicative competence in a language.[97]All healthy, normally developing human beings learn to use language. Children acquire the language or languages used around them: whichever languages they receive sufficient exposure to during childhood. The development is essentially the same for children acquiring sign or oral languages.[98] This learning process is referred to as first-language acquisition, since unlike many other kinds of learning, it requires no direct teaching or specialized study. In The Descent of Man, naturalist Charles Darwin called this process \"an instinctive tendency to acquire an art\".[10]First language acquisition proceeds in a fairly regular sequence, though there is a wide degree of variation in the timing of particular stages among normally developing infants. From birth, newborns respond more readily to human speech than to other sounds. Around one month of age, babies appear to be able to distinguish between different speech sounds. Around six months of age, a child will begin babbling, producing the speech sounds or handshapes of the languages used around them. Words appear around the age of 12 to 18 months; the average vocabulary of an eighteen-month-old child is around 50 words. A child's first utterances are holophrases , utterances that use just one word to communicate some idea. Several months after a child begins producing words, he or she will produce two-word utterances, and within a few more months will begin to produce telegraphic speech, or short sentences that are less grammatically complex than adult speech, but that do show regular syntactic structure. From roughly the age of three to five years, a child's ability to speak or sign is refined to the point that it resembles adult language.[99][100] Studies published in 2013 have indicated that unborn fetuses are capable of language acquisition to some degree.[101][102]Acquisition of second and additional languages can come at any age, through exposure in daily life or courses. Children learning a second language are more likely to achieve native-like fluency than adults, but in general, it is very rare for someone speaking a second language to pass completely for a native speaker. An important difference between first language acquisition and additional language acquisition is that the process of additional language acquisition is influenced by languages that the learner already knows.[103]Languages, understood as the particular set of speech norms of a particular community, are also a part of the larger culture of the community that speaks them. Languages differ not only in pronunciation, vocabulary, and grammar, but also through having different \"cultures of speaking.\" Humans use language as a way of signalling identity with one cultural group as well as difference from others. Even among speakers of one language, several different ways of using the language exist, and each is used to signal affiliation with particular subgroups within a larger culture. Linguists and anthropologists, particularly sociolinguists, ethnolinguists, and linguistic anthropologists have specialized in studying how ways of speaking vary between speech communities.[104]Linguists use the term \"varieties\" to refer to the different ways of speaking a language. This term includes geographically or socioculturally defined dialects as well as the jargons or styles of subcultures. Linguistic anthropologists and sociologists of language define communicative style as the ways that language is used and understood within a particular culture.[105]Because norms for language use are shared by members of a specific group, communicative style also becomes a way of displaying and constructing group identity. Linguistic differences may become salient markers of divisions between social groups, for example, speaking a language with a particular accent may imply membership of an ethnic minority or social class, one's area of origin, or status as a second language speaker. These kinds of differences are not part of the linguistic system, but are an important part of how people use language as a social tool for constructing groups.[106]However, many languages also have grammatical conventions that signal the social position of the speaker in relation to others through the use of registers that are related to social hierarchies or divisions. In many languages, there are stylistic or even grammatical differences between the ways men and women speak, between age groups, or between social classes, just as some languages employ different words depending on who is listening. For example, in the Australian language Dyirbal, a married man must use a special set of words to refer to everyday items when speaking in the presence of his mother-in-law.[107] Some cultures, for example, have elaborate systems of \"social deixis\", or systems of signalling social distance through linguistic means.[108] In English, social deixis is shown mostly through distinguishing between addressing some people by first name and others by surname, and in titles such as \"Mrs.\", \"boy\", \"Doctor\", or \"Your Honor\", but in other languages, such systems may be highly complex and codified in the entire grammar and vocabulary of the language. For instance, in languages of east Asia such as Thai, Burmese, and Javanese, different words are used according to whether a speaker is addressing someone of higher or lower rank than oneself in a ranking system with animals and children ranking the lowest and gods and members of royalty as the highest.[108]Throughout history a number of different ways of representing language in graphic media have been invented. These are called writing systems.The use of writing has made language even more useful to humans. It makes it possible to store large amounts of information outside of the human body and retrieve it again, and it allows communication across distances that would otherwise be impossible. Many languages conventionally employ different genres, styles, and registers in written and spoken language, and in some communities, writing traditionally takes place in an entirely different language than the one spoken. There is some evidence that the use of writing also has effects on the cognitive development of humans, perhaps because acquiring literacy generally requires explicit and formal education.[109]The invention of the first writing systems is roughly contemporary with the beginning of the Bronze Age in the late 4th millennium BC. The Sumerian archaic cuneiform script and the Egyptian hieroglyphs are generally considered to be the earliest writing systems, both emerging out of their ancestral proto-literate symbol systems from 3400\u20133200 BC with the earliest coherent texts from about 2600 BC. It is generally agreed that Sumerian writing was an independent invention; however, it is debated whether Egyptian writing was developed completely independently of Sumerian, or was a case of cultural diffusion. A similar debate exists for the Chinese script, which developed around 1200 BC. The pre-Columbian Mesoamerican writing systems  are generally believed to have had independent origins.[71]All languages change as speakers adopt or invent new ways of speaking and pass them on to other members of their speech community. Language change happens at all levels from the phonological level to the levels of vocabulary, morphology, syntax, and discourse. Even though language change is often initially evaluated negatively by speakers of the language who often consider changes to be \"decay\" or a sign of slipping norms of language usage, it is natural and inevitable.[110]Changes may affect specific sounds or the entire phonological system. Sound change can consist of the replacement of one speech sound or phonetic feature by another, the complete loss of the affected sound, or even the introduction of a new sound in a place where there had been none. Sound changes can be conditioned in which case a sound is changed only if it occurs in the vicinity of certain other sounds. Sound change is usually assumed to be regular, which means that it is expected to apply mechanically whenever its structural conditions are met, irrespective of any non-phonological factors. On the other hand, sound changes can sometimes be sporadic, affecting only one particular word or a few words, without any seeming regularity. Sometimes a simple change triggers a chain shift in which the entire phonological system is affected. This happened in the Germanic languages when the sound change known as Grimm's law affected all the stop consonants in the system. The original consonant *b\u02b0 became /b/ in the Germanic languages, the previous *b in turn became /p/, and the previous *p became /f/. The same process applied to all stop consonants and explains why Italic languages such as Latin have p in words like pater and pisces, whereas Germanic languages, like English, have father and fish.[111]Another example is the Great Vowel Shift in English, which is the reason that the spelling of English vowels do not correspond well to their current pronunciation. This is because the vowel shift brought the already established orthography out of synchronization with pronunciation. Another source of sound change is the erosion of words as pronunciation gradually becomes increasingly indistinct and shortens words, leaving out syllables or sounds. This kind of change caused Latin mea domina to eventually become the French madame and American English ma'am.[112]Change also happens in the grammar of languages as discourse patterns such as idioms or particular constructions become grammaticalized. This frequently happens when words or morphemes erode and the grammatical system is unconsciously rearranged to compensate for the lost element. For example, in some varieties of Caribbean Spanish the final /s/ has eroded away. Since Standard Spanish uses final /s/ in the morpheme marking the second person subject \"you\" in verbs, the Caribbean varieties now have to express the second person using the pronoun t\u00fa. This means that the sentence \"what's your name\" is \u00bfcomo te llamas? [\u02c8komo te \u02c8jamas] in Standard Spanish, but [\u02c8komo \u02c8tu te \u02c8jama] in Caribbean Spanish. The simple sound change has affected both morphology and syntax.[113] Another common cause of grammatical change is the gradual petrification of idioms into new grammatical forms, for example, the way the English \"going to\" construction lost its aspect of movement and in some varieties of English has almost become a full-fledged future tense .Language change may be motivated by \"language internal\" factors, such as changes in pronunciation motivated by certain sounds being difficult to distinguish aurally or to produce, or through patterns of change that cause some rare types of constructions to drift towards more common types.[114] Other causes of language change are social, such as when certain pronunciations become emblematic of membership in certain groups, such as social classes, or with ideologies, and therefore are adopted by those who wish to identify with those groups or ideas. In this way, issues of identity and politics can have profound effects on language structure.[115]One important source of language change is contact and resulting diffusion of linguistic traits between languages. Language contact occurs when speakers of two or more languages or varieties interact on a regular basis.[116] Multilingualism is likely to have been the norm throughout human history and most people in the modern world are multilingual. Before the rise of the concept of the ethno-national state, monolingualism was characteristic mainly of populations inhabiting small islands. But with the ideology that made one people, one state, and one language the most desirable political arrangement, monolingualism started to spread throughout the world. Nonetheless, there are only 250 countries in the world corresponding to some 6000 languages, which means that most countries are multilingual and most languages therefore exist in close contact with other languages.[117]When speakers of different languages interact closely, it is typical for their languages to influence each other. Through sustained language contact over long periods, linguistic traits diffuse between languages, and languages belonging to different families may converge to become more similar. In areas where many languages are in close contact, this may lead to the formation of language areas in which unrelated languages share a number of linguistic features. A number of such language areas have been documented, among them, the Balkan language area, the Mesoamerican language area, and the Ethiopian language area. Also, larger areas such as South Asia, Europe, and Southeast Asia have sometimes been considered language areas, because of widespread diffusion of specific areal features.[118][119]Language contact may also lead to a variety of other linguistic phenomena, including language convergence, borrowing, and relexification . In situations of extreme and sustained language contact, it may lead to the formation of new mixed languages that cannot be considered to belong to a single language family. One type of mixed language called pidgins occurs when adult speakers of two different languages interact on a regular basis, but in a situation where neither group learns to speak the language of the other group fluently. In such a case, they will often construct a communication form that has traits of both languages, but which has a simplified grammatical and phonological structure. The language comes to contain mostly the grammatical and phonological categories that exist in both languages. Pidgin languages are defined by not having any native speakers, but only being spoken by people who have another language as their first language. But if a Pidgin language becomes the main language of a speech community, then eventually children will grow up learning the pidgin as their first language. As the generation of child learners grow up, the pidgin will often be seen to change its structure and acquire a greater degree of complexity. This type of language is generally called a creole language. An example of such mixed languages is Tok Pisin, the official language of Papua New-Guinea, which originally arose as a Pidgin based on English and Austronesian languages; others are Krey\u00f2l ayisyen, the French-based creole language spoken in Haiti, and Michif, a mixed language of Canada, based on the Native American language Cree and French.[120]SIL Ethnologue defines a \"living language\" as \"one that has at least one speaker for whom it is their first language\". The exact number of known living languages varies from 6,000 to 7,000, depending on the precision of one's definition of \"language\", and in particular, on how one defines the distinction between languages and dialects. As of 2016, Ethnologue cataloged 7,097 living human languages.[122] The Ethnologue establishes linguistic groups based on studies of mutual intelligibility, and therefore often includes more categories than more conservative classifications. For example, the Danish language that most scholars consider a single language with several dialects is classified as two distinct languages  by the Ethnologue.[121]According to the Ethnologue, 389 languages .[121]There is no clear distinction between a language and a dialect, notwithstanding a famous aphorism attributed to linguist Max Weinreich that \"a language is a dialect with an army and navy\".[123] For example, national boundaries frequently override linguistic difference in determining whether two linguistic varieties are languages or dialects. Hakka, Cantonese and Mandarin are, for example, often classified as \"dialects\" of Chinese, even though they are more different from each other than Swedish is from Norwegian. Before the Yugoslav civil war, Serbo-Croatian was considered a single language with two dialects, but now Croatian and Serbian are considered different languages and employ different writing systems. In other words, the distinction may hinge on political considerations as much as on cultural differences, distinctive writing systems, or degree of mutual intelligibility.[124]The world's languages can be grouped into language families consisting of languages that can be shown to have common ancestry. Linguists recognize many hundreds of language families, although some of them can possibly be grouped into larger units as more evidence becomes available and in-depth studies are carried out. At present, there are also dozens of language isolates: languages that cannot be shown to be related to any other languages in the world. Among them are Basque, spoken in Europe, Zuni of New Mexico, Pur\u00e9pecha of Mexico, Ainu of Japan, Burushaski of Pakistan, and many others.[125]The language family of the world that has the most speakers is the Indo-European languages, spoken by 46% of the world's population.[126] This family includes major world languages like English, Spanish, Russian, and Hindustani ,[citation needed] and subsequently through the European colonial expansion, which brought the Indo-European languages to a politically and often numerically dominant position in the Americas and much of Africa. The Sino-Tibetan languages are spoken by 20%[126] of the world's population and include many of the languages of East Asia, including Hakka, Mandarin Chinese, Cantonese, and hundreds of smaller languages.[127]Africa is home to a large number of language families, the largest of which is the Niger-Congo language family, which includes such languages as Swahili, Shona, and Yoruba. Speakers of the Niger-Congo languages account for 6.9% of the world's population.[126] A similar number of people speak the Afroasiatic languages, which include the populous Semitic languages such as Arabic, Hebrew language, and the languages of the Sahara region, such as the Berber languages and Hausa.[127]The Austronesian languages are spoken by 5.5% of the world's population and stretch from Madagascar to maritime Southeast Asia all the way to Oceania.[126] It includes such languages as Malagasy, M\u0101ori, Samoan, and many of the indigenous languages of Indonesia and Taiwan. The Austronesian languages are considered to have originated in Taiwan around 3000 BC and spread through the Oceanic region through island-hopping, based on an advanced nautical technology. Other populous language families are the Dravidian languages of South Asia .[127]The areas of the world in which there is the greatest linguistic diversity, such as the Americas, Papua New Guinea, West Africa, and South-Asia, contain hundreds of small language families. These areas together account for the majority of the world's languages, though not the majority of speakers. In the Americas, some of the largest language families include the Quechumaran, Arawak, and Tupi-Guarani families of South America, the Uto-Aztecan, Oto-Manguean, and Mayan of Mesoamerica, and the Na-Dene, Iroquoian, and Algonquian language families of North America. In Australia, most indigenous languages belong to the Pama-Nyungan family, whereas New Guinea is home to a large number of small families and isolates, as well as a number of Austronesian languages.[125]Language endangerment occurs when a language is at risk of falling out of use as its speakers die out or shift to speaking another language. Language loss occurs when the language has no more native speakers, and becomes a dead language. If eventually no one speaks the language at all, it becomes an extinct language. While languages have always gone extinct throughout human history, they have been disappearing at an accelerated rate in the 20th and 21st centuries due to the processes of globalization and neo-colonialism, where the economically powerful languages dominate other languages.[128]The more commonly spoken languages dominate the less commonly spoken languages, so the less commonly spoken languages eventually disappear from populations. The total number of languages in the world is not known. Estimates vary depending on many factors. The consensus is that there are between 6,000[129] and 7,000 languages spoken as of 2010, and that between 50\u201390% of those will have become extinct by the year 2100.[128] The top 20 languages, those spoken by more than 50 million speakers each, are spoken by 50% of the world's population, whereas many of the other languages are spoken by small communities, most of them with less than 10,000 speakers.[128]The United Nations Educational, Scientific and Cultural Organization . Notwithstanding claims that the world would be better off if most adopted a single common lingua franca, such as English or Esperanto, there is a consensus that the loss of languages harms the cultural diversity of the world. It is a common belief, going back to the biblical narrative of the tower of Babel in the Old Testament, that linguistic diversity causes political conflict,[28] but this is contradicted by the fact that many of the world's major episodes of violence have taken place in situations with low linguistic diversity, such as the Yugoslav and American Civil War, or the genocide of Rwanda, whereas many of the most stable political units have been highly multilingual.[130]Many projects aim to prevent or slow this loss by revitalizing endangered languages and promoting education and literacy in minority languages. Across the world, many countries have enacted specific legislation to protect and stabilize the language of indigenous speech communities. A minority of linguists have argued that language loss is a natural process that should not be counteracted, and that documenting endangered languages for posterity is sufficient.[131]", "Literature, most generically, is any body of written works. More restrictively, literature is writing considered to be an art form, or any single writing deemed to have artistic or intellectual value, often due to deploying language in ways that differ from ordinary usage.Its Latin root literatura/litteratura . The concept has changed meaning over time: nowadays it can broaden to have non-written verbal art forms, and thus it is difficult to agree on its origin, which can be paired with that of language or writing itself. Developments in print technology have allowed an ever-growing distribution and proliferation of written works, culminating in electronic literature.Literature can be classified according to whether it is fiction or non-fiction, and whether it is poetry or prose. It can be further distinguished according to major forms such as the novel, short story or drama; and works are often categorized according to historical periods or their adherence to certain aesthetic features or expectations .Definitions of literature have varied over time: it is a \"culturally relative definition\".[1] In Western Europe prior to the 18th century, literature denoted all books and writing.[1] A more restricted sense of the term emerged during the Romantic period, in which it began to demarcate \"imaginative\" writing.[2][3] Contemporary debates over what constitutes literature can be seen as returning to older, more inclusive notions; Cultural studies, for instance, takes as its subject of analysis both popular and minority genres, in addition to canonical works.The value judgment definition of literature considers it to cover exclusively those writings that possess high quality or distinction, forming part of the so-called belles-lettres  when it classifies literature as \"the best expression of the best thought reduced to writing.\"[5] Problematic in this view is that there is no objective definition of what constitutes \"literature\": anything can be literature, and anything which is universally regarded as literature has the potential to be excluded, since value judgments can change over time.[4]The formalist definition is that \"literature\" foregrounds poetic effects; it is the \"literariness\" or \"poetic\" of literature that distinguishes it from ordinary speech or other kinds of writing , as such writing must use language according to particular standards.[8] The problem with the formalist definition is that in order to say that literature deviates from ordinary uses of language, those uses must first be identified; this is difficult because \"ordinary language\" is an unstable category, differing according to social categories and across history.[9]Etymologically, the term derives from Latin literatura/litteratura \"learning, a writing, grammar,\" originally \"writing formed with letters,\" from litera/littera \"letter\".[10] In spite of this, the term has also been applied to spoken or sung texts.[8][11]Poetry is a form of literary art which uses aesthetic and rhythmic qualities of language to evoke meanings in addition to, or in place of, prosaic ostensible meaning.[12] Poetry has traditionally been distinguished from prose by its being set in verse;[a] prose is cast in sentences, poetry in lines; the syntax of prose is dictated by meaning, whereas that of poetry is held across meter or the visual aspects of the poem.[17] Prior to the 19th century, poetry was commonly understood to be something set in metrical lines; accordingly, in 1658 a definition of poetry is \"any kind of subject consisting of Rhythm or Verses\".[12] Possibly as a result of Aristotle's influence , \"poetry\" before the 19th century was usually less a technical designation for verse than a normative category of fictive or rhetorical art.[18] As a form it may pre-date literacy, with the earliest works being composed within and sustained by an oral tradition;[19][20] hence it constitutes the earliest example of literature.Prose is a form of language that possesses ordinary syntax and natural speech rather than rhythmic structure; in which regard, along with its measurement in sentences rather than lines, it differs from poetry.[17][21] On the historical development of prose, Richard Graff notes that \"[In the case of Ancient Greece] recent scholarship has emphasized the fact that formal prose was a comparatively late development, an \"invention\" properly associated with the classical period\".[22]Drama is literature intended for performance.[42] The form is often combined with music and dance, as in opera and musical theater. A play is a subset of this form, referring to the written dramatic work of a playwright that is intended for performance in a theater; it comprises chiefly dialogue between characters, and usually aims at dramatic or theatrical performance rather than at reading. A closet drama, by contrast, refers to a play written to be read rather than to be performed; hence, it is intended that the meaning of such a work can be realized fully on the page.[43] Nearly all drama took verse form until comparatively recently.Greek drama exemplifies the earliest form of drama of which we have substantial knowledge. Tragedy, as a dramatic genre, developed as a performance associated with religious and civic festivals, typically enacting or developing upon well-known historical or mythological themes. Tragedies generally presented very serious themes. With the advent of newer technologies, scripts written for non-stage media have been added to this form. War of the Worlds  in 1938 saw the advent of literature written for radio broadcast, and many works of Drama have been adapted for film or television. Conversely, television, film, and radio literature have been adapted to printed or electronic media.The history of literature follows closely the development of civilization. When defined exclusively as written work, Ancient Egyptian literature,[44] along with Sumerian literature, are considered the world's oldest literatures.[45] The primary genres of the literature of Ancient Egypt\u2014didactic texts, hymns and prayers, and tales\u2014were written almost entirely in verse;[46] while use of poetic devices is clearly recognizable, the prosody of the verse is unknown.[47] The question of whether Sumerian literature was poetry or prose remains unanswered. It did contain at least one feature of poetry , but the style of writing precludes the detection of certain other identifying features.Different historical periods are reflected in literature. National and tribal sagas, accounts of the origin of the world and of customs, and myths which sometimes carry moral or spiritual messages predominate in the pre-urban eras. The epics of Homer, dating from the early to middle Iron age, and the great Indian epics of a slightly later period, have more evidence of deliberate literary authorship, surviving like the older myths through oral tradition for long periods before being written down.Literature in all its forms can be seen as written records, whether the literature itself be factual or fictional, it is still quite possible to decipher facts through things like characters' actions and words or the authors' style of writing and the intent behind the words. The plot is for more than just entertainment purposes; within it lies information about economics, psychology, science, religions, politics, cultures, and social depth. Studying and analyzing literature becomes very important in terms of learning about our[who?] history. Through the study of past literature we[who?] are able to learn about how society has evolved and about the societal norms during each of the different periods all throughout history. This can even help us to understand references made in more modern literature because authors often make references to Greek mythology and other old religious texts or historical moments. Not only is there literature written on each of the aforementioned topics themselves, and how they have evolved throughout history  but one can also learn about these things in fictional works. Authors often include historical moments in their works, like when Lord Byron talks about the Spanish and the French in \"Childe Harold's Pilgrimage: Canto I\"[48] and expresses his opinions through his character Childe Harold. Through literature we are able to continuously uncover new information about history. It is easy to see how all academic fields have roots in literature.[49] Information became easier to pass down from generation to generation once we began to write it down. Eventually everything was written down, from things like home remedies and cures for illness, or how to build shelter to traditions and religious practices. From there people were able to study literature, improve on ideas, further our knowledge, and academic fields such as the medical field or trades could be started. In much the same way as the literature that we study today continue to be updated as we[who?] continue to evolve and learn more and more.As a more urban culture developed, academies provided a means of transmission for speculative and philosophical literature in early civilizations, resulting in the prevalence of literature in Ancient China, Ancient India, Persia and Ancient Greece and Rome. Many works of earlier periods, even in narrative form, had a covert moral or didactic purpose, such as the Sanskrit Panchatantra or the Metamorphoses of Ovid. Drama and satire also developed as urban culture provided a larger public audience, and later readership, for literary production. Lyric poetry  was often the speciality of courts and aristocratic circles, particularly in East Asia where songs were collected by the Chinese aristocracy as poems, the most notable being the Shijing or Book of Songs. Over a long period, the poetry of popular pre-literate balladry and song interpenetrated and eventually influenced poetry in the literary medium.In ancient China, early literature was primarily focused on philosophy, historiography, military science, agriculture, and poetry. China, the origin of modern paper making and woodblock printing, produced the world's first print cultures.[50] Much of Chinese literature originates with the Hundred Schools of Thought period that occurred during the Eastern Zhou Dynasty . Ancient Chinese literature had a heavy emphasis on historiography, with often very detailed court records. An exemplary piece of narrative history of ancient China was the Zuo Zhuan, which was compiled no later than 389 BCE, and attributed to the blind 5th-century BCE historian Zuo Qiuming.In ancient India, literature originated from stories that were originally orally transmitted. Early genres included drama, fables, sutras and epic poetry. Sanskrit literature begins with the Vedas, dating back to 1500\u20131000 BCE, and continues with the Sanskrit Epics of Iron Age India. The Vedas are among the oldest sacred texts. The Samhitas  date to roughly 1500\u20131000 BCE, and the \"circum-Vedic\" texts, as well as the redaction of the Samhitas, date to c. 1000\u2012500 BCE, resulting in a Vedic period, spanning the mid-2nd to mid 1st millennium BCE, or the Late Bronze Age and the Iron Age.[51] The period between approximately the 6th to 1st centuries BC saw the composition and redaction of the two most influential Indian epics, the Mahabharata and the Ramayana, with subsequent redaction progressing down to the 4th century AD. Other major literary works are Ramcharitmanas & Krishnacharitmanas.In ancient Greece, the epics of Homer, who wrote the Iliad and the Odyssey, and Hesiod, who wrote Works and Days and Theogony, are some of the earliest, and most influential, of Ancient Greek literature. Classical Greek genres included philosophy, poetry, historiography, comedies and dramas. Plato and Aristotle authored philosophical texts that are the foundation of Western philosophy, Sappho and Pindar were influential lyric poets, and Herodotus and Thucydides were early Greek historians. Although drama was popular in Ancient Greece, of the hundreds of tragedies written and performed during the classical age, only a limited number of plays by three authors still exist: Aeschylus, Sophocles, and Euripides. The plays of Aristophanes provide the only real examples of a genre of comic drama known as Old Comedy, the earliest form of Greek Comedy, and are in fact used to define the genre.[52]Roman histories and biographies anticipated the extensive mediaeval literature of lives of saints and miraculous chronicles, but the most characteristic form of the Middle Ages was the romance, an adventurous and sometimes magical narrative with strong popular appeal. Controversial, religious, political and instructional literature proliferated during the Renaissance as a result of the invention of printing, while the mediaeval romance developed into a more character-based and psychological form of narrative, the novel, of which early and important examples are the Chinese Monkey and the German Faust books.In the Age of Reason philosophical tracts and speculations on history and human nature integrated literature with social and political developments. The inevitable reaction was the explosion of Romanticism in the later 18th century which reclaimed the imaginative and fantastical bias of old romances and folk-literature and asserted the primacy of individual experience and emotion. But as the 19th century went on, European fiction evolved towards realism and naturalism, the meticulous documentation of real life and social trends. Much of the output of naturalism was implicitly polemical, and influenced social and political change, but 20th century fiction and drama moved back towards the subjective, emphasizing unconscious motivations and social and environmental pressures on the individual. Writers such as Proust, Eliot, Joyce, Kafka and Pirandello exemplify the trend of documenting internal rather than external realities.Genre fiction also showed it could question reality in its 20th century forms, in spite of its fixed formulas, through the enquiries of the skeptical detective and the alternative realities of science fiction. The separation of \"mainstream\" and \"genre\" forms  continued to blur during the period up to our own times. William Burroughs, in his early works, and Hunter S. Thompson expanded documentary reporting into strong subjective statements after the second World War, and post-modern critics have disparaged the idea of objective realism in general.There are numerous awards recognizing achievement and contribution in literature. Given the diversity of the field, awards are typically limited in scope, usually on: form, genre, language, nationality and output .[53]The Nobel Prize in Literature was one of the six Nobel Prizes established by the will of Alfred Nobel in 1895,[54] and is awarded to an author on the basis of their body of work, rather than to, or for, a particular work itself.[b] Other literary prizes for which all nationalities are eligible include: the Neustadt International Prize for Literature, the Man Booker International Prize and the Franz Kafka Prize.An essay consists of a discussion of a topic from an author's personal point of view, exemplified by works by Michel de Montaigne or by Charles Lamb.Genres related to the essay may include the memoir and the epistle.Philosophical, historical, journalistic, and scientific writings are traditionally ranked as literature. They offer some of the oldest prose writings in existence; novels and prose stories earned the names \"fiction\" to distinguish them from factual writing or nonfiction, which writers historically have crafted in prose.As advances and specialization have made new scientific research inaccessible to most audiences, the \"literary\" nature of science writing has become less pronounced over the last two centuries. Now, science appears mostly in journals. Scientific works of Aristotle, Copernicus, and Newton still exhibit great value, but since the science in them has largely become outdated, they no longer serve for scientific instruction. Yet, they remain too technical to sit well in most programs of literary study. Outside of \"history of science\" programs, students rarely read such works.Philosophy has become an increasingly academic discipline. More of its practitioners lament this situation than occurs with the sciences; nonetheless most new philosophical work appears in academic journals. Major philosophers through history\u2014Plato, Aristotle, Socrates, Augustine, Descartes, Kierkegaard, Nietzsche\u2014have become as canonical as any writers. Some recent philosophy works are argued to merit the title \"literature\", but much of it does not, and some areas, such as logic, have become extremely technical to a degree similar to that of mathematics.Literature allows readers to access intimate emotional aspects of a person's character that would not be obvious otherwise.[55] It benefits the psychological development and understanding of the reader. For example, it allows a person to access emotional states from which the person has distanced himself or herself. An entry written by D. Mitchell featured in The English Journal explains how the author used young adult literature in order to re-experience the emotional psychology she experienced as a child which she describes as a state of \"wonder\".[56]Hogan also explains that the temporal and emotional amount which a person devotes to understanding a character's situation in literature allows literature to be considered \"ecological[ly] valid in the study of emotion\".[57] This can be understood in the sense that literature unites a large community by provoking universal emotions. It also allows readers to access cultural aspects that they are not exposed to thus provoking new emotional experiences.[58] Authors choose literary device according to what psychological emotion he or she is attempting to describe, thus certain literary devices are more emotionally effective than others.[59]Furthermore, literature is being more popularly regarded as a psychologically effective research tool. It can be considered a research tool because it allows psychologists to discover new psychological aspects and it also allows psychologists to promote their theories.[60] For example, the print capacity available for literature distribution has allowed psychological theories such as Maslow's Hierarchy of Needs to be universally recognized.Maslow's \"Third Force Psychology Theory\" even allows literary analysts to critically understand how characters reflect the culture and the history in which they are contextualized. It also allows analysts to understand the author's intended message and to understand the author's psychology.[61] The theory suggests that human beings possess a nature within them that demonstrates their true \"self\" and it suggests that the fulfillment of this nature is the reason for living. It also suggests that neurological development hinders actualizing the nature because a person becomes estranged from his or her true self.[62] Therefore, literary devices reflect a character's and an author's natural self.[59] In his \"Third Force Psychology and the Study of Literature\", Paris argues \"D.H. Lawrence's 'pristine unconscious' is a metaphor for the real self\".[63] Thus Literature is a reputable tool that allows readers to develop and apply critical reasoning to the nature of emotions.A significant portion of historical writing ranks as literature, particularly the genre known as creative nonfiction, as can a great deal of journalism, such as literary journalism. However, these areas have become extremely large, and often have a primarily utilitarian purpose: to record data or convey immediate information. As a result, the writing in these fields often lacks a literary quality, although it oftenhas that quality. Major \"literary\" historians include Herodotus, Thucydides and Procopius, all of whom count as canonical literary figures.Law offers more ambiguity. Some writings of Plato and Aristotle, the law tables of Hammurabi of Babylon, or even the early parts of the Bible could be seen as legal literature. Roman civil law as codified in the Corpus Juris Civilis during the reign of Justinian I of the Byzantine Empire has a reputation as significant literature. The founding documents of many countries, including Constitutions and Law Codes, can count as literature.Literary genre is a mode of categorizing literature. The term originates from French, designating a proposed type or class.[64] However, such classes are subject to change, and have been used in different ways in different periods and traditions.A literary technique or literary device can be used by authors in order to enhance the written framework of a piece of literature, and produce specific effects. Literary techniques encompass a wide range of approaches to crafting a work: whether a work is narrated in first-person or from another perspective, whether to use a traditional linear narrative or a nonlinear narrative, or the choice of literary genre, are all examples of literary technique. They may indicate to a reader that there is a familiar structure and presentation to a work, such as a conventional murder-mystery novel; or, the author may choose to experiment with their technique to surprise the reader.In this way, use of a technique can lead to the development of a new genre, as was the case with one of the first modern novels, Pamela by Samuel Richardson. Pamela is written as a collection of letter-writing correspondence, called \"epistolary technique\"; by using this technique, Pamela strengthened the tradition of the epistolary novel, a genre which had been practiced for some time already but without the same acclaim.Literary technique is distinguished from literary device, as military strategy is distinguished from military tactics. Devices are specific constructions within the narrative that make it effective. Examples include metaphor, simile, ellipsis, narrative motifs, and allegory. Even simple word play functions as a literary device. The narrative mode may be considered a literary device, such as the use of stream-of-consciousness narrative.Literary criticism implies a critique and evaluation of a piece of literature and, in some cases, it is used to improve a work in progress or a classical piece, as with an ongoing theater production. Literary editors can serve a similar purpose for the authors with whom they work. There are many types of literary criticism and each can be used to critique a piece in a different way or critique a different aspect of a piece.Literary works have been protected by copyright law from unauthorized reproduction since at least 1710.[65] Literary works are defined by copyright law to mean any work, other than a dramatic or musical work, which is written, spoken or sung, and accordingly includes  a database.Literary works are not limited to works of literature, but include all works expressed in print or writing .[66]CitationsBibliographyMajor formsHistory"], "Philosophy": ["Philosophy ?[12] Do humans have free will?[13]Historically, \"philosophy\" encompassed any body of knowledge.[14] From the time of Ancient Greek philosopher Aristotle to the 19th century, \"natural philosophy\" encompassed astronomy, medicine, and physics.[15] For example, Newton's 1687 Mathematical Principles of Natural Philosophy later became classified as a book of physics. In the 19th century, the growth of modern research universities led academic philosophy and other disciplines to professionalize and specialize.[16][17] In the modern era, some investigations that were traditionally part of philosophy became separate academic disciplines, including psychology, sociology, linguistics, and economics.Other investigations closely related to art, science, politics, or other pursuits remained part of philosophy. For example, is beauty objective or subjective?[18][19] Are there many scientific methods or just one?[20] Is political utopia a hopeful dream or hopeless fantasy?[21][22][23] Major sub-fields of academic philosophy include metaphysics , ethics, aesthetics, political philosophy, logic, philosophy of science, and the history of Western philosophy.Since the 20th century, professional philosophers contribute to society primarily as professors. However, many of those who study philosophy in undergraduate or graduate programs contribute in the fields of law, journalism, politics, religion, science, business and various art and entertainment activities.[26]Traditionally, the term \"philosophy\" referred to any body of knowledge.[14][27] In this sense, philosophy is closely related to religion, mathematics, natural science, education and politics. Newton's 1687 \"Mathematical Principles of Natural Philosophy\" is classified in the 2000s as a book of physics; he used the term \"natural philosophy\" because it used to encompass disciplines that later became associated with sciences such as astronomy, medicine and physics.[15]In Classical antiquity, Philosophy was traditionally divided into three major branches:This division is not obsolete but has changed. Natural philosophy has split into the various natural sciences, especially astronomy, physics, chemistry, biology, and cosmology. Moral philosophy has birthed the social sciences, but still includes value theory . Metaphysical philosophy has birthed formal sciences such as logic, mathematics and philosophy of science, but still includes epistemology, cosmology and others.Many philosophical debates that began in ancient times are still debated today. Colin McGinn and others claim that no philosophical progress has occurred during that interval.[29] Chalmers and others, by contrast, see progress in philosophy similar to that in science,[30] while Talbot Brewer argued that \"progress\" is the wrong standard by which to judge philosophical activity.[31]In one general sense, philosophy is associated with wisdom, intellectual culture and a search for knowledge. In that sense, all cultures and literate societies ask philosophical questions such as \"how are we to live\" and \"what is the nature of reality\". A broad and impartial conception of philosophy then, finds a reasoned inquiry into such matters as reality, morality and life in all world civilizations.[32]Western philosophy is the philosophical tradition of the Western world and dates to Pre-Socratic thinkers who were active in Ancient Greece in the 6th century BCE such as Thales , and Modern philosophy.The Ancient era was dominated by Greek philosophical schools which arose out of the various pupils of Socrates, such as Plato who founded the Platonic Academy, and was one of the most influential Greek thinkers for the whole of Western thought.[35] Plato's student Aristotle was also extremely influential, founding the Peripatetic school. Other traditions include Cynicism, Stoicism, Greek Skepticism and Epicureanism. Important topics covered by the Greeks included metaphysics . With the rise of the Roman empire, Greek philosophy was also increasingly discussed in Latin by Romans such as Cicero and Seneca.Medieval philosophy .[36] Following the rise of natural science, Modern philosophy was concerned with developing a secular and rational foundation for knowledge and moved away from traditional structures of authority such as religion, scholastic thought and the Church. Major modern philosophers include Spinoza, Leibniz, Locke, Berkeley, Hume, and Kant.[37][38][39] 19th-century philosophy is influenced by the wider movement termed the Enlightenment, and includes figures such as Hegel a key figure in German idealism, Kierkegaard who developed the foundations for existentialism, Nietzsche a famed anti-Christian, J.S. Mill who promoted Utilitarianism, Karl Marx who developed the foundations for Communism and the American William James. The 20th century saw the split between Analytic philosophy and Continental philosophy, as well as philosophical trends such as Phenomenology, Existentialism, Logical Positivism, Pragmatism and the Linguistic turn.The regions of the fertile Crescent, Iran and Arabia are home to the earliest known philosophical Wisdom literature and is today mostly dominated by Islamic culture. Early wisdom literature from the fertile crescent was a genre which sought to instruct people on ethical action, practical living and virtue through stories and proverbs. In Ancient Egypt, these texts were known as sebayt , Jewish existentialism and Reform Judaism.Pre-Islamic Iranian philosophy begins with the work of Zoroaster, one of the first promoters of monotheism and of the dualism between good and evil. This dualistic cosmogony influenced later Iranian developments such as Manichaeism, Mazdakism, and Zurvanism.After the Muslim conquests, Early Islamic philosophy developed the Greek philosophical traditions in new innovative directions. This Islamic Golden Age influenced European intellectual developments. The two main currents of early Islamic thought are Kalam which focuses on Islamic theology and Falsafa which was based on Aristotelianism and Neoplatonism. The work of Aristotle was very influential among the falsafa such as al-Kindi . Others such as Al-Ghazali were highly critical of the methods of the Aristotelian falsafa. Islamic thinkers also developed a scientific method, experimental medicine, a theory of optics and a legal philosophy. Ibn Khaldun was an influential thinker in philosophy of history.In Iran several schools of Islamic philosophy continued to flourish after the Golden Age and include currents such as Illuminationist philosophy, Sufi philosophy, and Transcendent theosophy. The 19th and 20th century Arab world saw the Nahda  movement which influenced contemporary Islamic philosophy.Indian philosophy  and logic and investigated topics such as metaphysics, ethics, hermeneutics and soteriology. Indian philosophy also covered topics such as political philosophy as seen in the Arthashastra c. 4th century BCE and the philosophy of love as seen in the Kama Sutra.The commonly named six orthodox schools arose sometime between the start of the Common Era and the Gupta Empire.[43] These Hindu schools developed what has been called the \"Hindu synthesis\" merging orthodox Brahmanical and unorthodox elements from Buddhism and Jainism as a way to respond to the unorthodox challenges.[44] Hindu thought also spread east to the Indonesian Srivijaya empire and the Cambodian Khmer Empire.Later developments include the development of Tantra and Iranian-Islamic influences. Buddhism mostly disappeared from India after the Muslim conquest in the Indian subcontinent, surviving in the Himalayan regions and south India.[45] The early modern period saw the flourishing of Navya-Ny\u0101ya .[46]The modern era saw the rise of Hindu nationalism, Hindu reform movements and Neo-Vedanta  whose major proponents included Vivekananda, Mahatma Gandhi and Aurobindo and who for the first time promoted the idea of a unified \"Hinduism\". Due to the influence of British colonialism, much modern Indian philosophical work was in English and includes thinkers such as Radhakrishnan, Krishna Chandra Bhattacharya, Bimal Krishna Matilal and M. Hiriyanna.[47]Buddhist philosophy begins with the thought of Gautama Buddha , and a certain skepticism about metaphysical questions.Later Buddhist philosophical traditions developed complex phenomenological psychologies termed 'Abhidharma'. Mahayana philosophers such as Nagarjuna and Vasubandhu developed the theories of Shunyata , a form of phenomenology or transcendental idealism. The Dign\u0101ga school of Pram\u0101\u1e47a promoted a complex form of epistemology and Buddhist logic. After the disappearance of Buddhism from India, these philosophical traditions continued to develop in the Tibetan Buddhist, East Asian Buddhist and Theravada Buddhist traditions. The modern period saw the rise of Buddhist modernism and Humanistic Buddhism under Western influences and the development of a Western Buddhism with influences from modern psychology and Western philosophy.East Asian philosophical thought began in Ancient China, and Chinese philosophy begins during the Western Zhou Dynasty and the following periods after its fall when the \"Hundred Schools of Thought\" flourished  became the dominant school of thought, and was promoted by the imperial state.In the Modern era, Chinese thinkers incorporated ideas from Western philosophy. Chinese Marxist philosophy developed under the influence of Mao Zedong, while a Chinese pragmatism under Hu Shih and New Confucianism's rise was influenced by Xiong Shili. Modern Japanese thought meanwhile developed under strong Western influences such as the study of Western Sciences  and the modernist Meirokusha intellectual society which drew from European enlightenment thought. The 20th century saw the rise of State Shinto and also Japanese nationalism. The Kyoto School, an influential and unique Japanese philosophical school developed from Western phenomenology and Medieval Japanese Buddhist philosophy such as that of Dogen.African philosophy is philosophy produced by African people, philosophy that presents African worldviews, ideas and themes, or philosophy that uses distinct African philosophical methods. Modern African thought has been occupied with Ethnophilosophy, with defining the very meaning of African philosophy and its unique characteristics and what it means to be African.[50] During the 17th century, Ethiopian philosophy developed a robust literary tradition as exemplified by Zera Yacob. Another early African philosopher was Anton Wilhelm Amo  who became a respected philosopher in Germany. Distinct African philosophical ideas include Ujamaa, the Bantu idea of 'Force', N\u00e9gritude, Pan-Africanism and Ubuntu. Contemporary African thought has also seen the development of Professional philosophy and of Africana philosophy, the philosophical literature of the African diaspora which includes currents such as black existentialism by African-Americans. Modern African thinkers have been influenced by Marxism, African-American literature, Critical theory, Critical race theory, Postcolonialism and Feminism.Indigenous American philosophy is the philosophy of the Indigenous people of the Americas. There is a wide variety of beliefs and traditions among these different American cultures. Among some of the Native Americans in the United States there is a belief in a metaphysical principle called the \"Great Mystery\"  as well as by reason.\"[51] The practices to access these transcendental experiences are termed Shamanism. Another feature of the indigenous American worldviews was their extension of ethics to non-human animals and plants.[51][52]In Mesoamerica, Aztec philosophy was an intellectual tradition developed by individuals called Tlamatini  which was based on moderation and balance in all actions as in the Nahua proverb \"the middle good is necessary\".[54]The Inca civilization also had an elite class of philosopher-scholars termed the Amawtakuna who were important in the Inca education system as teachers of religion, tradition, history and ethics. Key concepts of Andean thought are Yanantin and Masintin which involve a theory of \u201ccomplementary opposites\u201d that sees polarities  as interdependent parts of a harmonious whole.[55]Philosophical questions can be grouped into categories. These groupings allow philosophers to focus on a set of similar topics and interact with other thinkers who are interested in the same questions. The groupings also make philosophy easier for students to approach. Students can learn the basic principles involved in one aspect of the field without being overwhelmed with the entire set of philosophical theories.Various sources present different categorical schemes. The categories adopted in this article aim for breadth and simplicity.These five major branches can be separated into sub-branches and each sub-branch contains many specific fields of study.[56]These divisions are neither exhaustive, nor mutually exclusive.  Furthermore, these philosophical inquiries sometimes overlap with each other and with other inquiries such as science, religion or mathematics.[58]Metaphysics is the study of the most general features of reality, such as existence, time, objects and their properties, wholes and their parts, events, processes and causation and the relationship between mind and body. Metaphysics includes cosmology, the study of the world in its entirety and ontology, the study of being.A major point of debate is between realism, which holds that there are entities that exist independently of their mental perception and idealism, which holds that reality is mentally constructed or otherwise immaterial. Metaphysics deals with the topic of identity. Essence is the set of attributes that make an object what it fundamentally is and without which it loses its identity while accident is a property that the object has, without which the object can still retain its identity. Particulars are objects that are said to exist in space and time, as opposed to abstract objects, such as numbers, and universals, which are properties held by multiple particulars, such as redness or a gender. The type of existence, if any, of universals and abstract objects is an issue of debate.Epistemology is the study of knowledge . Epistemologists examine these and ask whether knowledge is really possible.Skepticism is the position which doubts claims to knowledge. The regress argument, a fundamental problem in epistemology, occurs when, in order to completely prove any statement, its justification itself needs to be supported by another justification. This chain can go on forever, called infinitism, it can eventually rely on basic beliefs that are left unproven, called foundationalism, or it can go in a circle so that a statement is included in its own chain of justification, called coherentism.Rationalism is the emphasis on reasoning as a source of knowledge. It is associated with a priori knowledge, which is independent of experience, such as math and logical deduction. Empiricism is the emphasis on observational evidence via sensory experience as the source of knowledge.Among the numerous topics within metaphysics and epistemology, broadly construed are:Value theory  is the major branch of philosophy that addresses topics such as goodness, beauty and justice. Value theory includes ethics, aesthetics, political philosophy, feminist philosophy, philosophy of law and more.Ethics, or \"moral philosophy\", studies and considers what is good and bad conduct, right and wrong values, and good and evil. Its primary investigations include how to live a good life and identifying standards of morality. It also includes meta-investigations about whether a best way to live or related standards exists. The main branches of ethics are normative ethics, meta-ethics and applied ethics.A major area of debate involves consequentialism, in which actions are judged by the potential results of the act, such as to maximize happiness, called utilitarianism, and deontology, in which actions are judged by how they adhere to principles, irrespective of negative ends.Aesthetics is the \"critical reflection on art, culture and nature.\"[60][61] It addresses the nature of art, beauty and taste, enjoyment, emotional values, perception and with the creation and appreciation of beauty.[62][63] It is more precisely defined as the study of sensory or sensori-emotional values, sometimes called judgments of sentiment and taste.[64] Its major divisions are art theory, literary theory, film theory and music theory. An example from art theory is to discern the set of principles underlying the work of a particular artist or artistic movement such as the Cubist aesthetic.[65] The philosophy of film analyzes films and filmmakers for their philosophical content and explores film  as a medium for philosophical reflection and expression.[citation needed]Political philosophy is the study of government and the relationship of individuals  to communities including the state. It includes questions about justice, law, property and the rights and obligations of the citizen. Politics and ethics are traditionally linked subjects, as both discuss the question of how people should live together.Other branches of value theory:Many academic disciplines generated philosophical inquiry. The relationship between \"X\" and the \"philosophy of X\" is debated. Richard Feynman argued that the philosophy of a topic is irrelevant to its primary study, saying that \"philosophy of science is as useful to scientists as ornithology is to birds.\" Curtis White, by contrast, argued that philosophical tools are essential to humanities, sciences and social sciences.[66]The topics of philosophy of science are numbers, symbols and the formal methods of reasoning as employed in the social sciences and natural sciences.Logic is the study of reasoning and argument. An argument is \"a connected series of statements intended to establish a proposition.\" The connected series of statements are \"premises\" and the proposition is the conclusion. For example:Deductive reasoning is when, given certain premises, conclusions are unavoidably implied. Rules of inference are used to infer conclusions such as, modus ponens, where given \u201cA\u201d and \u201cIf A then B\u201d, then \u201cB\u201d must be concluded.Because sound reasoning is an essential element of all sciences,[67] social sciences and humanities disciplines, logic became a formal science. Sub-fields include mathematical logic, philosophical logic, Modal logic, computational logic and non-classical logics. A major question in the philosophy of mathematics is whether mathematical entities are objective and discovered, called mathematical realism, or invented, called mathematical antirealism.This branch explores the foundations, methods, history, implications and purpose of science. Many of its sub-divisions correspond to a specific branch of science. For example, philosophy of biology deals specifically with the metaphysical, epistemological and ethical issues in the biomedical and life sciences. The philosophy of mathematics studies the philosophical assumptions, foundations and implications of mathematics.Some philosophers specialize in one or more historical periods. The history of philosophy .Hegel's Lectures on the Philosophy of History influenced many philosophers to interpret truth in light of history, a view called historicism.Philosophy of religion deals with questions that involve religion and religious ideas from a philosophically neutral perspective .[68] Traditionally, religious questions were not seen as a separate field from philosophy proper, the idea of a separate field only arose in the 19th century.[69]Issues include the existence of God, the relationship between reason and faith, questions of religious epistemology, the relationship between religion and science, how to interpret religious experiences, questions about the possibility of an afterlife, the problem of religious language and the existence of souls and responses to religious pluralism and diversity.Some philosophers specialize in one or more of the major philosophical schools, such as Continental philosophy, Analytical philosophy, Thomism, Asian philosophy or African philosophy.A variety of other academic and non-academic approaches have been explored.The ideas conceived by a society have profound repercussions on what actions the society performs. Weaver argued that ideas have consequences. Philosophy yields applications such as those in ethics \u2013 applied ethics in particular \u2013 and political philosophy. The political and economic philosophies of Confucius, Sun Tzu, Chanakya, Ibn Khaldun, Ibn Rushd, Ibn Taymiyyah, Machiavelli, Leibniz, Hobbes, Locke, Rousseau, Adam Smith, John Stuart Mill, Marx, Tolstoy, Gandhi and Martin Luther King Jr. have been used to shape and justify governments and their actions. Progressive education as championed by Dewey had a profound impact on 20th century US educational practices. Descendants of this movement include efforts in philosophy for children, which are part of philosophy education. Clausewitz's political philosophy of war has had a profound effect on statecraft, international politics and military strategy in the 20th century, especially around World War II. Logic is important in mathematics, linguistics, psychology, computer science and computer engineering.Other important applications can be found in epistemology, which aid in understanding the requisites for knowledge, sound evidence and justified belief . The philosophy of science discusses the underpinnings of the scientific method and has affected the nature of scientific investigation and argumentation. Philosophy thus has fundamental implications for science as a whole. For example, the strictly empirical approach of B. F. Skinner's behaviorism affected for decades the approach of the American psychological establishment. Deep ecology and animal rights examine the moral situation of humans as occupants of a world that has non-human occupants to consider also. Aesthetics can help to interpret discussions of music, literature, the plastic arts and the whole artistic dimension of life. In general, the various philosophies strive to provide practical activities with a deeper understanding of the theoretical or conceptual underpinnings of their fields.Some of those who study philosophy become professional philosophers, typically by working as professors who teach, research and write in academic institutions.[70] However, most students of academic philosophy later contribute to law, journalism, religion, sciences, politics, business, or various arts.[26][71] For example, public figures who have degrees in philosophy include comedians Steve Martin and Ricky Gervais, filmmaker Terrence Malick, Pope John Paul II, Wikipedia co-founder Larry Sanger, technology entrepreneur Peter Thiel, Supreme Court Justice Stephen Bryer and vice presidential candidate Carly Fiorina.[72][73]Recent efforts to avail the general public to the work and relevance of philosophers include the million-dollar Berggruen Prize, first awarded to Charles Taylor in 2016.[74]Germany was the first country to professionalize philosophy. At the end of 1817, Hegel was the first philosopher to be appointed Professor by the State, namely by the Prussian Minister of Education, as an effect of Napoleonic reform in Prussia. In the United States, the professionalisation grew out of reforms to the American higher-education system largely based on the German model.Within the last century, philosophy has increasingly become a professional discipline practiced within universities, like other academic disciplines. Accordingly, it has become less general and more specialized. In the view of one prominent recent historian: \"Philosophy has become a highly organized discipline, done by specialists primarily for other specialists. The number of philosophers has exploded, the volume of publication has swelled, and the subfields of serious philosophical investigation have multiplied. Not only is the broad field of philosophy today far too vast to be embraced by one mind, something similar is true even of many highly specialized subfields.\"[75] Some philosophers argue that this professionalization has negatively affected the discipline.[76]The end result of professionalization for philosophy has meant that work being done in the field is now almost exclusively done by university professors holding a doctorate in the field publishing in highly technical, peer-reviewed journals. While it remains common among the population at large for a person to have a set of religious, political or philosophical views that they consider their \"philosophy\", these views are rarely informed by or connected to the work being done in professional philosophy today. Furthermore, unlike many of the sciences for which there has come to be a healthy industry of books, magazines, and television shows meant to popularize science and communicate the technical results of a scientific field to the general populace, works by professional philosophers directed at an audience outside the profession remain rare. Philosopher Michael Sandel's book Justice: What's the Right Thing to Do? and Harry Frankfurt's On Bullshit are examples of works that hold the uncommon distinction of having been written by professional philosophers but directed at and ultimately popular among a broader audience of non-philosophers. Both works became 'New York Times best sellers.Many inquiries outside of academia are philosophical in the broad sense. Novelists, playwrights, filmmakers, and musicians, as well as scientists and others engage in recognizably philosophical activity.Ayn Rand is the foremost example of an intellectual working contemporaneously with contemporary philosophy but whose contributions were not made within the professional discipline of \"philosophy\": \"For all her [Ayn Rand's] popularity, however, only a few professional philosophers have taken her work seriously. As a result, most of the serious philosophical work on Rand has appeared in non-academic, non-peer-reviewed journals, or in books, and the bibliography reflects this fact.\"[15]Also working from outside the profession were philosophers such as Gerd B. Achenbach  who have proposed since the 1980s various forms of philosophical counseling claiming to bring Socratic dialogues back to life in a quasi-psychotherapeutic framework.Pierre Hadot is famous for his analysis on the conception of philosophy during Greco-Roman antiquity. Hadot identified and analyzed the \"spiritual exercises\" used in ancient philosophy . By \"spiritual exercises\" Hadot means \"practices ... intended to effect a modification and a transformation in the subjects who practice them.[6] The philosophy teacher's discourse could be presented in such a way that the disciple, as auditor, reader, or interlocutor, could make spiritual progress and transform himself within.\"[7] Hadot shows that the key to understanding the original philosophical impulse is to be found in Socrates. What characterizes Socratic therapy above all is the importance given to living contact between human beings. Hadot's recurring theme is that philosophy in antiquity was characterized by a series of spiritual exercises intended to transform the perception, and therefore the being, of those who practice it; that philosophy is best pursued in real conversation and not through written texts and lectures; and that philosophy, as it is taught in universities today, is for the most part a distortion of its original, therapeutic impulse. He brings these concerns together in What Is Ancient Philosophy?,[7] which has been critically reviewed.[8]Although men have generally dominated philosophical discourse, women have engaged in philosophy throughout history. Women philosophers have contributed since ancient times\u2013notably Hipparchia of Maroneia . More were accepted during the ancient, medieval and modern eras, but no women philosophers became part the Western canon until the 20th and 21st century, when some sources indicate that Susanne Langer, Hannah Arendt and Simone de Beauvoir entered the canon.[77][78]In the early 1800s, some colleges and universities in the UK and US began admitting women, producing more female academics. Nevertheless, U.S. Department of Education reports from the 1990s indicate that few women ended up in philosophy, and that philosophy is one of the least gender-proportionate fields in the humanities.[79] In 2014, Inside Higher Education described the philosophy \"...discipline's own long history of misogyny and sexual harassment\" of women students and professors.[80] University of Sheffield philosophy professor Jennifer Saul stated in 2015 that women are \"...leaving philosophy after being harassed, assaulted, or retaliated against.\"[81]In the early 1990s, the Canadian Philosophical Association noted a gender imbalance and gender bias in the academic field of philosophy.[82] In June 2013, a US sociology professor stated that \"out of all recent citations in four prestigious philosophy journals, female authors comprise just 3.6 percent of the total.\"[83] Susan Price argues that the philosophical \"...canon remains dominated by white males \u2013 the discipline that...still hews to the myth that genius is tied to gender.\"[84] Morgan Thompson suggests that discrimination, differences in abilities, grade differences and the lack of role models in philosophy could be potential factors for the gender gap.[85] According to Saul, \"[p]hilosophy, the oldest of the humanities, is also the malest . While other areas of the humanities are at or near gender parity, philosophy is actually more overwhelmingly male than even mathematics.\"[86]In 2000, the Open Court Publishing Company began publishing a series of books on philosophy and popular culture. Each book consists of essays written by philosophers for general readers. The books \"explore the meanings, concepts and puzzles within television shows, movies, music and other icons of popular culture\"[87] analyzing topics such as the TV shows Seinfeld and The Simpsons, The Matrix and Star Wars movies and related media and new technological developments such as the iPod and Facebook. Their most recent publication  is titled Louis C.K. and Philosophy; its subject is the comedian Louis C.K..The Matrix makes numerous references to philosophy including Buddhism, Vedanta, Advaita Hinduism, Christianity, Messianism, Judaism, Gnosticism, existentialism and nihilism. The film's premise resembles Plato's Allegory of the cave, Descartes's evil demon, Kant's reflections on the Phenomenon versus the Ding an sich, Zhuangzi's \"Zhuangzi dreamed he was a butterfly\", Marxist social theory and the brain in a vat thought experiment. Many references to Baudrillard's Simulacra and Simulation appear in the film, although Baudrillard himself considered this a misrepresentation.[88]"], "Theology": ["Theology is the critical study of the nature of the divine. It is taught as an academic discipline, typically in universities and seminaries.[1]Theology translates into English from the Greek theologia  had evolved by 1362.[3] The sense the word has in English depends in large part on the sense the Latin and Greek equivalents had acquired in patristic and medieval Christian usage, although the English term has now spread beyond Christian contexts.Augustine of Hippo defined the Latin equivalent, theologia, as \"reasoning or discussion concerning the Deity\";[4] Richard Hooker defined \"theology\" in English as \"the science of things divine\".[5] The term can, however, be used for a variety of different disciplines or fields of study.[6]Theology begins with the assumption that the divine exists in some form, such as in physical, supernatural, mental, or social realities, and that evidence for and about it may be found via personal spiritual experiences and/or historical records of such experiences as documented by others. The study of these assumptions is not part of theology proper but is found in the philosophy of religion, and increasingly through the psychology of religion and neurotheology. Theology then aims to structure and understand these experiences and concepts, and to use them to derive normative prescriptions for how to live our lives.Theologians use various forms of analysis and argument  to help understand, explain, test, critique, defend or promote any myriad of religious topics. As in philosophy of ethics and case law, arguments often assume the existence of previously resolved questions, and develop by making analogies from them to draw new inferences in new situations.The study of theology may help a theologian more deeply understand their own religious tradition,[7] another religious tradition,[8] or it may enable them to explore the nature of divinity without reference to any specific tradition. Theology may be used to propagate,[9] reform,[10] or justify a religious tradition or it may be used to compare,[11] challenge  a religious tradition or world-view. Theology might also help a theologian to address some present situation or need through a religious tradition,[12] or to explore possible ways of interpreting the world.[13]Greek theologia  was used with the meaning \"discourse on god\" in the fourth century BC by Plato in The Republic, Book ii, Ch. 18.[14] Aristotle divided theoretical philosophy into mathematike, physike and theologike, with the last corresponding roughly to metaphysics, which, for Aristotle, included discourse on the nature of the divine.[15]Drawing on Greek Stoic sources, the Latin writer Varro distinguished three forms of such discourse: mythical .[16]Theologos, closely related to theologia, appears once in some biblical manuscripts, in the heading to the Book of Revelation: apokalypsis ioannoy toy theologoy, \"the revelation of John the theologos\". There, however, the word refers not to John the \"theologian\" in the modern English sense of the word but\u2014using a slightly different sense of the root logos, meaning not \"rational discourse\" but \"word\" or \"message\"\u2014one who speaks the words of God, logoi toy theoy.[17]Some Latin Christian authors, such as Tertullian and Augustine, followed Varro's threefold usage,[18] though Augustine also used the term more simply to mean 'reasoning or discussion concerning the deity'[4]In patristic Greek Christian sources, theologia could refer narrowly to devout and inspired knowledge of, and teaching about, the essential nature of God.[19]The Latin author Boethius, writing in the early 6th century, used theologia to denote a subdivision of philosophy as a subject of academic study, dealing with the motionless, incorporeal reality .[20] Boethius' definition influenced medieval Latin usage.[21]In scholastic Latin sources, the term came to denote the rational study of the doctrines of the Christian religion, or .[22]In the Renaissance, especially with Florentine Platonist apologists of Dante's poetics, the distinction between \"poetic theology\"  and \"revealed\" or Biblical theology serves as steppingstone for a revival of philosophy as independent of theological authority.It is in this last sense, theology as an academic discipline involving rational study of Christian teaching, that the term passed into English in the fourteenth century,[23] although it could also be used in the narrower sense found in Boethius and the Greek patristic authors, to mean rational study of the essential nature of God \u2013 a discourse now sometimes called Theology Proper.[24]From the 17th century onwards, it also became possible to use the term theology to refer to study of religious ideas and teachings that are not specifically Christian .\"Theology\" can also now be used in a derived sense to mean \"a system of theoretical principles; an  ideology\".[26]The term theology has been deemed by some as only appropriate to the study of religions that worship a supposed deityIn Jewish theology, the historical absence of political authority has meant that most theological reflection has happened within the context of the Jewish community and synagogue, rather than within specialized academic institutions, including though Rabbinical discussion of Jewish law and Jewish Biblical commentaries.[28] Historically it has been very active, and highly significant for Christian and Islamic theology and well as for Judaism.Christian theology is the study of Christian belief and practice. Such study concentrates primarily upon the texts of the Old Testament and the New Testament as well as on Christian tradition. Christian theologians use biblical exegesis, rational analysis and argument. Theology might be undertaken to help the theologian better understand Christian tenets, to make comparisons between Christianity and other traditions, to defend Christianity against objections and criticism, to facilitate reforms in the Christian church, to assist in the propagation of Christianity, to draw on the resources of the Christian tradition to address some present situation or need, or for a variety of other reasons.Islamic theological discussion that parallels Christian theological discussion is named \"Kalam\"; the Islamic analogue of Christian theological discussion would more properly be the investigation and elaboration of Sharia or Fiqh. \"Kalam ... does not hold the leading place in Muslim thought that theology does in Christianity. To find an equivalent for 'theology' in the Christian sense it is necessary to have recourse to several disciplines, and to the usul al-fiqh as much as to kalam.\" [30]Some academic inquiries within Buddhism, dedicated to the investigation of a Buddhist understanding of the world, prefer the designation Buddhist philosophy to the term Buddhist theology, since Buddhism lacks the same conception of a theos. Jose Ignacio Cabezon, who argues that the use of \"theology\" is appropriate, can only do so, he says, because \"I take theology not to be restricted to discourse on God ... I take 'theology' not to be restricted to its etymological meaning. In that latter sense, Buddhism is of course atheological, rejecting as it does the notion of God.\"[31]Within Hindu philosophy, there is a tradition of philosophical speculation on the nature of the universe, of God . Vaishnava theology has been a subject of study for many devotees, philosophers and scholars in India for centuries. A large part of its study lies in classifying and organizing the manifestations of thousands of gods and their aspects. In recent decades also has been taken on by a number of academic institutions in Europe, such as the Oxford Centre for Hindu Studies and Bhaktivedanta College.[32] See also: KrishnologyThe history of the study of theology in institutions of higher education is as old as the history of such institutions themselves. For instance, Taxila was an early centre of Vedic learning, possible from the 6th century BC or earlier;[33] the Platonic Academy founded in Athens in the 4th century BC seems to have included theological themes in its subject matter;[34] the Chinese Taixue delivered Confucian teaching from the 2nd century BC;[35] the School of Nisibis was a centre of Christian learning from the 4th century AD;[36][37] Nalanda in India was a site of Buddhist higher learning from at least the 5th or 6th century AD;[38] and the Moroccan University of Al-Karaouine was a centre of Islamic learning from the 10th century,[39] as was Al-Azhar University in Cairo.[40]The earliest universities were developed under the aegis of the Latin Church by papal bull as studia generalia and perhaps from cathedral schools. It is possible, however, that the development of cathedral schools into universities was quite rare, with the University of Paris being an exception.[41] Later they were also founded by Kings . In the early medieval period, most new universities were founded from pre-existing schools, usually when these schools were deemed to have become primarily sites of higher education. Many historians state that universities and cathedral schools were a continuation of the interest in learning promoted by monasteries.[42] Christian theological learning was therefore a component in these institutions, as was the study of Church or Canon law: universities played an important role in training people for ecclesiastical offices, in helping the church pursue the clarification and defence of its teaching, and in supporting the legal rights of the church over against secular rulers.[43] At such universities, theological study was initially closely tied to the life of faith and of the church: it fed, and was fed by, practices of preaching, prayer and celebration of the Mass.[44]During the High Middle Ages, theology was therefore the ultimate subject at universities, being named \"The Queen of the Sciences\" and serving as the capstone to the Trivium and Quadrivium that young men were expected to study. This meant that the other subjects  existed primarily to help with theological thought.[45]Christian theology's preeminent place in the university began to be challenged during the European Enlightenment, especially in Germany.[46] Other subjects gained in independence and prestige, and questions were raised about the place of a discipline that seemed to involve commitment to the authority of particular religious traditions in institutions that were increasingly understood to be devoted to independent reason.[47]Since the early nineteenth century, various different approaches have emerged in the West to theology as an academic discipline. Much of the debate concerning theology's place in the university or within a general higher education curriculum centres on whether theology's methods are appropriately theoretical and  scientific or, on the other hand, whether theology requires a pre-commitment of faith by its practitioners, and whether such a commitment conflicts with academic freedom.[48]In some contexts, theology has been held to belong in institutions of higher education primarily as a form of professional training for Christian ministry. This was the basis on which Friedrich Schleiermacher, a liberal theologian, argued for the inclusion of theology in the new University of Berlin in 1810.[49]For instance, in Germany, theological faculties at state universities are typically tied to particular denominations, Protestant or Roman Catholic, and those faculties will offer denominationally-bound  degrees, and have denominationally bound public posts amongst their faculty; as well as contributing 'to the development and growth of Christian knowledge' they 'provide the academic training for the future clergy and teachers of religious instruction at German schools.'[50]In the United States, several prominent colleges and universities were started in order to train Christian ministers. Harvard,[51] Georgetown,[52] Boston University, Yale,[53] and Princeton[54] all had the theological training of clergy as a primary purpose at their foundation.Seminaries and bible colleges have continued this alliance between the academic study of theology and training for Christian ministry. There are, for instance, numerous prominent US examples, including Catholic Theological Union in Chicago,[55] The Graduate Theological Union in Berkeley,[56] Criswell College in Dallas,[57] The Southern Baptist Theological Seminary in Louisville,[58] Trinity Evangelical Divinity School in Deerfield, Illinois,[59] Dallas Theological Seminary,[60] North Texas Collegiate Institute in Farmers Branch, Texas[61] and the Assemblies of God Theological Seminary in Springfield, Missouri.In some contexts, scholars pursue theology as an academic discipline without formal affiliation to any particular church  and in religious studies.In some contemporary contexts, a distinction is made between theology, which is seen as involving some level of commitment to the claims of the religious tradition being studied, and religious studies, which by contrast is normally seen as requiring that the question of the truth or falsehood of the religious traditions studied be kept outside its field. Religious studies involves the study of historical or contemporary practices or of those traditions' ideas using intellectual tools and frameworks that are not themselves specifically tied to any religious tradition and that are normally understood to be neutral or secular.[63] In contexts where 'religious studies' in this sense is the focus, the primary forms of study are likely to include:Sometimes, theology and religious studies are seen as being in tension,[64] and at other times, they are held to coexist without serious tension.[65] Occasionally it is denied that there is as clear a boundary between them.[66]There is an ancient tradition of skepticism about theology, followed by a more modern rise in secularist and atheist criticism.Whether or not reasoned discussion about the divine is possible has long been a point of contention. Protagoras, as early as the fifth century BC, who is reputed to have been exiled from Athens because of his agnosticism about the existence of the gods, said that \"Concerning the gods I cannot know either that they exist or that they do not exist, or what form they might have, for there is much to prevent one's knowing: the obscurity of the subject and the shortness of man's life.\"[67]Lord Bolingbroke, an English politician and political philosopher wrote in his political works his views on theology, \"Theology is in fault not religion. Theology is a science that may justly be compared to the Box of Pandora. Many good things lie uppermost in it; but many evil lie under them, and scatter plagues and desolation throughout the world.\"[68]Thomas Paine the American revolutionary, wrote in his two part work The Age of Reason, \"The study of theology, as it stands in Christian churches, is the study of nothing; it is founded on nothing; it rests on no principles; it proceeds by no authorities; it has no data; it can demonstrate nothing; and it admits of no conclusion. Not anything can be studied as a science, without our being in possession of the principles upon which it is founded; and as this is the case with Christian theology, it is therefore the study of nothing.\"[69]Ludwig Feuerbach, the atheist philosopher sought to dissolve theology in his work Principles of the Philosophy of the Future: \"The task of the modern era was the realization and humanization of God \u2013 the transformation and dissolution of theology into anthropology.\"[70] This mirrored his earlier work The Essence of Christianity , for which he was banned from teaching in Germany, in which he had said that theology was a \"web of contradictions and delusions\".[71]A.J. Ayer the former logical-positivist, sought to show in his essay \"Critique of Ethics and Theology\" that all statements about the divine are nonsensical and any divine-attribute is unprovable. He wrote: \"It is now generally admitted, at any rate by philosophers, that the existence of a being having the attributes which define the god of any non-animistic religion cannot be demonstratively proved... [A]ll utterances about the nature of God are nonsensical.\"[72]Walter Kaufmann the philosopher, in his essay \"Against Theology\", sought to differentiate theology from religion in general. \"Theology, of course, is not religion; and a great deal of religion is emphatically anti-theological... An attack on theology, therefore, should not be taken as necessarily involving an attack on religion. Religion can be, and often has been, untheological or even anti-theological.\" However, Kaufmann found that \"Christianity is inescapably a theological religion\".[73]Critics dating back to the 18th century have questioned the suitability of theology as an academic discipline and in the 21st century criticism continues.[74]Charles Bradlaugh believed theology prevented human beings achieving liberty.[75] Bradlaugh noted theologians of his time stated that modern scientific research contradicted sacred scriptures therefore the scriptures must be wrong.[76]Robert G. Ingersoll stated that when theologians had power the majority of people lived in hovels while a privileged few had palaces and cathedrals. In Ingersoll's opinion science rather than theology improved people's lives. Ingersoll maintained further that trained theologians reason no better than a person who assumes the devil must exist because pictures resemble the devil so exactly.[77]Mark Twain stated that several mutually incompatible religions claimed to be the true religion and that people cut the throats of others for following a different theology.[78]In 1993, Richard Dawkins wrote, \"The achievements of theologians don't do anything, don't affect anything, don't achieve anything, don't even mean anything. What makes you think that 'theology' is a subject at all?\"[79]"], "Anthropology": ["Anthropology is the study of humans and human behaviour and societies in the past and present.[1][2][3] Social anthropology and cultural anthropology[1][2][3] study the norms and values of societies. Linguistic anthropology studies how language affects social life. Biological or physical anthropology[1][2][3] studies the biological development of humans.Archaeology, which studies past human cultures through investigation of physical evidence, is thought of as a branch of anthropology in the United States,[4] while in Europe, it is viewed as a discipline in its own right or grouped under other related disciplines, such as history.The abstract noun anthropology is first attested in reference to history.[5][n 1] Its present use first appeared in Renaissance Germany in the works of Magnus Hundt and Otto Casmann.[6] Their New Latin anthropologia derived from the combining forms of the Greek words \u00e1nthr\u014dpos [5] It began to be used in English, possibly via French Anthropologie, by the early 18th century.[5][n 2]In 1647, the Bartholins, founders of the University of Copenhagen, defined l'anthropologie as follows:[7]Sporadic use of the term for some of the subject matter occurred subsequently, such as the use by \u00c9tienne Serres in 1839 to describe the natural history, or paleontology, of man, based on comparative anatomy, and the creation of a chair in anthropology and ethnography in 1850 at the National Museum of Natural History  by Jean Louis Armand de Quatrefages de Br\u00e9au. Various short-lived organizations of anthropologists had already been formed. The Soci\u00e9t\u00e9 Ethnologique de Paris, the first to use Ethnology, was formed in 1839. Its members were primarily anti-slavery activists. When slavery was abolished in France in 1848 the Soci\u00e9t\u00e9 was abandoned.Meanwhile, the Ethnological Society of New York, currently the American Ethnological Society, was founded on its model in 1842, as well as the Ethnological Society of London in 1843, a break-away group of the Aborigines' Protection Society.[8] These anthropologists of the times were liberal, anti-slavery, and pro-human-rights activists. They maintained international connections.Anthropology and many other current fields are the intellectual results of the comparative methods developed in the earlier 19th century. Theorists in such diverse fields as anatomy, linguistics, and Ethnology, making feature-by-feature comparisons of their subject matters, were beginning to suspect that similarities between animals, languages, and folkways were the result of processes or laws unknown to them then.[9] For them, the publication of Charles Darwin's On the Origin of Species was the epiphany of everything they had begun to suspect. Darwin himself arrived at his conclusions through comparison of species he had seen in agronomy and in the wild.Darwin and Wallace unveiled evolution in the late 1850s. There was an immediate rush to bring it into the social sciences. Paul Broca in Paris was in the process of breaking away from the Soci\u00e9t\u00e9 de biologie to form the first of the explicitly anthropological societies, the Soci\u00e9t\u00e9 d'Anthropologie de Paris, meeting for the first time in Paris in 1859.[10][n 4] When he read Darwin, he became an immediate convert to Transformisme, as the French called evolutionism.[11] His definition now became \"the study of the human group, considered as a whole, in its details, and in relation to the rest of nature\".[12]Broca, being what today would be called a neurosurgeon, had taken an interest in the pathology of speech. He wanted to localize the difference between man and the other animals, which appeared to reside in speech. He discovered the speech center of the human brain, today called Broca's area after him. His interest was mainly in Biological anthropology, but a German philosopher specializing in psychology, Theodor Waitz, took up the theme of general and social anthropology in his six-volume work, entitled Die Anthropologie der Naturv\u00f6lker, 1859\u20131864. The title was soon translated as \"The Anthropology of Primitive Peoples\". The last two volumes were published posthumously.Waitz defined anthropology as \"the science of the nature of man\". By nature he meant matter animated by \"the Divine breath\";[13] i.e., he was an animist. Following Broca's lead, Waitz points out that anthropology is a new field, which would gather material from other fields, but would differ from them in the use of comparative anatomy, physiology, and psychology to differentiate man from \"the animals nearest to him\". He stresses that the data of comparison must be empirical, gathered by experimentation.[14] The history of civilization, as well as ethnology, are to be brought into the comparison. It is to be presumed fundamentally that the species, man, is a unity, and that \"the same laws of thought are applicable to all men\".[15]Waitz was influential among the British ethnologists. In 1863 the explorer Richard Francis Burton and the speech therapist James Hunt broke away from the Ethnological Society of London to form the Anthropological Society of London, which henceforward would follow the path of the new anthropology rather than just ethnology. It was the 2nd society dedicated to general anthropology in existence. Representatives from the French Soci\u00e9t\u00e9 were present, though not Broca. In his keynote address, printed in the first volume of its new publication, The Anthropological Review, Hunt stressed the work of Waitz, adopting his definitions as a standard.[16][n 5] Among the first associates were the young Edward Burnett Tylor, inventor of cultural anthropology, and his brother Alfred Tylor, a geologist. Previously Edward had referred to himself as an ethnologist; subsequently, an anthropologist.Similar organizations in other countries followed: The Anthropological Society of Madrid  founded by Rudolph Virchow, known for his vituperative attacks on the evolutionists. Not religious himself, he insisted that Darwin's conclusions lacked empirical foundation.During the last three decades of the 19th century, a proliferation of anthropological societies and associations occurred, most independent, most publishing their own journals, and all international in membership and association. The major theorists belonged to these organizations. They supported the gradual osmosis of anthropology curricula into the major institutions of higher learning. By 1898 the American Association for the Advancement of Science was able to report that 48 educational institutions in 13 countries had some curriculum in anthropology. None of the 75 faculty members were under a department named anthropology.[17]This meagre statistic expanded in the 20th century to comprise anthropology departments in the majority of the world's higher educational institutions, many thousands in number. Anthropology has diversified from a few major subdivisions to dozens more. Practical Anthropology, the use of anthropological knowledge and technique to solve specific problems, has arrived; for example, the presence of buried victims might stimulate the use of a forensic archaeologist to recreate the final scene. The organization has reached global level. For example, the World Council of Anthropological Associations , \"a network of national, regional and international associations that aims to promote worldwide communication and cooperation in anthropology\", currently contains members from about three dozen nations.[18]Since the work of Franz Boas and Bronis\u0142aw Malinowski in the late 19th and early 20th centuries, social anthropology in Great Britain and cultural anthropology in the US have been distinguished from other social sciences by its emphasis on cross-cultural comparisons, long-term in-depth examination of context, and the importance it places on participant-observation or experiential immersion in the area of research. Cultural anthropology, in particular, has emphasized cultural relativism, holism, and the use of findings to frame cultural critiques.[19] This has been particularly prominent in the United States, from Boas' arguments against 19th-century racial ideology, through Margaret Mead's advocacy for gender equality and sexual liberation, to current criticisms of post-colonial oppression and promotion of multiculturalism. Ethnography is one of its primary research designs as well as the text that is generated from anthropological fieldwork.[20][21][22]In Great Britain and the Commonwealth countries, the British tradition of social anthropology tends to dominate. In the United States, anthropology has traditionally been divided into the four field approach developed by Franz Boas in the early 20th century: biological or physical anthropology; social, cultural, or sociocultural anthropology; and archaeology; plus anthropological linguistics. These fields frequently overlap but tend to use different methodologies and techniques.European countries with overseas colonies tended to practice more ethnology . It is sometimes referred to as sociocultural anthropology in the parts of the world that were influenced by the European tradition.[23]Anthropology is a global discipline involving humanities, social sciences and natural sciences. Anthropology builds upon knowledge from natural sciences, including the discoveries about the origin and evolution of Homo sapiens, human physical traits, human behavior, the variations among different groups of humans, how the evolutionary past of Homo sapiens has influenced its social organization and culture, and from social sciences, including the organization of human social and cultural relations, institutions, social conflicts, etc.[24][25] Early anthropology originated in Classical Greece and Persia and studied and tried to understand observable cultural diversity.[26][27] As such, anthropology has been central in the development of several new  interdisciplinary fields such as cognitive science,[28] global studies, and various ethnic studies.According to Clifford Geertz,Sociocultural anthropology has been heavily influenced by structuralist and postmodern theories, as well as a shift toward the analysis of modern societies. During the 1970s and 1990s, there was an epistemological shift away from the positivist traditions that had largely informed the discipline.[30][page\u00a0needed] During this shift, enduring questions about the nature and production of knowledge came to occupy a central place in cultural and social anthropology. In contrast, archaeology and biological anthropology remained largely positivist. Due to this difference in epistemology, the four sub-fields of anthropology have lacked cohesion over the last several decades.Sociocultural anthropology draws together the principle axes of cultural anthropology and social anthropology. Cultural anthropology is the comparative study of the manifold ways in which people make sense of the world around them, while social anthropology is the study of the relationships among individuals and groups.[31] Cultural anthropology is more related to philosophy, literature and the arts . There is no hard-and-fast distinction between them, and these categories overlap to a considerable degree.Inquiry in sociocultural anthropology is guided in part by cultural relativism, the attempt to understand other societies in terms of their own cultural symbols and values.[20] Accepting other cultures in their own terms moderates reductionism in cross-cultural comparison.[32] This project is often accommodated in the field of ethnography. Ethnography can refer to both a methodology and the product of ethnographic research, i.e. an ethnographic monograph. As a methodology, ethnography is based upon long-term fieldwork within a community or other research site. Participant observation is one of the foundational methods of social and cultural anthropology.[33] Ethnology involves the systematic comparison of different cultures. The process of participant-observation can be especially helpful to understanding a culture from an emic  point of view.The study of kinship and social organization is a central focus of sociocultural anthropology, as kinship is a human universal. Sociocultural anthropology also covers economic and political organization, law and conflict resolution, patterns of consumption and exchange, material culture, technology, infrastructure, gender relations, ethnicity, childrearing and socialization, religion, myth, symbols, values, etiquette, worldview, sports, music, nutrition, recreation, games, food, festivals, and language .Comparison across cultures is a key element of method in sociocultural anthropology, including the industrialized [34] of world societies are:Biological Anthropology and Physical Anthropology are synonymous terms to describe anthropological research focused on the study of humans and non-human primates in their biological, evolutionary, and demographic dimensions. It examines the biological and social factors that have affected the evolution of humans and other primates, and that generate, maintain or change contemporary genetic and physiological variation.[35]Archaeology is the study of the human past through its material remains. Artifacts, faunal remains, and human altered landscapes are evidence of the cultural and material lives of past societies. Archaeologists examine this material remains in order to deduce patterns of past human behavior and cultural practices. Ethnoarchaeology is a type of archaeology that studies the practices and material remain of living human groups in order to gain a better understanding of the evidence left behind by past human groups, who are presumed to have lived in similar ways.[36]Linguistic anthropology  seeks to understand the processes of human communications, verbal and non-verbal, variation in language across time and space, the social uses of language, and the relationship between language and culture.[37] It is the branch of anthropology that brings linguistic methods to bear on anthropological problems, linking the analysis of linguistic forms and processes to the interpretation of sociocultural processes. Linguistic anthropologists often draw on related fields including sociolinguistics, pragmatics, cognitive linguistics, semiotics, discourse analysis, and narrative analysis.[38]One of the central problems in the anthropology of art concerns the universality of 'art' as a cultural phenomenon. Several anthropologists have noted that the Western categories of 'painting', 'sculpture', or 'literature', conceived as independent artistic activities, do not exist, or exist in a significantly different form, in most non-Western contexts.[39] To surmount this difficulty, anthropologists of art have focused on formal features in objects which, without exclusively being 'artistic', have certain evident 'aesthetic' qualities. Boas' Primitive Art, Claude L\u00e9vi-Strauss' The Way of the Masks  are some examples in this trend to transform the anthropology of 'art' into an anthropology of culturally specific 'aesthetics'.Media anthropology  to contexts of media reception, following audiences in their everyday responses to media. Other types include cyber anthropology, a relatively new area of internet research, as well as ethnographies of other areas of research which happen to involve media, such as development work, social movements, or health education. This is in addition to many classic ethnographic contexts, where media such as radio, the press, new media, and television have started to make their presences felt since the early 1990s.[40][41]Ethnomusicology is an academic field encompassing various approaches to the study of music , that emphasize its cultural, social, material, cognitive, biological, and other dimensions or contexts instead of or in addition to its isolated sound component or any particular repertoire.Visual anthropology is concerned, in part, with the study and production of ethnographic photography, film and, since the mid-1990s, new media. While the term is sometimes used interchangeably with ethnographic film, visual anthropology also encompasses the anthropological study of visual representation, including areas such as performance, museums, art, and the production and reception of mass media. Visual representations from all cultures, such as sandpaintings, tattoos, sculptures and reliefs, cave paintings, scrimshaw, jewelry, hieroglyphics, paintings, and photographs are included in the focus of visual anthropology.Economic anthropology attempts to explain human economic behavior in its widest historic, geographic and cultural scope. It has a complex relationship with the discipline of economics, of which it is highly critical. Its origins as a sub-field of anthropology begin with the Polish-British founder of Anthropology, Bronis\u0142aw Malinowski, and his French compatriot, Marcel Mauss, on the nature of gift-giving exchange  as an alternative to market exchange. Economic Anthropology remains, for the most part, focused upon exchange. The school of thought derived from Marx and known as Political Economy focuses on production, in contrast.[42] Economic Anthropologists have abandoned the primitivist niche they were relegated to by economists, and have now turned to examine corporations, banks, and the global financial system from an anthropological perspective.Political economy in anthropology is the application of the theories and methods of Historical Materialism to the traditional concerns of anthropology, including, but not limited to, non-capitalist societies. Political Economy introduced questions of history and colonialism to ahistorical anthropological theories of social structure and culture. Three main areas of interest rapidly developed. The first of these areas was concerned with the \"pre-capitalist\" societies that were subject to evolutionary \"tribal\" stereotypes. Sahlin's work on hunter-gatherers as the 'original affluent society' did much to dissipate that image. The second area was concerned with the vast majority of the world's population at the time, the peasantry, many of whom were involved in complex revolutionary wars such as in Vietnam. The third area was on colonialism, imperialism, and the creation of the capitalist world-system.[43] More recently, these Political Economists have more directly addressed issues of industrial  capitalism around the world.Applied Anthropology refers to the application of the method and theory of anthropology to the analysis and solution of practical problems. It is a \"complex of related, research-based, instrumental methods which produce change or stability in specific cultural systems through the provision of data, initiation of direct action, and/or the formulation of policy\".[44] More simply, applied anthropology is the practical side of anthropological research; it includes researcher involvement and activism within the participating community. It is closely related to Development anthropology .Anthropology of development tends to view development from a critical perspective. The kind of issues addressed and implications for the approach simply involve pondering why, if a key development goal is to alleviate poverty, is poverty increasing? Why is there such a gap between plans and outcomes? Why are those working in development so willing to disregard history and the lessons it might offer? Why is development so externally driven rather than having an internal basis? In short, why does so much planned development fail?Kinship can refer both to the study of the patterns of social relationships in one or more human cultures, or it can refer to the patterns of social relationships themselves. Over its history, anthropology has developed a number of related concepts and terms, such as \"descent\", \"descent groups\", \"lineages\", \"affines\", \"cognates\", and even \"fictive kinship\". Broadly, kinship patterns may be considered to include people related both by descent , and also relatives by marriage.Feminist anthropology is a four field approach to anthropology  that seeks to reduce male bias in research findings, anthropological hiring practices, and the scholarly production of knowledge. Anthropology engages often with feminists from non-Western traditions, whose perspectives and experiences can differ from those of white European and American feminists. Historically, such 'peripheral' perspectives have sometimes been marginalized and regarded as less valid or important than knowledge from the western world. Feminist anthropologists have claimed that their research helps to correct this systematic bias in mainstream feminist theory. Feminist anthropologists are centrally concerned with the construction of gender across societies. Feminist anthropology is inclusive of birth anthropology as a specialization. The first African-American female anthropologist and Caribbeanist are said to be Vera Mae Green who studied ethnic and family relations in the Caribbean as well as the United States, and thereby tried to improve the way black life, experiences, and culture were studied.[45]Medical anthropology is an interdisciplinary field which studies \"human health and disease, health care systems, and biocultural adaptation\".[46] It is believed that William Caudell was the first to discover the field of medical anthropology. Currently, research in medical anthropology is one of the main growth areas in the field of anthropology as a whole. It focuses on the following six basic fields:[47]Other subjects that have become central to medical anthropology worldwide are violence and social suffering  as well as other issues that involve physical and psychological harm and suffering that are not a result of illness. On the other hand, there are fields that intersect with medical anthropology in terms of research methodology and theoretical production, such as cultural psychiatry and transcultural psychiatry or ethnopsychiatry.Nutritional anthropology is a synthetic concept that deals with the interplay between economic systems, nutritional status and food security, and how changes in the former affect the latter. If economic and environmental changes in a community affect access to food, food security, and dietary health, then this interplay between culture and biology is in turn connected to broader historical and economic trends associated with globalization. Nutritional status affects overall health status, work performance potential, and the overall potential for economic development  for any given group of people.Psychological anthropology is an interdisciplinary subfield of anthropology that studies the interaction of cultural and mental processes. This subfield tends to focus on ways in which humans' development and enculturation within a particular cultural group\u2014with its own history, language, practices, and conceptual categories\u2014shape processes of human cognition, emotion, perception, motivation, and mental health. It also examines how the understanding of cognition, emotion, motivation, and similar psychological processes inform or constrain our models of cultural and social processes.[48][49]Cognitive anthropology seeks to explain patterns of shared knowledge, cultural innovation, and transmission over time and space using the methods and theories of the cognitive sciences  often through close collaboration with historians, ethnographers, archaeologists, linguists, musicologists and other specialists engaged in the description and interpretation of cultural forms. Cognitive anthropology is concerned with what people from different groups know and how that implicit knowledge changes the way people perceive and relate to the world around them.[48]Transpersonal anthropology studies the relationship between altered states of consciousness and culture. As with transpersonal psychology, the field is much concerned with altered states of consciousness  and transpersonal experience. However, the field differs from mainstream transpersonal psychology in taking more cognizance of cross-cultural issues\u2014for instance, the roles of myth, ritual, diet, and texts in evoking and interpreting extraordinary experiences.[50]Political anthropology concerns the structure of political systems, looked at from the basis of the structure of societies. Political anthropology developed as a discipline concerned primarily with politics in stateless societies, a new development started from the 1960s, and is still unfolding: anthropologists started increasingly to study more \"complex\" social settings in which the presence of states, bureaucracies and markets entered both ethnographic accounts and analysis of local phenomena. The turn towards complex societies meant that political themes were taken up at two main levels. First of all, anthropologists continued to study political organization and political phenomena that lay outside the state-regulated sphere . An anthropology of the state developed, and it is a most thriving field today. Geertz' comparative work on \"Negara\", the Balinese state is an early, famous example.Legal anthropology or anthropology of law specializes in \"the cross-cultural study of social ordering\".[51] Earlier legal anthropological research often focused more narrowly on conflict management, crime, sanctions, or formal regulation. More recent applications include issues such as human rights, legal pluralism,[52] and political uprisings.Public Anthropology was created by Robert Borofsky, a professor at Hawaii Pacific University, to \"demonstrate the ability of anthropology and anthropologists to effectively address problems beyond the discipline \u2013 illuminating larger social issues of our times as well as encouraging broad, public conversations about them with the explicit goal of fostering social change\" .Cyborg anthropology originated as a sub-focus group within the American Anthropological Association's annual meeting in 1993. The sub-group was very closely related to STS and the Society for the Social Studies of Science.[53] Donna Haraway's 1985 Cyborg Manifesto could be considered the founding document of cyborg anthropology by first exploring the philosophical and sociological ramifications of the term. Cyborg anthropology studies humankind and its relations with the technological systems it has built, specifically modern technological systems that have reflexively shaped notions of what it means to be human beings.Digital anthropology is the study of the relationship between humans and digital-era technology, and extends to various areas where anthropology and technology intersect. It is sometimes grouped with sociocultural anthropology, and sometimes considered part of material culture. The field is new, and thus has a variety of names with a variety of emphases. These include techno-anthropology,[54] digital ethnography, cyberanthropology,[55] and virtual anthropology.[56]Ecological anthropology is defined as the \"study of cultural adaptations to environments\".[57] The sub-field is also defined as, \"the study of relationships between a population of humans and their biophysical environment\".[58] The focus of its research concerns \"how cultural beliefs and practices helped human populations adapt to their environments, and how their environment across space and time.[59] The contemporary perspective of environmental anthropology, and arguably at least the backdrop, if not the focus of most of the ethnographies and cultural fieldworks of today, is political ecology. Many characterize this new perspective as more informed with culture, politics and power, globalization, localized issues, century anthropology and more.[60] The focus and data interpretation is often used for arguments for/against or creation of policy, and to prevent corporate exploitation and damage of land. Often, the observer has become an active part of the struggle either directly . Such is the case with environmental justice advocate Melissa Checker and her relationship with the people of Hyde Park.[61]Ethnohistory is the study of ethnographic cultures and indigenous customs by examining historical records. It is also the study of the history of various ethnic groups that may or may not exist today. Ethnohistory uses both historical and ethnographic data as its foundation. Its historical methods and materials go beyond the standard use of documents and manuscripts. Practitioners recognize the utility of such source material as maps, music, paintings, photography, folklore, oral tradition, site exploration, archaeological materials, museum collections, enduring customs, language, and place names.[62]The anthropology of religion involves the study of religious institutions in relation to other social institutions, and the comparison of religious beliefs and practices across cultures. Modern anthropology assumes that there is complete continuity between magical thinking and religion,[63][n 6] and that every religion is a cultural product, created by the human community that worships it.[64]Urban anthropology is concerned with issues of urbanization, poverty, and neoliberalism. Ulf Hannerz quotes a 1960s remark that traditional anthropologists were \"a notoriously agoraphobic lot, anti-urban by definition\". Various social processes in the Western World as well as in the \"Third World\"  brought the attention of \"specialists in 'other cultures'\" closer to their homes.[65] There are two main approaches to urban anthropology: examining the types of cities or examining the social issues within the cities. These two methods are overlapping and dependent of each other. By defining different types of cities, one would use social factors as well as economic and political factors to categorize the cities. By directly looking at the different social issues, one would also be studying how they affect the dynamic of the city.[66]Anthrozoology  is the study of interaction between living things. It is a burgeoning interdisciplinary field that overlaps with a number of other disciplines, including anthropology, ethology, medicine, psychology, veterinary medicine and zoology. A major focus of anthrozoologic research is the quantifying of the positive effects of human-animal relationships on either party and the study of their interactions.[67] It includes scholars from a diverse range of fields, including anthropology, sociology, biology, and philosophy.[68][69][n 7]Biocultural anthropology is the scientific exploration of the relationships between human biology and culture. Physical anthropologists throughout the first half of the 20th century viewed this relationship from a racial perspective; that is, from the assumption that typological human biological differences lead to cultural differences.[70] After World War II the emphasis began to shift toward an effort to explore the role culture plays in shaping human biology.Evolutionary anthropology is the interdisciplinary study of the evolution of human physiology and human behaviour and the relation between hominins and non-hominin primates. Evolutionary anthropology is based in natural science and social science, combining the human development with socioeconomic factors. Evolutionary anthropology is concerned with both biological and cultural evolution of humans, past and present. It is based on a scientific approach, and brings together fields such as archaeology, behavioral ecology, psychology, primatology, and genetics. It is a dynamic and interdisciplinary field, drawing on many lines of evidence to understand the human experience, past and present.Forensic anthropology is the application of the science of physical anthropology and human osteology in a legal setting, most often in criminal cases where the victim's remains are in the advanced stages of decomposition. A forensic anthropologist can assist in the identification of deceased individuals whose remains are decomposed, burned, mutilated or otherwise unrecognizable. The adjective \"forensic\" refers to the application of this subfield of science to a court of law.Paleoanthropology combines the disciplines of paleontology and physical anthropology. It is the study of ancient humans, as found in fossil hominid evidence such as petrifacted bones and footprints.Contemporary anthropology is an established science with academic departments at most universities and colleges. The single largest organization of Anthropologists is the American Anthropological Association , which was founded in 1903.[71] Membership is made up of anthropologists from around the globe.[72]In 1989, a group of European and American scholars in the field of anthropology established the European Association of Social Anthropologists  which serves as a major professional organization for anthropologists working in Europe. The EASA seeks to advance the status of anthropology in Europe and to increase visibility of marginalized anthropological traditions and thereby contribute to the project of a global anthropology or world anthropology.Hundreds of other organizations exist in the various sub-fields of anthropology, sometimes divided up by nation or region, and many anthropologists work with collaborators in other disciplines, such as geology, physics, zoology, paleontology, anatomy, music theory, art history, sociology and so on, belonging to professional societies in those disciplines as well.[73][74]As the field has matured it has debated and arrived at ethical principles aimed at protecting both the subjects of anthropological research as well as the researchers themselves, and professional societies have generated codes of ethics.[75]Anthropologists, like other researchers , have over time assisted state policies and projects, especially colonialism.[76][77]Some commentators have contended:As part of their quest for scientific objectivity, present-day anthropologists typically urge cultural relativism, which has an influence on all the sub-fields of anthropology.[20] This is the notion that cultures should not be judged by another's values or viewpoints, but be examined dispassionately on their own terms. There should be no notions, in good anthropology, of one culture being better or worse than another culture.[79][80]Ethical commitments in anthropology include noticing and documenting genocide, infanticide, racism, mutilation , and torture. Topics like racism, slavery, and human sacrifice attract anthropological attention and theories ranging from nutritional deficiencies[81] to genes[82] to acculturation have been proposed, not to mention theories of colonialism and many others as root causes of Man's inhumanity to man. To illustrate the depth of an anthropological approach, one can take just one of these topics, such as \"racism\" and find thousands of anthropological references, stretching across all the major and minor sub-fields.[83][84][85][86]Anthropologists' involvement with the U.S. government, in particular, has caused bitter controversy within the discipline. Franz Boas publicly objected to US participation in World War I, and after the war he published a brief expose and condemnation of the participation of several American archaeologists in espionage in Mexico under their cover as scientists.But by the 1940s, many of Boas' anthropologist contemporaries were active in the allied war effort against the \"Axis\" . At the same time, David H. Price's work on American anthropology during the Cold War provides detailed accounts of the pursuit and dismissal of several anthropologists from their jobs for communist sympathies.Attempts to accuse anthropologists of complicity with the CIA and government intelligence activities during the Vietnam War years have turned up surprisingly little. Many anthropologists .Professional anthropological bodies often object to the use of anthropology for the benefit of the state. Their codes of ethics or statements may proscribe anthropologists from giving secret briefings. The Association of Social Anthropologists of the UK and Commonwealth  has called certain scholarship ethically dangerous. The AAA's current 'Statement of Professional Responsibility' clearly states that \"in relation with their own government and with host governments\u00a0... no secret research, no secret reports or debriefings of any kind should be agreed to or given.\"Anthropologists, along with other social scientists, are working with the US military as part of the US Army's strategy in Afghanistan.[87] The Christian Science Monitor reports that \"Counterinsurgency efforts focus on better grasping and meeting local needs\" in Afghanistan, under the Human Terrain System  program; in addition, HTS teams are working with the US military in Iraq.[88] In 2009, the American Anthropological Association's Commission on the Engagement of Anthropology with the US Security and Intelligence Communities released its final report concluding, in part, that, \"When ethnographic investigation is determined by military missions, not subject to external review, where data collection occurs in the context of war, integrated into the goals of counterinsurgency, and in a potentially coercive environment \u2013 all characteristic factors of the HTS concept and its application \u2013 it can no longer be considered a legitimate professional exercise of anthropology. In summary, while we stress that constructive engagement between anthropology and the military is possible, CEAUSSIC suggests that the AAA emphasize the incompatibility of HTS with disciplinary ethics and practice for job seekers and that it further recognize the problem of allowing HTS to define the meaning of \"anthropology\" within DoD.\"[89]Before WWII British 'social anthropology' and American 'cultural anthropology' were still distinct traditions. After the war, enough British and American anthropologists borrowed ideas and methodological approaches from one another that some began to speak of them collectively as 'sociocultural' anthropology.There are several characteristics that tend to unite anthropological work. One of the central characteristics is that anthropology tends to provide a comparatively more holistic account of phenomena and tends to be highly empirical.[19] The quest for holism leads most anthropologists to study a particular place, problem or phenomenon in detail, using a variety of methods, over a more extensive period than normal in many parts of academia.In the 1990s and 2000s , calls for clarification of what constitutes a culture, of how an observer knows where his or her own culture ends and another begins, and other crucial topics in writing anthropology were heard. These dynamic relationships, between what can be observed on the ground, as opposed to what can be observed by compiling many local observations remain fundamental in any kind of anthropology, whether cultural, biological, linguistic or archaeological.[90][91]Biological anthropologists are interested in both human variation[92][93] and in the possibility of human universals .[94][95] They use many different methods of study, but modern population genetics, participant observation and other techniques often take anthropologists \"into the field,\" which means traveling to a community in its own setting, to do something called \"fieldwork.\" On the biological or physical side, human measurements, genetic samples, nutritional data may be gathered and published as articles or monographs.Along with dividing up their project by theoretical emphasis, anthropologists typically divide the world up into relevant time periods and geographic regions. Human time on Earth is divided up into relevant cultural traditions based on material, such as the Paleolithic and the Neolithic, of particular use in archaeology.[citation needed] Further cultural subdivisions according to tool types, such as Olduwan or Mousterian or Levalloisian help archaeologists and other anthropologists in understanding major trends in the human past.[citation needed] Anthropologists and geographers share approaches to Culture regions as well, since mapping cultures is central to both sciences. By making comparisons across cultural traditions , anthropologists have developed various kinds of comparative method, a central part of their science.Because anthropology developed from so many different enterprises , including but not limited to fossil-hunting, exploring, documentary film-making, paleontology, primatology, antiquity dealings and curatorship, philology, etymology, genetics, regional analysis, ethnology, history, philosophy, and religious studies,[96][97] it is difficult to characterize the entire field in a brief article, although attempts to write histories of the entire field have been made.[98]Some authors argue that anthropology originated and developed as the study of \"other cultures\", both in terms of time .[99] For example, the classic of urban anthropology, Ulf Hannerz in the introduction to his seminal Exploring the City: Inquiries Toward an Urban Anthropology mentions that the \"Third World\" had habitually received most of attention; anthropologists who traditionally specialized in \"other cultures\" looked for them far away and started to look \"across the tracks\" only in late 1960s.[65]Now there exist many works focusing on peoples and topics very close to the author's \"home\".[100] It is also argued that other fields of study, like History and Sociology, on the contrary focus disproportionately on the West.[101]In France, the study of Western societies has been traditionally left to sociologists, but this is increasingly changing,[102] starting in the 1970s from scholars like Isac Chiva and journals like Terrain .Since the 1980s it has become common for social and cultural anthropologists to set ethnographic research in the North Atlantic region, frequently examining the connections between locations rather than limiting research to a single locale. There has also been a related shift toward broadening the focus beyond the daily life of ordinary people; increasingly, research is set in settings such as scientific laboratories, social movements, governmental and nongovernmental organizations and businesses.[103]"], "Economics": ["Economics [1][2][3] is the social science that studies the production, distribution, and consumption of goods and services.[4]Economics focuses on the behaviour and interactions of economic agents and how economies work. Microeconomics analyzes basic elements in the economy, including individual agents and markets, their interactions, and the outcomes of interactions. Individual agents may include, for example, households, firms, buyers, and sellers. Macroeconomics analyzes the entire economy . See glossary of economics.Other broad distinctions within economics include those between positive economics, describing \"what is\", and normative economics, advocating \"what ought to be\"; between economic theory and applied economics; between rational and behavioural economics; and between mainstream economics and heterodox economics.[5]The discipline was renamed in the late 19th century primarily due to Alfred Marshall from \"political economy\" to \"economics\" as a shorter term for \"economic science\". At that time, it became more open to rigorous thinking and made increased use of mathematics, which helped support efforts to have it accepted as a science and as a separate discipline outside of political science and other social sciences.[a][7][8][9] The ultimate goal of economics is to improve the living conditions of people in their everyday life.[10]Economic analysis can be applied throughout society, in business, finance, health care, and government. Economic analysis is sometimes also applied to such diverse subjects as crime, education,[11] the family, law, politics, religion,[12] social institutions, war,[13] science,[14] and the environment.[15]There are a variety of modern definitions of economics; some reflect evolving views of the subject or different views among economists.[17][18] Scottish philosopher Adam Smith  defined what was then called political economy as \"an inquiry into the nature and causes of the wealth of nations\", in particular as:Jean-Baptiste Say  defines the subject in a social context as:Alfred Marshall provides a still widely cited definition in his textbook Principles of Economics  that extends analysis beyond wealth and from the societal to the microeconomic level:Lionel Robbins  developed implications of what has been termed \"[p]erhaps the most commonly accepted current definition of the subject\":[18]Robbins describes the definition as not classificatory in \"pick[ing] out certain kinds of behaviour\" but rather analytical in \"focus[ing] attention on a particular aspect of behaviour, the form imposed by the influence of scarcity.\"[25] He affirmed that previous economists have usually centred their studies on the analysis of wealth: how wealth is created .Some subsequent comments criticized the definition as overly broad in failing to limit its subject matter to analysis of markets. From the 1960s, however, such comments abated as the economic theory of maximizing behaviour and rational-choice modelling expanded the domain of the subject to areas previously treated in other fields.[27] There are other criticisms as well, such as in scarcity not accounting for the macroeconomics of high unemployment.[28]Gary Becker, a contributor to the expansion of economics into new areas, describes the approach he favours as \"combin[ing the] assumptions of maximizing behaviour, stable preferences, and market equilibrium, used relentlessly and unflinchingly.\"[29] One commentary characterizes the remark as making economics an approach rather than a subject matter but with great specificity as to the \"choice process and the type of social interaction that [such] analysis involves.\" The same source reviews a range of definitions included in principles of economics textbooks and concludes that the lack of agreement need not affect the subject-matter that the texts treat. Among economists more generally, it argues that a particular definition presented may reflect the direction toward which the author believes economics is evolving, or should evolve.[18]Microeconomics examines how entities, forming a market structure, interact within a market to create a market system. These entities include private and public players with various classifications, typically operating under scarcity of tradable units and light government regulation.[clarification needed] The item traded may be a tangible product such as apples or a service such as repair services, legal counsel, or entertainment.In theory, in a free market the aggregates  of quantity demanded by buyers and quantity supplied by sellers may reach economic equilibrium over time in reaction to price changes; in practice, various issues may prevent equilibrium, and any equilibrium reached may not necessarily be morally equitable. For example, if the supply of healthcare services is limited by external factors, the equilibrium price may be unaffordable for many who desire it but cannot pay for it.Various market structures exist. In perfectly competitive markets, no participants are large enough to have the market power to set the price of a homogeneous product. In other words, every participant is a \"price taker\" as no participant influences the price of a product. In the real world, markets often experience imperfect competition.Forms include monopoly . Unlike perfect competition, imperfect competition invariably means market power is unequally distributed. Firms under imperfect competition have the potential to be \"price makers\", which means that, by holding a disproportionately high share of market power, they can influence the prices of their products.Microeconomics studies individual markets by simplifying the economic system by assuming that activity in the market being analysed does not affect other markets. This method of analysis is known as partial-equilibrium analysis  across all markets. This method studies both changes in markets and their interactions leading towards equilibrium.[30]In microeconomics, production is the conversion of inputs into outputs. It is an economic process that uses inputs to create a commodity or a service for exchange or direct use. Production is a flow and thus a rate of output per period of time. Distinctions include such production alternatives as for consumption , and \"guns\" vs \"butter\".Opportunity cost is the economic cost of production: the value of the next best opportunity foregone. Choices must be made between desirable yet mutually exclusive actions. It has been described as expressing \"the basic relationship between scarcity and choice\".[31] For example, if a baker uses a sack of flour to make pretzels one morning, then the baker cannot use either the flour or the morning to make bagels instead. Part of the cost of making pretzels is that neither the flour nor the morning are available any longer, for use in some other way. The opportunity cost of an activity is an element in ensuring that scarce resources are used efficiently, such that the cost is weighed against the value of that activity in deciding on more or less of it. Opportunity costs are not restricted to monetary or financial costs but could be measured by the real cost of output forgone, leisure, or anything else that provides the alternative benefit .[32]Inputs used in the production process include such primary factors of production as labour services, capital . Other inputs may include intermediate goods used in production of final goods, such as the steel in a new car.Economic efficiency measures how well a system generates desired output with a given set of inputs and available technology. Efficiency is improved if more output is generated without changing inputs, or in other words, the amount of \"waste\" is reduced. A widely accepted general standard is Pareto efficiency, which is reached when no further change can make someone better off without making someone else worse off.The production\u2013possibility frontier  showing the different quantity combinations of the two goods producible with a given technology and total factor inputs, which limit feasible total output. Each point on the curve shows potential total output for the economy, which is the maximum feasible output of one good, given a feasible output quantity of the other good.Scarcity is represented in the figure by people being willing but unable in the aggregate to consume beyond the PPF  and by the negative slope of the curve.[33] If production of one good increases along the curve, production of the other good decreases, an inverse relationship. This is because increasing output of one good requires transferring inputs to it from production of the other good, decreasing the latter.The slope of the curve at a point on it gives the trade-off between the two goods. It measures what an additional unit of one good costs in units forgone of the other good, an example of a real opportunity cost. Thus, if one more Gun costs 100 units of butter, the opportunity cost of one Gun is 100 Butter. Along the PPF, scarcity implies that choosing more of one good in the aggregate entails doing with less of the other good. Still, in a market economy, movement along the curve may indicate that the choice of the increased output is anticipated to be worth the cost to the agents.By construction, each point on the curve shows productive efficiency in maximizing output for given total inputs. A point inside the curve  if it does not produce a mix of goods that consumers prefer over other points.Much applied economics in public policy is concerned with determining how the efficiency of an economy can be improved. Recognizing the reality of scarcity and then figuring out how to organize society for the most efficient use of resources has been described as the \"essence of economics\", where the subject \"makes its unique contribution.\"[34]Specialization is considered key to economic efficiency based on theoretical and empirical considerations. Different individuals or nations may have different real opportunity costs of production, say from differences in stocks of human capital per worker or capital/labour ratios. According to theory, this may give a comparative advantage in production of goods that make more intensive use of the relatively more abundant, thus relatively cheaper, input.Even if one region has an absolute advantage as to the ratio of its outputs to inputs in every type of output, it may still specialize in the output in which it has a comparative advantage and thereby gain from trading with a region that lacks any absolute advantage but has a comparative advantage in producing something else.It has been observed that a high volume of trade occurs among regions even with access to a similar technology and mix of factor inputs, including high-income countries. This has led to investigation of economies of scale and agglomeration to explain specialization in similar but differentiated product lines, to the overall benefit of respective trading parties or regions.[35]The general theory of specialization applies to trade among individuals, farms, manufacturers, service providers, and economies. Among each of these production systems, there may be a corresponding division of labour with different work groups specializing, or correspondingly different types of capital equipment and differentiated land uses.[36]An example that combines features above is a country that specializes in the production of high-tech knowledge products, as developed countries do, and trades with developing nations for goods produced in factories where labour is relatively cheap and plentiful, resulting in different in opportunity costs of production. More total output and utility thereby results from specializing in production and trading than if each country produced its own high-tech and low-tech products.Theory and observation set out the conditions such that market prices of outputs and productive inputs select an allocation of factor inputs by comparative advantage, so that  low-cost inputs go to producing low-cost outputs. In the process, aggregate output may increase as a by-product or by design.[37] Such specialization of production creates opportunities for gains from trade whereby resource owners benefit from trade in the sale of one type of output for other, more highly valued goods. A measure of gains from trade is the increased income levels that trade may facilitate.[38]Prices and quantities have been described as the most directly observable attributes of goods produced and exchanged in a market economy.[39] The theory of supply and demand is an organizing principle for explaining how prices coordinate the amounts produced and consumed. In microeconomics, it applies to price and output determination for a market with perfect competition, which includes the condition of no buyers or sellers large enough to have price-setting power.For a given market of a commodity, demand is the relation of the quantity that all buyers would be prepared to purchase at each unit price of the good. Demand is often represented by a table or a graph showing price and quantity demanded . Here, utility refers to the hypothesized relation of each individual consumer for ranking different commodity bundles as more or less preferred.The law of demand states that, in general, price and quantity demanded in a given market are inversely related. That is, the higher the price of a product, the less of it people would be prepared to buy . Other factors can change demand; for example an increase in income will shift the demand curve for a normal good outward relative to the origin, as in the figure. All determinants are predominantly taken as constant factors of demand and supply.Supply is the relation between the price of a good and the quantity available for sale at that price. It may be represented as a table or graph relating price and quantity supplied. Producers, for example business firms, are hypothesized to be profit-maximizers, meaning that they attempt to produce and supply the amount of goods that will bring them the highest profit. Supply is typically represented as a function relating price and quantity, if other factors are unchanged.That is, the higher the price at which the good can be sold, the more of it producers will supply, as in the figure. The higher price makes it profitable to increase production. Just as on the demand side, the position of the supply can shift, say from a change in the price of a productive input or a technical improvement. The \"Law of Supply\" states that, in general, a rise in price leads to an expansion in supply and a fall in price leads to a contraction in supply. Here as well, the determinants of supply, such as price of substitutes, cost of production, technology applied and various factors inputs of production are all taken to be constant for a specific time period of evaluation of supply.Market equilibrium occurs where quantity supplied equals quantity demanded, the intersection of the supply and demand curves in the figure above. At a price below equilibrium, there is a shortage of quantity supplied compared to quantity demanded. This is posited to bid the price up. At a price above equilibrium, there is a surplus of quantity supplied compared to quantity demanded. This pushes the price down. The model of supply and demand predicts that for given supply and demand curves, price and quantity will stabilize at the price that makes quantity supplied equal to quantity demanded. Similarly, demand-and-supply theory predicts a new price-quantity combination from a shift in demand , or in supply.For a given quantity of a consumer good, the point on the demand curve indicates the value, or marginal utility, to consumers for that unit. It measures what the consumer would be prepared to pay for that unit.[40] The corresponding point on the supply curve measures marginal cost, the increase in total cost to the supplier for the corresponding unit of the good. The price in equilibrium is determined by supply and demand. In a perfectly competitive market, supply and demand equate marginal cost and marginal utility at equilibrium.[41]On the supply side of the market, some factors of production are described as  of the supply curve in the short and long runs and corresponding differences in the price-quantity change from a shift on the supply or demand side of the market.Marginalist theory, such as above, describes the consumers as attempting to reach most-preferred positions, subject to income and wealth constraints while producers attempt to maximize profits subject to their own constraints, including demand for goods produced, technology, and the price of inputs. For the consumer, that point comes where marginal utility of a good, net of price, reaches zero, leaving no net gain from further consumption increases. Analogously, the producer compares marginal revenue  against the marginal cost of a good, with marginal profit the difference. At the point where marginal profit reaches zero, further increases in production of the good stop. For movement to market equilibrium and for changes in equilibrium, price and quantity also change \"at the margin\": more-or-less of something, rather than necessarily all-or-nothing.Other applications of demand and supply include the distribution of income among the factors of production, including labour and capital, through factor markets. In a competitive labour market for example the quantity of labour employed and the price of labour employment, productivity through human capital, and related public-policy issues.[42]Demand-and-supply analysis is used to explain the behaviour of perfectly competitive markets, but as a standard of comparison it can be extended to any type of market. It can also be generalized to explain variables across the economy, for example, total output  and the general price level, as studied in macroeconomics.[43] Tracing the qualitative and quantitative effects of variables that change supply and demand, whether in the short or long run, is a standard exercise in applied economics. Economic theory may also specify conditions such that supply and demand through the market is an efficient mechanism for allocating resources.[44]People frequently do not trade directly on markets. Instead, on the supply side, they may work in and produce through firms. The most obvious kinds of firms are corporations, partnerships and trusts. According to Ronald Coase, people begin to organize their production in firms when the costs of doing business becomes lower than doing it on the market.[45] Firms combine labour and capital, and can achieve far greater economies of scale  than individual market trading.In perfectly competitive markets studied in the theory of supply and demand, there are many producers, none of which significantly influence price. Industrial organization generalizes from that special case to study the strategic behaviour of firms that do have significant control of price. It considers the structure of such markets and their interactions. Common market structures studied besides perfect competition include monopolistic competition, various forms of oligopoly, and monopoly.[46]Managerial economics applies microeconomic analysis to specific decisions in business firms or other management units. It draws heavily from quantitative methods such as operations research and programming and from statistical methods such as regression analysis in the absence of certainty and perfect knowledge. A unifying theme is the attempt to optimize business decisions, including unit-cost minimization and profit maximization, given the firm's objectives and constraints imposed by technology and market conditions.[47]Uncertainty in economics is an unknown prospect of gain or loss, whether quantifiable as risk or not. Without it, household behaviour would be unaffected by uncertain employment and income prospects, financial and capital markets would reduce to exchange of a single instrument in each market period, and there would be no communications industry.[48] Given its different forms, there are various ways of representing uncertainty and modelling economic agents' responses to it.[49]Game theory is a branch of applied mathematics that considers strategic interactions between agents, one kind of uncertainty. It provides a mathematical foundation of industrial organization, discussed above, to model different types of firm behaviour, for example in an oligopolistic industry , but equally applicable to wage negotiations, bargaining, contract design, and any situation where individual agents are few enough to have perceptible effects on each other. In behavioural economics, it has been used to model the strategies agents choose when interacting with others whose interests are at least partially adverse to their own.[50]In this, it generalizes maximization approaches developed to analyse market actors such as in the supply and demand model and allows for incomplete information of actors. The field dates from the 1944 classic Theory of Games and Economic Behavior by John von Neumann and Oskar Morgenstern. It has significant applications seemingly outside of economics in such diverse subjects as formulation of nuclear strategies, ethics, political science, and evolutionary biology.[51]Risk aversion may stimulate activity that in well-functioning markets smooths out risk and communicates information about risk, as in markets for insurance, commodity futures contracts, and financial instruments. Financial economics or simply finance describes the allocation of financial resources. It also analyses the pricing of financial instruments, the financial structure of companies, the efficiency and fragility of financial markets,[52] financial crises, and related government policy or regulation.[53]Some market organizations may give rise to inefficiencies associated with uncertainty. Based on George Akerlof's \"Market for Lemons\" article, the paradigm example is of a dodgy second-hand car market. Customers without knowledge of whether a car is a \"lemon\" depress its price below what a quality second-hand car would be.[54] Information asymmetry arises here, if the seller has more relevant information than the buyer but no incentive to disclose it. Related problems in insurance are adverse selection, such that those at most risk are most likely to insure .[55]Both problems may raise insurance costs and reduce efficiency by driving otherwise willing transactors from the market . Moreover, attempting to reduce one problem, say adverse selection by mandating insurance, may add to another, say moral hazard. Information economics, which studies such problems, has relevance in subjects such as insurance, contract law, mechanism design, monetary economics, and health care.[55] Applied subjects include market and legal remedies to spread or reduce risk, such as warranties, government-mandated partial insurance, restructuring or bankruptcy law, inspection, and regulation for quality and information disclosure.[56][57]The term \"market failure\" encompasses several problems which may undermine standard economic assumptions. Although economists categorize market failures differently, the following categories emerge in the main texts.[b]Information asymmetries and incomplete markets may result in economic inefficiency but also a possibility of improving efficiency through market, legal, and regulatory remedies, as discussed above.Natural monopoly, or the overlapping concepts of \"practical\" and \"technical\" monopoly, is an extreme case of failure of competition as a restraint on producers. Extreme economies of scale are one possible cause.Public goods are goods which are undersupplied in a typical market. The defining features are that people can consume public goods without having to pay for them and that more than one person can consume the good at the same time.Externalities occur where there are significant social costs or benefits from production or consumption that are not reflected in market prices. For example, air pollution may generate a negative externality, and education may generate a positive externality . Governments often tax and otherwise restrict the sale of goods that have negative externalities and subsidize or otherwise promote the purchase of goods that have positive externalities in an effort to correct the price distortions caused by these externalities.[58] Elementary demand-and-supply theory predicts equilibrium but not the speed of adjustment for changes of equilibrium due to a shift in demand or supply.[59]In many areas, some form of price stickiness is postulated to account for quantities, rather than prices, adjusting in the short run to changes on the demand side or the supply side. This includes standard analysis of the business cycle in macroeconomics. Analysis often revolves around causes of such price stickiness and their implications for reaching a hypothesized long-run equilibrium. Examples of such price stickiness in particular markets include wage rates in labour markets and posted prices in markets deviating from perfect competition.Some specialized fields of economics deal in market failure more than others. The economics of the public sector is one example. Much environmental economics concerns externalities or \"public bads\".Policy options include regulations that reflect cost-benefit analysis or market solutions that change incentives, such as emission fees or redefinition of property rights.[60]Public finance is the field of economics that deals with budgeting the revenues and expenditures of a public sector entity, usually government. The subject addresses such matters as tax incidence , cost-benefit analysis of government programmes, effects on economic efficiency and income distribution of different kinds of spending and taxes, and fiscal politics. The latter, an aspect of public choice theory, models public-sector behaviour analogously to microeconomics, involving interactions of self-interested voters, politicians, and bureaucrats.[61]Much of economics is positive, seeking to describe and predict economic phenomena. Normative economics seeks to identify what economies ought to be like.Welfare economics is a normative branch of economics that uses microeconomic techniques to simultaneously determine the allocative efficiency within an economy and the income distribution associated with it. It attempts to measure social welfare by examining the economic activities of the individuals that comprise society.[62]Macroeconomics examines the economy as a whole to explain broad aggregates and their interactions \"top down\", that is, using a simplified form of general-equilibrium theory.[63] Such aggregates include national income and output, the unemployment rate, and price inflation and subaggregates like total consumption and investment spending and their components. It also studies effects of monetary policy and fiscal policy.Since at least the 1960s, macroeconomics has been characterized by further integration as to micro-based modelling of sectors, including rationality of players, efficient use of market information, and imperfect competition.[64] This has addressed a long-standing concern about inconsistent developments of the same subject.[65]Macroeconomic analysis also considers factors affecting the long-term level and growth of national income. Such factors include capital accumulation, technological change and labour force growth.[66]Growth economics studies factors that explain economic growth\u00a0\u2013 the increase in output per capita of a country over a long period of time. The same factors are used to explain differences in the level of output per capita between countries, in particular why some countries grow faster than others, and whether countries converge at the same rates of growth.Much-studied factors include the rate of investment, population growth, and technological change. These are represented in theoretical and empirical forms  and in growth accounting.[67]The economics of a depression were the spur for the creation of \"macroeconomics\" as a separate discipline field of study. During the Great Depression of the 1930s, John Maynard Keynes authored a book entitled The General Theory of Employment, Interest and Money outlining the key theories of Keynesian economics. Keynes contended that aggregate demand for goods might be insufficient during economic downturns, leading to unnecessarily high unemployment and losses of potential output.He therefore advocated active policy responses by the public sector, including monetary policy actions by the central bank and fiscal policy actions by the government to stabilize output over the business cycle.[68] Thus, a central conclusion of Keynesian economics is that, in some situations, no strong automatic mechanism moves output and employment towards full employment levels. John Hicks' IS/LM model has been the most influential interpretation of The General Theory.Over the years, understanding of the business cycle has branched into various research programmes, mostly related to or distinct from Keynesianism. The neoclassical synthesis refers to the reconciliation of Keynesian economics with neoclassical economics, stating that Keynesianism is correct in the short run but qualified by neoclassical-like considerations in the intermediate and long run.[69]New classical macroeconomics, as distinct from the Keynesian view of the business cycle, posits market clearing with imperfect information. It includes Friedman's permanent income hypothesis on consumption and \"rational expectations\" theory,[70] led by Robert Lucas, and real business cycle theory.[71]In contrast, the new Keynesian approach retains the rational expectations assumption, however it assumes a variety of market failures. In particular, New Keynesians assume prices and wages are \"sticky\", which means they do not adjust instantaneously to changes in economic conditions.[72]Thus, the new classicals assume that prices and wages adjust automatically to attain full employment, whereas the new Keynesians see full employment as being automatically achieved only in the long run, and hence government and central-bank policies are needed because the \"long run\" may be very long.The amount of unemployment in an economy is measured by the unemployment rate, the percentage of workers without jobs in the labour force. The labour force only includes workers actively looking for jobs. People who are retired, pursuing education, or discouraged from seeking work by a lack of job prospects are excluded from the labour force. Unemployment can be generally broken down into several types that are related to different causes.[73]Classical models of unemployment occurs when wages are too high for employers to be willing to hire more workers. Wages may be too high because of minimum wage laws or union activity. Consistent with classical unemployment, frictional unemployment occurs when appropriate job vacancies exist for a worker, but the length of time needed to search for and find the job leads to a period of unemployment.[73]Structural unemployment covers a variety of possible causes of unemployment including a mismatch between workers' skills and the skills required for open jobs.[74] Large amounts of structural unemployment can occur when an economy is transitioning industries and workers find their previous set of skills are no longer in demand. Structural unemployment is similar to frictional unemployment since both reflect the problem of matching workers with job vacancies, but structural unemployment covers the time needed to acquire new skills not just the short term search process.[75]While some types of unemployment may occur regardless of the condition of the economy, cyclical unemployment occurs when growth stagnates. Okun's law represents the empirical relationship between unemployment and economic growth.[76] The original version of Okun's law states that a 3% increase in output would lead to a 1% decrease in unemployment.[77]Money is a means of final payment for goods in most price system economies, and is the unit of account in which prices are typically stated. Money has general acceptability, relative consistency in value, divisibility, durability, portability, elasticity in supply, and longevity with mass public confidence. It includes currency held by the nonbank public and checkable deposits. It has been described as a social convention, like language, useful to one largely because it is useful to others. In the words of Francis Amasa Walker, a well-known 19th-century economist, \"Money is what money does\" .[78]As a medium of exchange, money facilitates trade. It is essentially a measure of value and more importantly, a store of value being a basis for credit creation. Its economic function can be contrasted with barter . Given a diverse array of produced goods and specialized producers, barter may entail a hard-to-locate double coincidence of wants as to what is exchanged, say apples and a book. Money can reduce the transaction cost of exchange because of its ready acceptability. Then it is less costly for the seller to accept money in exchange, rather than what the buyer produces.[79]At the level of an economy, theory and evidence are consistent with a positive relationship running from the total money supply to the nominal value of total output and to the general price level. For this reason, management of the money supply is a key aspect of monetary policy.[80]Governments implement fiscal policy that influence macroeconomic conditions by adjusting spending and taxation policies to alter aggregate demand. When aggregate demand falls below the potential output of the economy, there is an output gap where some productive capacity is left unemployed. Governments increase spending and cut taxes to boost aggregate demand. Resources that have been idled can be used by the government.For example, unemployed home builders can be hired to expand highways. Tax cuts allow consumers to increase their spending, which boosts aggregate demand. Both tax cuts and spending have multiplier effects where the initial increase in demand from the policy percolates through the economy and generates additional economic activity.The effects of fiscal policy can be limited by crowding out. When there is no output gap, the economy is producing at full capacity and there are no excess productive resources. If the government increases spending in this situation, the government uses resources that otherwise would have been used by the private sector, so there is no increase in overall output. Some economists think that crowding out is always an issue while others do not think it is a major issue when output is depressed.Sceptics of fiscal policy also make the argument of Ricardian equivalence. They argue that an increase in debt will have to be paid for with future tax increases, which will cause people to reduce their consumption and save money to pay for the future tax increase. Under Ricardian equivalence, any boost in demand from tax cuts will be offset by the increased saving intended to pay for future higher taxes.International trade studies determinants of goods-and-services flows across international boundaries. It also concerns the size and distribution of gains from trade. Policy applications include estimating the effects of changing tariff rates and trade quotas. International finance is a macroeconomic field which examines the flow of capital across international borders, and the effects of these movements on exchange rates. Increased trade in goods, services and capital between countries is a major effect of contemporary globalization.[81]The distinct field of development economics examines economic aspects of the economic development process in relatively low-income countries focusing on structural change, poverty, and economic growth. Approaches in development economics frequently incorporate social and political factors.[82]Economic systems is the branch of economics that studies the methods and institutions by which societies determine the ownership, direction, and allocation of economic resources. An economic system of a society is the unit of analysis.Among contemporary systems at different ends of the organizational spectrum are socialist systems and capitalist systems, in which most production occurs in respectively state-run and private enterprises. In between are mixed economies. A common element is the interaction of economic and political influences, broadly described as political economy. Comparative economic systems studies the relative performance and behaviour of different economies or systems.[83]The U.S. Export-Import Bank defines a Marxist-Lenninist state as having a centrally planned economy.[84] They are now rare; examples can still be seen in Cuba, North Korea and Laos.[85][needs update]Contemporary economics uses mathematics. Economists draw on the tools of calculus, linear algebra, statistics, game theory, and computer science.[86] Professional economists are expected to be familiar with these tools, while a minority specialize in econometrics and mathematical methods.Mainstream economic theory relies upon a priori quantitative economic models, which employ a variety of concepts. Theory typically proceeds with an assumption of ceteris paribus, which means holding constant explanatory variables other than the one under consideration. When creating theories, the objective is to find ones which are at least as simple in information requirements, more precise in predictions, and more fruitful in generating additional research than prior theories.[87]In microeconomics, principal concepts include supply and demand, marginalism, rational choice theory, opportunity cost, budget constraints, utility, and the theory of the firm.[88] Early macroeconomic models focused on modeling the relationships between aggregate variables, but as the relationships appeared to change over time macroeconomists, including new Keynesians, reformulated their models in microfoundations.[72]The aforementioned microeconomic concepts play a major part in macroeconomic models\u00a0\u2013 for instance, in monetary theory, the quantity theory of money predicts that increases in the growth rate of the money supply increase inflation, and inflation is assumed to be influenced by rational expectations. In development economics, slower growth in developed nations has been sometimes predicted because of the declining marginal returns of investment and capital, and this has been observed in the Four Asian Tigers. Sometimes an economic hypothesis is only qualitative, not quantitative.[89]Expositions of economic reasoning often use two-dimensional graphs to illustrate theoretical relationships. At a higher level of generality, Paul Samuelson's treatise Foundations of Economic Analysis  used mathematical methods beyond graphs to represent the theory, particularly as to maximizing behavioural relations of agents reaching equilibrium. The book focused on examining the class of statements called operationally meaningful theorems in economics, which are theorems that can conceivably be refuted by empirical data.[90]Economic theories are frequently tested empirically, largely through the use of econometrics using economic data.[91] The controlled experiments common to the physical sciences are difficult and uncommon in economics,[92] and instead broad data is observationally studied; this type of testing is typically regarded as less rigorous than controlled experimentation, and the conclusions typically more tentative. However, the field of experimental economics is growing, and increasing use is being made of natural experiments.Statistical methods such as regression analysis are common. Practitioners use such methods to estimate the size, economic significance, and statistical significance  and to adjust for noise from other variables. By such means, a hypothesis may gain acceptance, although in a probabilistic, rather than certain, sense. Acceptance is dependent upon the falsifiable hypothesis surviving tests. Use of commonly accepted methods need not produce a final conclusion or even a consensus on a particular question, given different tests, data sets, and prior beliefs.Criticisms based on professional standards and non-replicability of results serve as further checks against bias, errors, and over-generalization,[93][94] although much economic research has been accused of being non-replicable, and prestigious journals have been accused of not facilitating replication through the provision of the code and data.[95] Like theories, uses of test statistics are themselves open to critical analysis,[96] although critical commentary on papers in economics in prestigious journals such as the American Economic Review has declined precipitously in the past 40 years. This has been attributed to journals' incentives to maximize citations in order to rank higher on the Social Science Citation Index .[97]In applied economics, input-output models employing linear programming methods are quite common. Large amounts of data are run through computer programs to analyse the impact of certain policies; IMPLAN is one well-known example.Experimental economics has promoted the use of scientifically controlled experiments. This has reduced the long-noted distinction of economics from natural sciences because it allows direct tests of what were previously taken as axioms.[98] In some cases these have found that the axioms are not entirely correct; for example, the ultimatum game has revealed that people reject unequal offers.In behavioural economics, psychologist Daniel Kahneman won the Nobel Prize in economics in 2002 for his and Amos Tversky's empirical discovery of several cognitive biases and heuristics. Similar empirical testing occurs in neuroeconomics. Another example is the assumption of narrowly selfish preferences versus a model that tests for selfish, altruistic, and cooperative preferences.[99] These techniques have led some to argue that economics is a \"genuine science\".[100]The professionalization of economics, reflected in the growth of graduate programmes on the subject, has been described as \"the main change in economics since around 1900\".[101] Most major universities and many colleges have a major, school, or department in which academic degrees are awarded in the subject, whether in the liberal arts, business, or for professional study.In the private sector, professional economists are employed as consultants and in industry, including banking and finance. Economists also work for various government departments and agencies, for example, the national Treasury, Central Bank or Bureau of Statistics.The Nobel Memorial Prize in Economic Sciences  is a prize awarded to economists each year for outstanding intellectual contributions in the field.Economics is one social science among several and has fields bordering on other areas, including economic geography, economic history, public choice, energy economics, cultural economics, family economics and institutional economics.Law and economics, or economic analysis of law, is an approach to legal theory that applies methods of economics to law. It includes the use of economic concepts to explain the effects of legal rules, to assess which legal rules are economically efficient, and to predict what the legal rules will be.[102] A seminal article by Ronald Coase published in 1961 suggested that well-defined property rights could overcome the problems of externalities.[103]Political economy is the interdisciplinary study that combines economics, law, and political science in explaining how political institutions, the political environment, and the economic system  influence each other. It studies questions such as how monopoly, rent-seeking behaviour, and externalities should impact government policy.[104] Historians have employed political economy to explore the ways in the past that persons and groups with common economic interests have used politics to effect changes beneficial to their interests.[105]Energy economics is a broad scientific subject area which includes topics related to energy supply and energy demand. Georgescu-Roegen reintroduced the concept of entropy in relation to economics and energy from thermodynamics, as distinguished from what he viewed as the mechanistic foundation of neoclassical economics drawn from Newtonian physics. His work contributed significantly to thermoeconomics and to ecological economics. He also did foundational work which later developed into evolutionary economics.[106]The sociological subfield of economic sociology arose, primarily through the work of \u00c9mile Durkheim, Max Weber and Georg Simmel, as an approach to analysing the effects of economic phenomena in relation to the overarching social paradigm . More recently, the works of Mark Granovetter, Peter Hedstrom and Richard Swedberg have been influential in this field.Economic writings date from earlier Mesopotamian, Greek, Roman, Indian subcontinent, Chinese, Persian, and Arab civilizations. Economic precepts occur throughout the writings of the Boeotian poet Hesiod and several economic historians have described Hesiod himself as the \"first economist\".[108] Other notable writers from Antiquity through to the Renaissance include Aristotle, Xenophon, Chanakya , Qin Shi Huang, Thomas Aquinas, and Ibn Khaldun. Joseph Schumpeter described Aquinas as \"coming nearer than any other group to being the \"founders' of scientific economics\" as to monetary, interest, and value theory within a natural-law perspective.[109][not in citation given]Two groups, later called \"mercantilists\" and \"physiocrats\", more directly influenced the subsequent development of the subject. Both groups were associated with the rise of economic nationalism and modern capitalism in Europe. Mercantilism was an economic doctrine that flourished from the 16th to 18th century in a prolific pamphlet literature, whether of merchants or statesmen. It held that a nation's wealth depended on its accumulation of gold and silver. Nations without access to mines could obtain gold and silver from trade only by selling goods abroad and restricting imports other than of gold and silver. The doctrine called for importing cheap raw materials to be used in manufacturing goods, which could be exported, and for state regulation to impose protective tariffs on foreign manufactured goods and prohibit manufacturing in the colonies.[110]Physiocrats, a group of 18th-century French thinkers and writers, developed the idea of the economy as a circular flow of income and output. Physiocrats believed that only agricultural production generated a clear surplus over cost, so that agriculture was the basis of all wealth. Thus, they opposed the mercantilist policy of promoting manufacturing and trade at the expense of agriculture, including import tariffs. Physiocrats advocated replacing administratively costly tax collections with a single tax on income of land owners. In reaction against copious mercantilist trade regulations, the physiocrats advocated a policy of laissez-faire, which called for minimal government intervention in the economy.[111]Adam Smith  was an early economic theorist.[112] Smith was harshly critical of the mercantilists but described the physiocratic system \"with all its imperfections\" as \"perhaps the purest approximation to the truth that has yet been published\" on the subject.[113]The publication of Adam Smith's The Wealth of Nations in 1776, has been described as \"the effective birth of economics as a separate discipline.\"[114] The book identified land, labour, and capital as the three factors of production and the major contributors to a nation's wealth, as distinct from the physiocratic idea that only agriculture was productive.Smith discusses potential benefits of specialization by division of labour, including increased labour productivity and gains from trade, whether between town and country or across countries.[115] His \"theorem\" that \"the division of labor is limited by the extent of the market\" has been described as the \"core of a theory of the functions of firm and industry\" and a \"fundamental principle of economic organization.\"[116] To Smith has also been ascribed \"the most important substantive proposition in all of economics\" and foundation of resource-allocation theory \u2013 that, under competition, resource owners .[117]In an argument that includes \"one of the most famous passages in all economics,\"[118] Smith represents every individual as trying to employ any capital they might command for their own advantage, not that of the society,[c] and for the sake of profit, which is necessary at some level for employing capital in domestic industry, and positively related to the value of produce.[120] In this:The Rev. Thomas Robert Malthus  used the concept of diminishing returns to explain low living standards. Human population, he argued, tended to increase geometrically, outstripping the production of food, which increased arithmetically. The force of a rapidly growing population against a limited amount of land meant diminishing returns to labour. The result, he claimed, was chronically low wages, which prevented the standard of living for most of the population from rising above the subsistence level.[122] Economist Julian Lincoln Simon has criticized Malthus's conclusions.[123]While Adam Smith emphasized the production of income, David Ricardo  focused on the distribution of income among landowners, workers, and capitalists. Ricardo saw an inherent conflict between landowners on the one hand and labour and capital on the other. He posited that the growth of population and capital, pressing against a fixed supply of land, pushes up rents and holds down wages and profits. Ricardo was the first to state and prove the principle of comparative advantage, according to which each country should specialize in producing and exporting goods in that it has a lower relative cost of production, rather relying only on its own production.[124] It has been termed a \"fundamental analytical explanation\" for gains from trade.[125]Coming at the end of the classical tradition, John Stuart Mill  parted company with the earlier classical economists on the inevitability of the distribution of income produced by the market system. Mill pointed to a distinct difference between the market's two roles: allocation of resources and distribution of income. The market might be efficient in allocating resources but not in distributing income, he wrote, making it necessary for society to intervene.[126]Value theory was important in classical theory. Smith wrote that the \"real price of every thing\u00a0... is the toil and trouble of acquiring it\". Smith maintained that, with rent and profit, other costs besides wages also enter the price of a commodity.[127] Other classical economists presented variations on Smith, termed the 'labour theory of value'. Classical economics focused on the tendency of any market economy to settle in a final stationary state made up of a constant stock of physical wealth  and a constant population size.Marxist  economics descends from classical economics. It derives from the work of Karl Marx. The first volume of Marx's major work, Das Kapital, was published in German in 1867. In it, Marx focused on the labour theory of value and the theory of surplus value which, he believed, explained the exploitation of labour by capital.[128] The labour theory of value held that the value of an exchanged commodity was determined by the labour that went into its production and the theory of surplus value demonstrated how the workers only got paid a proportion of the value their work had created.[84]At the dawn as a social science, economics was defined and discussed at length as the study of production, distribution, and consumption of wealth by Jean-Baptiste Say in his Treatise on Political Economy or, The Production, Distribution, and Consumption of Wealth . For Robbins, the insufficiency was solved, and his definition allows us to proclaim, with an easy conscience, education economics, safety and security economics, health economics, war economics, and of course, production, distribution and consumption economics as valid subjects of the economic science.\"Citing Robbins: \"Economics is the science which studies human behavior as a relationship between ends and scarce means which have alternative uses\".[25] After discussing it for decades, Robbins' definition became widely accepted by mainstream economists, and it has opened way into current textbooks.[129] Although far from unanimous, most mainstream economists would accept some version of Robbins' definition, even though many have raised serious objections to the scope and method of economics, emanating from that definition.[130] Due to the lack of strong consensus, and that production, distribution and consumption of goods and services is the prime area of study of economics, the old definition still stands in many quarters.A body of theory later termed \"neoclassical economics\" or \"marginalism\" formed from about 1870 to 1910. The term \"economics\" was popularized by such neoclassical economists as Alfred Marshall as a concise synonym for \"economic science\" and a substitute for the earlier \"political economy\".[8][9] This corresponded to the influence on the subject of mathematical methods used in the natural sciences.[131]Neoclassical economics systematized supply and demand as joint determinants of price and quantity in market equilibrium, affecting both the allocation of output and the distribution of income. It dispensed with the labour theory of value inherited from classical economics in favour of a marginal utility theory of value on the demand side and a more general theory of costs on the supply side.[132] In the 20th century, neoclassical theorists moved away from an earlier notion suggesting that total utility for a society could be measured in favour of ordinal utility, which hypothesizes merely behaviour-based relations across persons.[41][133]In microeconomics, neoclassical economics represents incentives and costs as playing a pervasive role in shaping decision making. An immediate example of this is the consumer theory of individual demand, which isolates how prices  and income affect quantity demanded.[41] In macroeconomics it is reflected in an early and lasting neoclassical synthesis with Keynesian macroeconomics.[69][134]Neoclassical economics is occasionally referred as orthodox economics whether by its critics or sympathizers. Modern mainstream economics builds on neoclassical economics but with many refinements that either supplement or generalize earlier analysis, such as econometrics, game theory, analysis of market failure and imperfect competition, and the neoclassical model of economic growth for analysing long-run variables affecting national income.Neoclassical economics studies the behaviour of individuals, households, and organizations  is made by one or more resource-controlling players to attain the best possible outcome under bounded rational conditions. In other words, resource-controlling agents maximize value subject to the constraints imposed by the information the agents have, their cognitive limitations, and the finite amount of time they have to make and execute a decision. Economic science centres on the activities of the economic agents that comprise society.[135] They are the focus of economic analysis.[g]An approach to understanding these processes, through the study of agent behaviour under scarcity, may go as follows:The continuous interplay  of all variables involved is reached or until an external shock throws the system toward a new equilibrium point. Because of the autonomous actions of rational interacting agents, the economy is a complex adaptive system.[i]Keynesian economics derives from John Maynard Keynes, in particular his book The General Theory of Employment, Interest and Money , which ushered in contemporary macroeconomics as a distinct field.[136] The book focused on determinants of national income in the short run when prices are relatively inflexible. Keynes attempted to explain in broad theoretical detail why high labour-market unemployment might not be self-correcting due to low \"effective demand\" and why even price flexibility and monetary policy might be unavailing. The term \"revolutionary\" has been applied to the book in its impact on economic analysis.[137]Keynesian economics has two successors. Post-Keynesian economics also concentrates on macroeconomic rigidities and adjustment processes. Research on micro foundations for their models is represented as based on real-life practices rather than simple optimizing models. It is generally associated with the University of Cambridge and the work of Joan Robinson.[138]New-Keynesian economics is also associated with developments in the Keynesian fashion. Within this group researchers tend to share with other economists the emphasis on models employing micro foundations and optimizing behaviour but with a narrower focus on standard Keynesian themes such as price and wage rigidity. These are usually made to be endogenous features of the models, rather than simply assumed as in older Keynesian-style ones.The Chicago School of economics is best known for its free market advocacy and monetarist ideas. According to Milton Friedman and monetarists, market economies are inherently stable if the money supply does not greatly expand or contract. Ben Bernanke, former Chairman of the Federal Reserve, is among the economists today generally accepting Friedman's analysis of the causes of the Great Depression.[139]Milton Friedman effectively took many of the basic principles set forth by Adam Smith and the classical economists and modernized them. One example of this is his article in the 13 September 1970 issue of The New York Times Magazine, in which he claims that the social responsibility of business should be \"to use its resources and engage in activities designed to increase its profits\u00a0...  open and free competition without deception or fraud.\"[140]Other well-known schools or trends of thought referring to a particular style of economics practised at and disseminated from well-defined groups of academicians that have become known worldwide, include the Austrian School, the Freiburg School, the School of Lausanne, post-Keynesian economics and the Stockholm school. Contemporary mainstream economics is sometimes separated into the Saltwater approach of those universities along the Eastern and Western coasts of the US, and the Freshwater, or Chicago-school approach.Within macroeconomics there is, in general order of their appearance in the literature; classical economics, Keynesian economics, the neoclassical synthesis, post-Keynesian economics, monetarism, new classical economics, and supply-side economics. Alternative developments include ecological economics, constitutional economics, institutional economics, evolutionary economics, dependency theory, structuralist economics, world systems theory, econophysics, feminist economics and biophysical economics.[141]According to various random and anonymous surveys of members of the American Economic Association, economists have agreement about the following propositions by percentage:[142][143][144][145][146][147]\"The dismal science\" is a derogatory alternative name for economics devised by the Victorian historian Thomas Carlyle in the 19th century. It is often stated that Carlyle gave economics the nickname \"the dismal science\" as a response to the late 18th century writings of The Reverend Thomas Robert Malthus, who grimly predicted that starvation would result, as projected population growth exceeded the rate of increase in the food supply. However, the actual phrase was coined by Carlyle in the context of a debate with John Stuart Mill on slavery, in which Carlyle argued for slavery, while Mill opposed it.[21]Some economists, like John Stuart Mill or L\u00e9on Walras, have maintained that the production of wealth should not be tied to its distribution.[148]In The Wealth of Nations, Adam Smith addressed many issues that are currently also the subject of debate and dispute. Smith repeatedly attacks groups of politically aligned individuals who attempt to use their collective influence to manipulate a government into doing their bidding. In Smith's day, these were referred to as factions, but are now more commonly called special interests, a term which can comprise international bankers, corporate conglomerations, outright oligopolies, monopolies, trade unions and other groups.[j]Economics per se, as a social science, is independent of the political acts of any government or other decision-making organization; however, many policymakers or individuals holding highly ranked positions that can influence other people's lives are known for arbitrarily using a plethora of economic concepts and rhetoric as vehicles to legitimize agendas and value systems, and do not limit their remarks to matters relevant to their responsibilities.[149] The close relation of economic theory and practice with politics[150] is a focus of contention that may shade or distort the most unpretentious original tenets of economics, and is often confused with specific social agendas and value systems.[151]Notwithstanding, economics legitimately has a role in informing government policy. It is, indeed, in some ways an outgrowth of the older field of political economy. Some academic economic journals have increased their efforts to gauge the consensus of economists regarding certain policy issues in hopes of effecting a more informed political environment. Often there exists a low approval rate from professional economists regarding many public policies. Policy issues featured in one survey of American Economic Association economists include trade restrictions, social insurance for those put out of work by international competition, genetically modified foods, curbside recycling, health insurance , medical malpractice, barriers to entering the medical profession, organ donations, unhealthy foods, mortgage deductions, taxing internet sales, Wal-Mart, casinos, ethanol subsidies, and inflation targeting.[152]In Steady State Economics 1977, leading ecological economist and steady-state theorist Herman Daly argues that there exist logical inconsistencies between the emphasis placed on economic growth and the limited availability of natural resources.[153]Issues like central bank independence, central bank policies and rhetoric in central bank governors discourse or the premises of macroeconomic policies[154]  of the state, are focus of contention and criticism.[155]Deirdre McCloskey has argued that many empirical economic studies are poorly reported, and she and Stephen Ziliak argue that although her critique has been well-received, practice has not improved.[156] This latter contention is controversial.[157]A 2002 International Monetary Fund study looked at \"consensus forecasts\"  that were made in advance of 60 different national recessions in the 1990s: in 97% of the cases the economists did not predict the contraction a year in advance. On those rare occasions when economists did successfully predict recessions, they significantly underestimated their severity.[158]Economics has been subject to criticism that it relies on unrealistic, unverifiable, or highly simplified assumptions, in some cases because these assumptions simplify the proofs of desired conclusions. Examples of such assumptions include perfect information, profit maximization and rational choices.[159] The field of information economics includes both mathematical-economical research and also behavioural economics, akin to studies in behavioural psychology.[160]Nevertheless, prominent mainstream economists such as Keynes[161] and Joskow have observed that much of economics is conceptual rather than quantitative, and difficult to model and formalize quantitatively. In a discussion on oligopoly research, Paul Joskow pointed out in 1975 that in practice, serious students of actual economies tended to use \"informal models\" based upon qualitative factors specific to particular industries. Joskow had a strong feeling that the important work in oligopoly was done through informal observations while formal models were \"trotted out ex post\". He argued that formal models were largely not important in the empirical work, either, and that the fundamental factor behind the theory of the firm, behaviour, was neglected.[162]In recent years, feminist critiques of neoclassical economic models gained prominence, leading to the formation of feminist economics.[163] Contrary to common conceptions of economics as a positive and objective science, feminist economists call attention to the social construction of economics[164] and highlight the ways in which its models and methods reflect masculine preferences. Primary criticisms focus on failures to account for: the selfish nature of actors ; exogenous tastes; the impossibility of utility comparisons; the exclusion of unpaid work; and the exclusion of class and gender considerations. Feminist economics developed to address these concerns, and the field now includes critical examinations of many areas of economics including paid and unpaid work, economic epistemology and history, globalization, household economics and the care economy. In 1988, Marilyn Waring published the book If Women Counted, in which she argues that the discipline of economics ignores women's unpaid work and the value of nature;[165] according to Julie A. Nelson, If Women Counted \"showed exactly how the unpaid work traditionally done by women has been made invisible within national accounting systems\" and \"issued a wake-up call to issues of ecological sustainability.\"[166] Bj\u00f8rnholt and McKay argue that the financial crisis of 2007\u201308 and the response to it revealed a crisis of ideas in mainstream economics and within the economics profession, and call for a reshaping of both the economy, economic theory and the economics profession. They argue that such a reshaping should include new advances within feminist economics that take as their starting point the socially responsible, sensible and accountable subject in creating an economy and economic theories that fully acknowledge care for each other as well as the planet.[167]Philip Mirowski observes that:In a series of peer-reviewed journal and conference papers and books published over a period of several decades, John McMurtry has provided extensive criticism of what he terms the \"unexamined assumptions and implications [of economics], and their consequent cost to people's lives.\"[169][k]Nassim Nicholas Taleb and Michael Perelman are two additional scholars who criticized conventional or mainstream economics. Taleb opposes most economic theorizing, which in his view suffers acutely from the problem of overuse of Plato's Theory of Forms, and calls for cancellation of the Nobel Memorial Prize in Economics, saying that the damage from economic theories can be devastating.[170] Michael Perelman provides extensive criticism of economics and its assumptions in all his books , papers and interviews.Despite these concerns, mainstream graduate programs have become increasingly technical and mathematical.[171]General:"], "Human geography": ["Human geography is the branch of geography that deals with the study of people and their communities, cultures, economies, and interactions with the environment by studying their relations with and across space and place.[1] Human geography attends to human patterns of social interaction, as well as spatial level interdependencies, and how they influence or affect the earth's environment.[2][3] As an intellectual discipline, geography is divided into the sub-fields of physical geography and human geography, the latter concentrating upon the study of human activities, by the application of qualitative and quantitative research methods.Geography was not recognized as a formal academic discipline until the 18th century, although many scholars had undertaken geographical scholarship for much longer, particularly through cartography.The Royal Geographical Society was founded in England in 1830,[4] although the United Kingdom did not get its first full Chair of geography until 1917. The first real geographical intellect to emerge in United Kingdom's geographical minds was Halford John Mackinder, appointed reader at Oxford University in 1887.The National Geographic Society was founded in the United States in 1888 and began publication of the National Geographic magazine which became, and continues to be, a great popularizer of geographic information. The society has long supported geographic research and education on geographical topics.The Association of American Geographers was founded in 1904 and was renamed the American Association of Geographers in 2016 to better reflect the increasingly international character of its membership.One of the first examples of geographic methods being used for purposes other than to describe and theorize the physical properties of the earth is John Snow's map of the 1854 Broad Street cholera outbreak. Though a physician and a pioneer of epidemiology, the map is probably one of the earliest examples of health geography.The now fairly distinct differences between the subfields of physical and human geography have developed at a later date. This connection between both physical and human properties of geography is most apparent in the theory of environmental determinism, made popular in the 19th century by Carl Ritter and others, and has close links to the field of evolutionary biology of the time. Environmental determinism is the theory, that people's physical, mental and moral habits are directly due to the influence of their natural environment. However, by the mid-19th century, environmental determinism was under attack for lacking methodological rigor associated with modern science, and later as a means to justify racism and imperialism.A similar concern with both human and physical aspects is apparent during the later 19th and first half of the 20th centuries focused on regional geography.The goal of regional geography, through something known as regionalisation, was to delineate space into regions and then understand and describe the unique characteristics of each region through both human and physical aspects. With links to  and cultural ecology some of the same notions of causal effect of the environment on society and culture remain with environmental determinism.By the 1960s, however, the quantitative revolution led to strong criticism of regional geography. Due to a perceived lack of scientific rigor in an overly descriptive nature of the discipline, and a continued separation of geography from its two subfields of physical and human geography and from geology, geographers in the mid-20th century began to apply statistical and mathematical models in order to solve spatial problems.[1] Much of the development during the quantitative revolution is now apparent in the use of geographic information systems; the use of statistics, spatial modeling, and positivist approaches are still important to many branches of human geography. Well-known geographers from this period are Fred K. Schaefer, Waldo Tobler, William Garrison, Peter Haggett, Richard J. Chorley, William Bunge, and Torsten H\u00e4gerstrand.From the 1970s, a number of critiques of the positivism now associated with geography emerged. Known under the term 'critical geography,' these critiques signaled another turning point in the discipline. Behavioral geography emerged for some time as a means to understand how people made perceived spaces and places, and made locational decisions. The more influential 'radical geography' emerged in the 1970s and 1980s. It draws heavily on Marxist's theory and techniques, and is associated with geographers such as David Harvey and Richard Peet. Radical geographers seek to say meaningful things about problems recognized through quantitative methods,[5] provide explanations rather than descriptions, put forward alternatives and solutions, and be politically engaged,[6] rather than using the detachment associated with positivists. . Critical geography also saw the introduction of 'humanistic geography', associated with the work of Yi-Fu Tuan, which pushed for a much more qualitative approach in methodology.The changes under critical geography have led to contemporary approaches in the discipline such as feminist geography, new cultural geography, \"demonic\" geographies[7], and the engagement with postmodern and post-structural theories and philosophies.The primary fields of study in human geography focus around the core fields of:Cultural geography is the study of cultural products and norms - their variation across spaces and places, as well as their relations. It focuses on describing and analyzing the ways language, religion, economy, government, and other cultural phenomena vary or remain constant from one place to another and on explaining how humans function spatially.[8]Development geography is the study of the Earth's geography with reference to the standard of living and the quality of life of its human inhabitants, study of the location, distribution and spatial organization of economic activities, across the Earth. The subject matter investigated is strongly influenced by the researcher's methodological approach.Economic geography examines relationships between human economic systems, states, and other factors, and the biophysical environment.Health geography is the application of geographical information, perspectives, and methods to the study of health, disease, and health care. Health geography deals with the spatial relations and patterns between people and the environment. This is a sub-discipline of human geography, researching how and why diseases are spread.[9]Historical geography is the study of the human, physical, fictional, theoretical, and \"real\" geographies of the past. Historical geography studies a wide variety of issues and topics. A common theme is the study of the geographies of the past and how a place or region changes through time. Many historical geographers study geographical patterns through time, including how people have interacted with their environment, and created the cultural landscape.Political geography is concerned with the study of both the spatially uneven outcomes of political processes and the ways in which political processes are themselves affected by spatial structures.Population geography is the study of ways in which spatial variations in the distribution, composition, migration, and growth of populations are related to their environment or location.Settlement geography, including urban geography, is the study of urban and rural areas with specific regards to spatial, relational and theoretical aspects of settlement. That is the study of areas which have a concentration of buildings and infrastructure. These are areas where the majority of economic activities are in the secondary sector and tertiary sectors. In case of urban settlement, they probably have a high population density.[citation needed]Urban geography is the study of cities, towns, and other areas of relatively dense settlement. Two main interests are site . Another area of interest is the internal organization of urban areas with regard to different demographic groups and the layout of infrastructure. This subdiscipline also draws on ideas from other branches of Human Geography to see their involvement in the processes and patterns evident in an urban area.[10][11]Within each of the subfields, various philosophical approaches can be used in research; therefore, an urban geographer could be a Feminist or Marxist geographer, etc.Such approaches are:As with all social sciences, human geographers publish research and other written work in a variety of academic journals. Whilst human geography is interdisciplinary, there are a number of journals that focus on human geography.These include:"], "Law": ["Law is a system of rules that are created and enforced through social or governmental institutions to regulate behavior.[2] Law is a system that regulates and ensures that individuals or a community adhere to the will of the state. State-enforced laws can be made by a collective legislature or by a single legislator, resulting in statutes, by the executive through decrees and regulations, or established by judges through precedent, normally in common law jurisdictions. Private individuals can create legally binding contracts, including arbitration agreements that may elect to accept alternative arbitration to the normal court process. The formation of laws themselves may be influenced by a constitution, written or tacit, and the rights encoded therein. The law shapes politics, economics, history and society in various ways and serves as a mediator of relations between people.A general distinction can be made between  common law systems, where judge-made precedent is accepted as binding law. Historically, religious laws played a significant role even in settling of secular matters, and is still used in some religious communities. Islamic Sharia law is the world's most widely used religious law, and is used as the primary legal system in some countries, such as Iran and Saudi Arabia.[3]The adjudication of the law is generally divided into two main areas. Criminal law deals with conduct that is considered harmful to social order and in which the guilty party may be imprisoned or fined. Civil law  between individuals or organizations.[4]Law provides a source of scholarly inquiry into legal history, philosophy, economic analysis and sociology. Law also raises important and complex issues concerning equality, fairness, and justice.Numerous definitions of law have been put forward over the centuries. The Third New International Dictionary from Merriam-Webster[5] defines law as: \"Law is a binding custom or practice of a community; a rule or mode of conduct or action that is prescribed or formally recognized as binding by a supreme controlling authority or is made obligatory by a sanction  made, recognized, or enforced by the controlling authority.\"The Dictionary of the History of Ideas published by Scribner's in 1973 defined the concept of law accordingly as: \"A legal system is the most explicit, institutionalized, and complex mode of regulating human conduct. At the same time, it plays only one part in the congeries of rules which influence behavior, for social and moral rules of a less institutionalized kind are also of great importance.\"[6]There have been several attempts to produce \"a universally acceptable definition of law\". In 1972, one source indicated that no such definition could be produced.[7] McCoubrey and White said that the question \"what is law?\" has no simple answer.[8] Glanville Williams said that the meaning of the word \"law\" depends on the context in which that word is used. He said that, for example, \"early customary law\" and \"municipal law\" were contexts where the word \"law\" had two different and irreconcilable meanings.[9] Thurman Arnold said that it is obvious that it is impossible to define the word \"law\" and that it is also equally obvious that the struggle to define that word should not ever be abandoned.[10] It is possible to take the view that there is no need to define the word \"law\" .[11]The history of law links closely to the development of civilization. Ancient Egyptian law, dating as far back as 3000\u00a0BC, contained a civil code that was probably broken into twelve books. It was based on the concept of Ma'at, characterised by tradition, rhetorical speech, social equality and impartiality.[12][13] By the 22nd century\u00a0BC, the ancient Sumerian ruler Ur-Nammu had formulated the first law code, which consisted of casuistic statements . Around 1760\u00a0BC, King Hammurabi further developed Babylonian law, by codifying and inscribing it in stone. Hammurabi placed several copies of his law code throughout the kingdom of Babylon as stelae, for the entire public to see; this became known as the Codex Hammurabi. The most intact copy of these stelae was discovered in the 19th century by British Assyriologists, and has since been fully transliterated and translated into various languages, including English, Italian, German, and French.[14]The Old Testament dates back to 1280\u00a0BC and takes the form of moral imperatives as recommendations for a good society. The small Greek city-state, ancient Athens, from about the 8th century BC was the first society to be based on broad inclusion of its citizenry, excluding women and the slave class. However, Athens had no legal science or single word for \"law\",[15] relying instead on the three-way distinction between divine law .[16] Yet Ancient Greek law contained major constitutional innovations in the development of democracy.[17]Roman law was heavily influenced by Greek philosophy, but its detailed rules were developed by professional jurists and were highly sophisticated.[18][19] Over the centuries between the rise and decline of the Roman Empire, law was adapted to cope with the changing social situations and underwent major codification under Theodosius II and Justinian I.[20] Although codes were replaced by custom and case law during the Dark Ages, Roman law was rediscovered around the 11th century when medieval legal scholars began to research Roman codes and adapt their concepts. Latin legal maxims  were compiled for guidance. In medieval England, royal courts developed a body of precedent which later became the common law. A Europe-wide Law Merchant was formed so that merchants could trade with common standards of practice rather than with the many splintered facets of local laws. The Law Merchant, a precursor to modern commercial law, emphasised the freedom to contract and alienability of property.[21] As nationalism grew in the 18th and 19th centuries, the Law Merchant was incorporated into countries' local law under new civil codes. The Napoleonic and German Codes became the most influential. In contrast to English common law, which consists of enormous tomes of case law, codes in small books are easy to export and easy for judges to apply. However, today there are signs that civil and common law are converging.[22] EU law is codified in treaties, but develops through the precedent laid down by the European Court of Justice.Ancient India and China represent distinct traditions of law, and have historically had independent schools of legal theory and practice. The Arthashastra, probably compiled around 100\u00a0AD  were foundational treatises in India, and comprise texts considered authoritative legal guidance.[23] Manu's central philosophy was tolerance and pluralism, and was cited across Southeast Asia.[24] This Hindu tradition, along with Islamic law, was supplanted by the common law when India became part of the British Empire.[25] Malaysia, Brunei, Singapore and Hong Kong also adopted the common law. The eastern Asia legal tradition reflects a unique blend of secular and religious influences.[26] Japan was the first country to begin modernising its legal system along western lines, by importing bits of the French, but mostly the German Civil Code.[27] This partly reflected Germany's status as a rising power in the late 19th\u00a0century. Similarly, traditional Chinese law gave way to westernisation towards the final years of the Qing Dynasty in the form of six private law codes based mainly on the Japanese model of German law.[28] Today Taiwanese law retains the closest affinity to the codifications from that period, because of the split between Chiang Kai-shek's nationalists, who fled there, and Mao Zedong's communists who won control of the mainland in 1949. The current legal infrastructure in the People's Republic of China was heavily influenced by Soviet Socialist law, which essentially inflates administrative law at the expense of private law rights.[29] Due to rapid industrialisation, today China is undergoing a process of reform, at least in terms of economic, if not social and political, rights. A new contract code in 1999 represented a move away from administrative domination.[30] Furthermore, after negotiations lasting fifteen years, in 2001 China joined the World Trade Organisation.[31]The philosophy of law is commonly known as jurisprudence. Normative jurisprudence asks \"what should law be?\", while analytic jurisprudence asks \"what is law?\" John Austin's utilitarian answer was that law is \"commands, backed by threat of sanctions, from a sovereign, to whom people have a habit of obedience\".[33] Natural lawyers on the other side, such as Jean-Jacques Rousseau, argue that law reflects essentially moral and unchangeable laws of nature. The concept of \"natural law\" emerged in ancient Greek philosophy concurrently and in connection with the notion of justice, and re-entered the mainstream of Western culture through the writings of Thomas Aquinas, notably his Treatise on Law.Hugo Grotius, the founder of a purely rationalistic system of natural law, argued that law arises from both a social impulse\u2014as Aristotle had indicated\u2014and reason.[34] Immanuel Kant believed a moral imperative requires laws \"be chosen as though they should hold as universal laws of nature\".[35] Jeremy Bentham and his student Austin, following David Hume, believed that this conflated the \"is\" and what \"ought to be\" problem. Bentham and Austin argued for law's positivism; that real law is entirely separate from \"morality\".[36] Kant was also criticised by Friedrich Nietzsche, who rejected the principle of equality, and believed that law emanates from the will to power, and cannot be labelled as \"moral\" or \"immoral\".[37][38][39]In 1934, the Austrian philosopher Hans Kelsen continued the positivist tradition in his book the Pure Theory of Law.[40] Kelsen believed that although law is separate from morality, it is endowed with \"normativity\", meaning we ought to obey it. While laws are positive \"is\" statements , which denied that legal norms could encompass all of political experience.[42]Later in the 20th century, H. L. A. Hart attacked Austin for his simplifications and Kelsen for his fictions in The Concept of Law.[43] Hart argued law is a system of rules, divided into primary . Two of Hart's students continued the debate: In his book Law's Empire, Ronald Dworkin attacked Hart and the positivists for their refusal to treat law as a moral issue. Dworkin argues that law is an \"interpretive concept\",[44] that requires judges to find the best fitting and most just solution to a legal dispute, given their constitutional traditions. Joseph Raz, on the other hand, defended the positivist outlook and criticised Hart's \"soft social thesis\" approach in The Authority of Law.[45] Raz argues that law is authority, identifiable purely through social sources and without reference to moral reasoning. In his view, any categorisation of rules beyond their role as authoritative instruments in mediation are best left to sociology, rather than jurisprudence.[46]One definition is that law is a system of rules and guidelines which are enforced through social institutions to govern behaviour.[2] In The Concept of Law Hart argued law is a \"system of rules\";[47] Austin said law was \"the command of a sovereign, backed by the threat of a sanction\";[33] Dworkin describes law as an \"interpretive concept\" to achieve justice in his text titled Law's Empire;[48] and Raz argues law is an \"authority\" to mediate people's interests.[45] Holmes said \"The prophecies of what the courts will do in fact, and nothing more pretentious, are what I mean by the law.\"[49] In his Treatise on Law Aquinas argues that law is a rational ordering of things which concern the common good that is promulgated by whoever is charged with the care of the community.[50] This definition has both positivist and naturalist elements.[51]In the 18th century Adam Smith presented a philosophical foundation for explaining the relationship between law and economics.[52] The discipline arose partly out of a critique of trade unions and U.S. antitrust law. The most influential proponents, such as Richard Posner and Oliver Williamson and the so-called Chicago School of economists and lawyers including Milton Friedman and Gary Becker, are generally advocates of deregulation and privatisation, and are hostile to state regulation or what they see as restrictions on the operation of free markets.[53]The most prominent economic analyst of law is 1991 Nobel Prize winner Ronald Coase, whose first major article, The Nature of the Firm , argued that if we lived in a world without transaction costs, people would bargain with one another to create the same allocation of resources, regardless of the way a court might rule in property disputes.[56] Coase used the example of a nuisance case named Sturges v Bridgman, where a noisy sweetmaker and a quiet doctor were neighbours and went to court to see who should have to move.[57] Coase said that regardless of whether the judge ruled that the sweetmaker had to stop using his machinery, or that the doctor had to put up with it, they could strike a mutually beneficial bargain about who moves that reaches the same outcome of resource distribution. Only the existence of transaction costs may prevent this.[58] So the law ought to pre-empt what would happen, and be guided by the most efficient solution. The idea is that law and regulation are not as important or effective at helping people as lawyers and government planners believe.[59] Coase and others like him wanted a change of approach, to put the burden of proof for positive effects on a government that was intervening in the market, by analysing the costs of action.[60]Sociology of law is a diverse field of study that examines the interaction of law with society and overlaps with jurisprudence, philosophy of law, social theory and more specialised subjects such as criminology.[61] The institutions of social construction, social norms, dispute processing and legal culture are key areas for inquiry in this knowledge field. Sociology of law is sometimes seen as a sub-discipline of sociology, but its ties to the academic discipline of law are equally strong, and it is best seen as a transdisciplinary and multidisciplinary study focused on the theorisation and empirical study of legal practices and experiences as social phenomena. In the United States the field is usually called law and society studies; in Europe it is more often referred to as socio-legal studies. At first, jurists and legal philosophers were suspicious of sociology of law. Kelsen attacked one of its founders, Eugen Ehrlich, who sought to make clear the differences and connections between positive law, which lawyers learn and apply, and other forms of 'law' or social norms that regulate everyday life, generally preventing conflicts from reaching barristers and courts.[62] Contemporary research in sociology of law is much concerned with the way that law is developing outside discrete state jurisdictions, being produced through social interaction in many different kinds of social arenas, and acquiring a diversity of sources of  authority in communal networks existing sometimes within nation states but increasingly also transnationally.[63]Around 1900 Max Weber defined his \"scientific\" approach to law, identifying the \"legal rational form\" as a type of domination, not attributable to personal authority but to the authority of abstract norms.[64] Formal legal rationality was his term for the key characteristic of the kind of coherent and calculable law that was a precondition for modern political developments and the modern bureaucratic state. Weber saw this law as having developed in parallel with the growth of capitalism.[61] Another leading sociologist, \u00c9mile Durkheim, wrote in his classic work The Division of Labour in Society that as society becomes more complex, the body of civil law concerned primarily with restitution and compensation grows at the expense of criminal laws and penal sanctions.[65] Other notable early legal sociologists included Hugo Sinzheimer, Theodor Geiger, Georges Gurvitch and Leon Petra\u017cycki in Europe, and William Graham Sumner in the U.S.[66][67]In general, legal systems can be split between civil law and common law systems.[68] The term \"civil law\" referring to a legal system should not be confused with \"civil law\" as a group of legal subjects distinct from criminal or public law. A third type of legal system\u2014accepted by some countries without separation of church and state\u2014is religious law, based on scriptures. The specific system that a country is ruled by is often determined by its history, connections with other countries, or its adherence to international standards. The sources that jurisdictions adopt as authoritatively binding are the defining features of any legal system. Yet classification is a matter of form rather than substance, since similar rules often prevail.Civil law is the legal system used in most countries around the world today. In civil law the sources recognised as authoritative are, primarily, legislation\u2014especially codifications in constitutions or statutes passed by government\u2014and custom.[69] Codifications date back millennia, with one early example being the Babylonian Codex Hammurabi. Modern civil law systems essentially derive from the legal practice of the 6th-century Eastern Roman Empire whose texts were rediscovered by late medieval Western Europe. Roman law in the days of the Roman Republic and Empire was heavily procedural, and lacked a professional legal class.[70] Instead a lay magistrate, iudex, was chosen to adjudicate. Decisions were not published in any systematic way, so any case law that developed was disguised and almost unrecognised.[71] Each case was to be decided afresh from the laws of the State, which mirrors the , but also the Japanese and Korean legal traditions.[75][76] Today, countries that have civil law systems range from Russia and China to most of Central and Latin America.[77] With the exception of Louisiana's Civil Code, the United States follows the common law system described below.In common law legal systems, decisions by courts are explicitly acknowledged as \"law\" on equal footing with statutes adopted through the legislative process and with regulations issued by the executive branch. The \"doctrine of precedent\", or stare decisis  means that decisions by higher courts bind lower courts, and future decisions of the same court, to assure that similar cases reach similar results. In contrast, in \"civil law\" systems, legislative statutes are typically more detailed, and judicial decisions are shorter and less detailed, because the judge or barrister is only writing to decide the single case, rather than to set out reasoning that will guide future courts.Common law originated from England and has been inherited by almost every country once tied to the British Empire . In medieval England, the Norman conquest the law varied-shire-to-shire, based on disparate tribal customs. The concept of a \"common law\" developed during the reign of Henry II during the late 12th century, when Henry appointed judges that had authority to create an institutionalized and unified system of law \"common\" to the country. The next major step in the evolution of the common law came when King John was forced by his barons to sign a document limiting his authority to pass laws. This \"great charter\" or Magna Carta of 1215 also required that the King's entourage of judges hold their courts and judgments at \"a certain place\" rather than dispensing autocratic justice in unpredictable places about the country.[78] A concentrated and elite group of judges acquired a dominant role in law-making under this system, and compared to its European counterparts the English judiciary became highly centralized. In 1297, for instance, while the highest court in France had fifty-one judges, the English Court of Common Pleas had five.[79] This powerful and tight-knit judiciary gave rise to a systematized process of developing common law.[80]However, the system became overly systematized\u2014overly rigid and inflexible. As a result, as time went on, increasing numbers of citizens petitioned the King to override the common law, and on the King's behalf the Lord Chancellor gave judgment to do what was equitable in a case. From the time of Sir Thomas More, the first lawyer to be appointed as Lord Chancellor, a systematic body of equity grew up alongside the rigid common law, and developed its own Court of Chancery. At first, equity was often criticized as erratic, that it varied according to the length of the Chancellor's foot.[81] Over time, courts of equity developed solid principles, especially under Lord Eldon.[82] In the 19th century in England, and in 1937 in the U.S., the two systems were merged.In developing the common law, academic writings have always played an important part, both to collect overarching principles from dispersed case law, and to argue for change. William Blackstone, from around 1760, was the first scholar to collect, describe, and teach the common law.[83] But merely in describing, scholars who sought explanations and underlying structures slowly changed the way the law actually worked.[84]Religious law is explicitly based on religious precepts. Examples include the Jewish Halakha and Islamic Sharia\u2014both of which translate as the \"path to follow\"\u2014while Christian canon law also survives in some church communities. Often the implication of religion for law is unalterability, because the word of God cannot be amended or legislated against by judges or governments.[citation needed] However a thorough and detailed legal system generally requires human elaboration. For instance, the Quran has some law, and it acts as a source of further law through interpretation,[85] Qiyas  and precedent. This is mainly contained in a body of law and jurisprudence known as Sharia and Fiqh respectively. Another example is the Torah or Old Testament, in the Pentateuch or Five Books of Moses. This contains the basic code of Jewish law, which some Israeli communities choose to use. The Halakha is a code of Jewish law which summarises some of the Talmud's interpretations. Nevertheless, Israeli law allows litigants to use religious laws only if they choose. Canon law is only in use by members of the Catholic Church, the Eastern Orthodox Church and the Anglican Communion.Until the 18th century, Sharia law was practiced throughout the Muslim world in a non-codified form, with the Ottoman Empire's Mecelle code in the 19th century being a first attempt at codifying elements of Sharia law. Since the mid-1940s, efforts have been made, in country after country, to bring Sharia law more into line with modern conditions and conceptions.[86][87] In modern times, the legal systems of many Muslim countries draw upon both civil and common law traditions as well as Islamic law and custom. The constitutions of certain Muslim states, such as Egypt and Afghanistan, recognise Islam as the religion of the state, obliging legislature to adhere to Sharia.[88] Saudi Arabia recognises Quran as its constitution, and is governed on the basis of Islamic law.[89] Iran has also witnessed a reiteration of Islamic law into its legal system after 1979.[90] During the last few decades, one of the fundamental features of the movement of Islamic resurgence has been the call to restore the Sharia, which has generated a vast amount of literature and affected world politics.[91]The main institutions of law in industrialised countries are independent courts, representative parliaments, an accountable executive, the military and police, bureaucratic organisation, the legal profession and civil society itself. John Locke, in his Two Treatises of Government, and Baron de Montesquieu in The Spirit of the Laws, advocated for a separation of powers between the political, legislature and executive bodies.[92] Their principle was that no person should be able to usurp all powers of the state, in contrast to the absolutist theory of Thomas Hobbes' Leviathan.[93]Max Weber and others reshaped thinking on the extension of state. Modern military, policing and bureaucratic power over ordinary citizens' daily lives pose special problems for accountability that earlier writers such as Locke or Montesquieu could not have foreseen. The custom and practice of the legal profession is an important part of people's access to justice, whilst civil society is a term used to refer to the social institutions, communities and partnerships that form law's political basis.A judiciary is a number of judges mediating disputes to determine outcome. Most countries have systems of appeal courts, answering up to a supreme legal authority. In the United States, this authority is the Supreme Court;[94] in Australia, the High Court; in the UK, the Supreme Court;[95] in Germany, the Bundesverfassungsgericht; and in France, the Cour de Cassation.[96][97] For most European countries the European Court of Justice in Luxembourg can overrule national law, when EU law is relevant. The European Court of Human Rights in Strasbourg allows citizens of the Council of Europe member states to bring cases relating to human rights issues before it.[98]Some countries allow their highest judicial authority to overrule legislation they determine to be unconstitutional. For example, in Brown v. Board of Education, the United States Supreme Court nullified many state statutes that had established racially segregated schools, finding such statutes to be incompatible with the Fourteenth Amendment to the United States Constitution.[99]A judiciary is theoretically bound by the constitution, just as all other government bodies are. In most countries judges may only interpret the constitution and all other laws. But in common law countries, where matters are not constitutional, the judiciary may also create law under the doctrine of precedent. The UK, Finland and New Zealand assert the ideal of parliamentary sovereignty, whereby the unelected judiciary may not overturn law passed by a democratic legislature.[100]In communist states, such as China, the courts are often regarded as parts of the executive, or subservient to the legislature; governmental institutions and actors exert thus various forms of influence on the judiciary.[101] In Muslim countries, courts often examine whether state laws adhere to the Sharia: the Supreme Constitutional Court of Egypt may invalidate such laws,[102] and in Iran the Guardian Council ensures the compatibility of the legislation with the \"criteria of Islam\".[102][103]Prominent examples of legislatures are the Houses of Parliament in London, the Congress in Washington D.C., the Bundestag in Berlin, the Duma in Moscow, the Parlamento Italiano in Rome and the Assembl\u00e9e nationale in Paris. By the principle of representative government people vote for politicians to carry out their wishes. Although countries like Israel, Greece, Sweden and China are unicameral, most countries are bicameral, meaning they have two separately appointed legislative houses.[104]In the 'lower house' politicians are elected to represent smaller constituencies. The 'upper house' is usually elected to represent states in a federal system . In the UK the upper house is appointed by the government as a house of review. One criticism of bicameral systems with two elected chambers is that the upper and lower houses may simply mirror one another. The traditional justification of bicameralism is that an upper chamber acts as a house of review. This can minimise arbitrariness and injustice in governmental action.[104]To pass legislation, a majority of the members of a legislature must vote for a bill .[105]The executive in a legal system serves as the centre of political authority of the State. In a parliamentary system, as with Britain, Italy, Germany, India, and Japan, the executive is known as the cabinet, and composed of members of the legislature. The executive is led by the head of government, whose office holds power under the confidence of the legislature. Because popular elections appoint political parties to govern, the leader of a party can change in between elections.[106]The head of state is apart from the executive, and symbolically enacts laws and acts as representative of the nation. Examples include the President of Germany . The other important model is the presidential system, found in the United States and in Brazil. In presidential systems, the executive acts as both head of state and head of government, and has power to appoint an unelected cabinet. Under a presidential system, the executive branch is separate from the legislature to which it is not accountable.[106][107]Although the role of the executive varies from country to country, usually it will propose the majority of legislation, and propose government agenda. In presidential systems, the executive often has the power to veto legislation. Most executives in both systems are responsible for foreign relations, the military and police, and the bureaucracy. Ministers or other officials head a country's public offices, such as a foreign ministry or defence ministry. The election of a different executive is therefore capable of revolutionising an entire country's approach to government.While military organisations have existed as long as government itself, the idea of a standing police force is a relatively modern concept. For example, Medieval England's system of traveling criminal courts, or assizes, used show trials and public executions to instill communities with fear to maintain control.[108] The first modern police were probably those in 17th-century Paris, in the court of Louis XIV,[109] although the Paris Prefecture of Police claim they were the world's first uniformed policemen.[110]Max Weber famously argued that the state is that which controls the monopoly on the legitimate use of force.[111][112] The military and police carry out enforcement at the request of the government or the courts. The term failed state refers to states that cannot implement or enforce policies; their police and military no longer control security and order and society moves into anarchy, the absence of government.[113]The etymology of \"bureaucracy\" derives from the French word for \"office\" .[114] Like the military and police, a legal system's government servants and bodies that make up its bureaucracy carry out the directives of the executive. One of the earliest references to the concept was made by Baron de Grimm, a German author who lived in France. In 1765 he wrote,Cynicism over \"officialdom\" is still common, and the workings of public servants is typically contrasted to private enterprise motivated by profit.[116] In fact private companies, especially large ones, also have bureaucracies.[117] Negative perceptions of \"red tape\" aside, public services such as schooling, health care, policing or public transport are considered a crucial state function making public bureaucratic action the locus of government power.[117]Writing in the early 20th century, Max Weber believed that a definitive feature of a developed state had come to be its bureaucratic support.[118] Weber wrote that the typical characteristics of modern bureaucracy are that officials define its mission, the scope of work is bound by rules, and management is composed of career experts who manage top down, communicating through writing and binding public servants' discretion with rules.[119]A corollary of the rule of law is the existence of a legal profession sufficiently autonomous to invoke the authority of the independent judiciary; the right to assistance of a barrister in a court proceeding emanates from this corollary\u2014in England the function of barrister or advocate is distinguished from legal counselor.[121] As the European Court of Human Rights has stated, the law should be adequately accessible to everyone and people should be able to foresee how the law affects them.[122]In order to maintain professionalism, the practice of law is typically overseen by either a government or independent regulating body such as a bar association, bar council or law society. Modern lawyers achieve distinct professional identity through specified legal procedures . There are few titles of respect to signify famous lawyers, such as Esquire, to indicate barristers of greater dignity,[123][124] and Doctor of law, to indicate a person who obtained a PhD in Law.Many Muslim countries have developed similar rules about legal education and the legal profession, but some still allow lawyers with training in traditional Islamic law to practice law before personal status law courts.[125] In China and other developing countries there are not sufficient professionally trained people to staff the existing judicial systems, and, accordingly, formal standards are more relaxed.[126]Once accredited, a lawyer will often work in a law firm, in a chambers as a sole practitioner, in a government post or in a private corporation as an internal counsel. In addition a lawyer may become a legal researcher who provides on-demand legal research through a library, a commercial service or freelance work. Many people trained in law put their skills to use outside the legal field entirely.[127]Significant to the practice of law in the common law tradition is the legal research to determine the current state of the law. This usually entails exploring case-law reports, legal periodicals and legislation. Law practice also involves drafting documents such as court pleadings, persuasive briefs, contracts, or wills and trusts. Negotiation and dispute resolution skills  are also important to legal practice, depending on the field.[127]The Classical republican concept of \"civil society\" dates back to Hobbes and Locke.[128] Locke saw civil society as people who have \"a common established law and judicature to appeal to, with authority to decide controversies between them.\"[129] German philosopher Georg Wilhelm Friedrich Hegel distinguished the \"state\" from \"civil society\"  in Elements of the Philosophy of Right.[130]Hegel believed that civil society and the state were polar opposites, within the scheme of his dialectic theory of history. The modern dipole state\u2013civil society was reproduced in the theories of Alexis de Tocqueville and Karl Marx.[131][132] Nowadays in post-modern theory civil society is necessarily a source of law, by being the basis from which people form opinions and lobby for what they believe law should be. As Australian barrister and author Geoffrey Robertson QC wrote of international law,Freedom of speech, freedom of association and many other individual rights allow people to gather, discuss, criticise and hold to account their governments, from which the basis of a deliberative democracy is formed. The more people are involved with, concerned by and capable of changing how political power is exercised over their lives, the more acceptable and legitimate the law becomes to the people. The most familiar institutions of civil society include economic markets, profit-oriented firms, families, trade unions, hospitals, universities, schools, charities, debating clubs, non-governmental organisations, neighbourhoods, churches, and religious associations.[134]All legal systems deal with the same basic issues, but jurisdictions categorise and identify its legal subjects in different ways. A common distinction is that between \"public law\" .[135] In civil law systems, contract and tort fall under a general law of obligations, while trusts law is dealt with under statutory regimes or international conventions. International, constitutional and administrative law, criminal law, contract, tort, property law and trusts are regarded as the \"traditional core subjects\",[136] although there are many further disciplines.International law can refer to three things: public international law, private international law or conflict of laws and the law of supranational organisations.Constitutional and administrative law govern the affairs of the state. Constitutional law concerns both the relationships between the executive, legislature and judiciary and the human rights or civil liberties of individuals against the state. Most jurisdictions, like the United States and France, have a single codified constitution with a bill of rights. A few, like the United Kingdom, have no such document. A \"constitution\" is simply those laws which constitute the body politic, from statute, case law and convention. A case named Entick v Carrington[144] illustrates a constitutional principle deriving from the common law. Mr Entick's house was searched and ransacked by Sheriff Carrington. When Mr Entick complained in court, Sheriff Carrington argued that a warrant from a Government minister, the Earl of Halifax, was valid authority. However, there was no written statutory provision or court authority. The leading judge, Lord Camden, stated that,The fundamental constitutional principle, inspired by John Locke, holds that the individual can do anything except that which is forbidden by law, and the state may do nothing except that which is authorised by law.[146][147] Administrative law is the chief method for people to hold state bodies to account. People can sue an agency, local council, public service, or government ministry for judicial review of actions or decisions, to ensure that they comply with the law, and that the government entity observed required procedure. The first specialist administrative court was the Conseil d'\u00c9tat set up in 1799, as Napoleon assumed power in France.[148]Criminal law, also known as penal law, pertains to crimes and punishment.[149] It thus regulates the definition of and penalties for offences found to have a sufficiently deleterious social impact but, in itself, makes no moral judgment on an offender nor imposes restrictions on society that physically prevent people from committing a crime in the first place.[150] Investigating, apprehending, charging, and trying suspected offenders is regulated by the law of criminal procedure.[151] The paradigm case of a crime lies in the proof, beyond reasonable doubt, that a person is guilty of two things. First, the accused must commit an act which is deemed by society to be criminal, or actus reus , and negligence. Negligence does not carry criminal responsibility unless a particular crime provides for its punishment.[154][155]Examples of crimes include murder, assault, fraud and theft. In exceptional circumstances defences can apply to specific acts, such as killing in self defence, or pleading insanity. Another example is in the 19th-century English case of R v Dudley and Stephens, which tested a defence of \"necessity\". The Mignonette, sailing from Southampton to Sydney, sank. Three crew members and Richard Parker, a 17-year-old cabin boy, were stranded on a raft. They were starving and the cabin boy was close to death. Driven to extreme hunger, the crew killed and ate the cabin boy. The crew survived and were rescued, but put on trial for murder. They argued it was necessary to kill the cabin boy to preserve their own lives. Lord Coleridge, expressing immense disapproval, ruled, \"to preserve one's life is generally speaking a duty, but it may be the plainest and the highest duty to sacrifice it.\" The men were sentenced to hang, but public opinion was overwhelmingly supportive of the crew's right to preserve their own lives. In the end, the Crown commuted their sentences to six months in jail.[156]Criminal law offences are viewed as offences against not just individual victims, but the community as well.[150] The state, usually with the help of police, takes the lead in prosecution, which is why in common law countries cases are cited as \"The People v ...\" or \"R , or community service. Modern criminal law has been affected considerably by the social sciences, especially with respect to sentencing, legal research, legislation, and rehabilitation.[157] On the international field, 111 countries are members of the International Criminal Court, which was established to try people for crimes against humanity.[158]Contract law concerns enforceable promises, and can be summed up in the Latin phrase pacta sunt servanda .[159] In common law jurisdictions, three key elements to the creation of a contract are necessary: offer and acceptance, consideration and the intention to create legal relations. In Carlill v Carbolic Smoke Ball Company a medical firm advertised that its new wonder drug, the smokeball, would cure people's flu, and if it did not, the buyers would get \u00a3100. Many people sued for their \u00a3100 when the drug did not work. Fearing bankruptcy, Carbolic argued the advert was not to be taken as a serious, legally binding offer. It was an invitation to treat, mere puffery, a gimmick. But the Court of Appeal held that to a reasonable man Carbolic had made a serious offer, accentuated by their reassuring statement, \"\u00a31000 is deposited\". Equally, people had given good consideration for the offer by going to the \"distinct inconvenience\" of using a faulty product. \"Read the advertisement how you will, and twist it about as you will\", said Lord Justice Lindley, \"here is a distinct promise expressed in language which is perfectly unmistakable\".[160]\"Consideration\" indicates the fact that all parties to a contract have exchanged something of value. Some common law systems, including Australia, are moving away from the idea of consideration as a requirement. The idea of estoppel or culpa in contrahendo, can be used to create obligations during pre-contractual negotiations.[161] In civil law jurisdictions, consideration is not required for a contract to be binding.[162] In France, an ordinary contract is said to form simply on the basis of a \"meeting of the minds\" or a \"concurrence of wills\". Germany has a special approach to contracts, which ties into property law. Their 'abstraction principle' [163] the contractual obligation to pay can be invalidated separately from the proprietary title of the car. Unjust enrichment law, rather than contract law, is then used to restore title to the rightful owner.[164]Torts, sometimes called delicts, are civil wrongs. To have acted tortiously, one must have breached a duty to another person, or infringed some pre-existing legal right. A simple example might be accidentally hitting someone with a cricket ball.[165] Under the law of negligence, the most common form of tort, the injured party could potentially claim compensation for their injuries from the party responsible. The principles of negligence are illustrated by Donoghue v Stevenson.[166] A friend of Mrs Donoghue ordered an opaque bottle of ginger beer  in a caf\u00e9 in Paisley. Having consumed half of it, Mrs Donoghue poured the remainder into a tumbler. The decomposing remains of a snail floated out. She claimed to have suffered from shock, fell ill with gastroenteritis and sued the manufacturer for carelessly allowing the drink to be contaminated. The House of Lords decided that the manufacturer was liable for Mrs Donoghue's illness. Lord Atkin took a distinctly moral approach, and said,This became the basis for the four principles of negligence:  his act was the proximate cause of her harm.[166] Another example of tort might be a neighbour making excessively loud noises with machinery on his property.[57] Under a nuisance claim the noise could be stopped. Torts can also involve intentional acts, such as assault, battery or trespass. A better known tort is defamation, which occurs, for example, when a newspaper makes unsupportable allegations that damage a politician's reputation.[168] More infamous are economic torts, which form the basis of labour law in some countries by making trade unions liable for strikes,[169] when statute does not provide immunity.[170]Property law governs ownership and possession. Real property, sometimes called 'real estate', refers to ownership of land and things attached to it.[172] Personal property, refers to everything else; movable objects, such as computers, cars, jewelry or intangible rights, such as stocks and shares. A right in rem is a right to a specific piece of property, contrasting to a right in personam which allows compensation for a loss, but not a particular thing back. Land law forms the basis for most kinds of property law, and is the most complex. It concerns mortgages, rental agreements, licences, covenants, easements and the statutory systems for land registration. Regulations on the use of personal property fall under intellectual property, company law, trusts and commercial law. An example of a basic case of most property law is Armory v Delamirie [1722].[173] A chimney sweep's boy found a jewel encrusted with precious stones. He took it to a goldsmith to have it valued. The goldsmith's apprentice looked at it, sneakily removed the stones, told the boy it was worth three halfpence and that he would buy it. The boy said he would prefer the jewel back, so the apprentice gave it to him, but without the stones. The boy sued the goldsmith for his apprentice's attempt to cheat him. Lord Chief Justice Pratt ruled that even though the boy could not be said to own the jewel, he should be considered the rightful keeper , but the boy's possessory interest was considered better, because it could be shown to be first in time. Possession may be nine tenths of the law, but not all.This case is used to support the view of property in common law jurisdictions, that the person who can show the best claim to a piece of property, against any contesting party, is the owner.[174] By contrast, the classic civil law approach to property, propounded by Friedrich Carl von Savigny, is that it is a right good against the world. Obligations, like contracts and torts, are conceptualised as rights good between individuals.[175] The idea of property raises many further philosophical and political issues. Locke argued that our \"lives, liberties and estates\" are our property because we own our bodies and mix our labour with our surroundings.[176]Equity is a body of rules that developed in England separately from the \"common law\". The common law was administered by judges and barristers. The Lord Chancellor on the other hand, as the King's keeper of conscience, could overrule the judge-made law if he thought it equitable to do so.[177] This meant equity came to operate more through principles than rigid rules. For instance, whereas neither the common law nor civil law systems allow people to split the ownership from the control of one piece of property, equity allows this through an arrangement known as a 'trust'. 'Trustees' control property, whereas the 'beneficial'  grew up, he sued Mr Sandford for the profit that he had been making by getting the market's lease. Mr Sandford was meant to be trusted, but he put himself in a position of conflict of interest. The Lord Chancellor, Lord King, agreed and ordered Mr Sandford should disgorge his profits. He wrote,Of course, Lord King LC was worried that trustees might exploit opportunities to use trust property for themselves instead of looking after it. Business speculators using trusts had just recently caused a stock market crash. Strict duties for trustees made their way into company law and were applied to directors and chief executive officers. Another example of a trustee's duty might be to invest property wisely or sell it.[180] This is especially the case for pension funds, the most important form of trust, where investors are trustees for people's savings until retirement. But trusts can also be set up for charitable purposes, famous examples being the British Museum or the Rockefeller Foundation.Law spreads far beyond the core subjects into virtually every area of life. Three categories are presented for convenience, though the subjects intertwine and overlap."], "Political science": ["Politics  is the process of making decisions that apply to members of a group.[1]It refers to achieving and exercising positions of governance\u2014organized control over a human community, particularly a state.[2]In modern nation states, people have formed political parties to represent their ideas. They agree to take the same position on many issues, and agree to support the same changes to law and the same leaders.[3]An election is usually a competition between different parties.[4] Some examples of political parties are the African National Congress  in South Africa, the Tories in Great Britain and the Indian National Congress.Politics is a multifaceted word. It has a set of fairly specific meanings that are descriptive and nonjudgmental , but often does carry a connotation of dishonest malpractice.[1][5][6] The negative connotation of politics, as seen in the phrase \"play politics\", for example, has been in use since at least 1853, when abolitionist Wendell Phillips declared: \"We do not play politics; anti-slavery is no half-jest with us.\"[7]A variety of methods are deployed in politics, which include promoting one's own political views among people, negotiation with other political subjects, making laws, and exercising force, including warfare against adversaries.[8][9][10][11][12] Politics is exercised on a wide range of social levels, from clans and tribes of traditional societies, through modern local governments, companies and institutions up to sovereign states, to the international level.It is very often said that politics is about power.[13] A political system is a framework which defines acceptable political methods within a given society. History of political thought can be traced back to early antiquity, with seminal works such as Plato's Republic, Aristotle's Politics and the works of Confucius.The word comes from the same Greek word from which the title of Aristotle's book Politics , \"city\".[18]Formal Politics refers to the operation of a constitutional system of government and publicly defined institutions and procedures.[13] Political parties, public policy or discussions about war and foreign affairs would fall under the category of Formal Politics.[13] Many people view formal politics as something outside of themselves, but that can still affect their daily lives.[13]Semi-formal Politics is Politics in government associations such as neighborhood associations, or student governments where student government political party politics is often important.Informal Politics is understood as forming alliances, exercising power and protecting and advancing particular ideas or goals. Generally, this includes anything affecting one's daily life, such as the way an office or household is managed, or how one person or group exercises influence over another.[13] Informal Politics is typically understood as everyday politics, hence the idea that \"politics is everywhere\".[13]The history of politics is reflected in the origin, development, and economics of the institutions of government.The origin of the state is to be found in the development of the art of warfare. Historically speaking, all political communities of the modern type owe their existence to successful warfare.[19]Kings, emperors and other types of monarchs in many countries including China and Japan, were considered divine. Of the institutions that ruled states, that of kingship stood at the forefront until the American Revolution put an end to the \"divine right of kings\". Nevertheless, the monarchy is among the longest-lasting political institutions, dating as early as 2100 BC in Sumeria[20] to the 21st century AD British Monarchy. Kingship becomes an institution through the institution of Hereditary monarchy.The king often, even in absolute monarchies, ruled his kingdom with the aid of an elite group of advisors, a council without which he could not maintain power. As these advisors and others outside the monarchy negotiated for power, constitutional monarchies emerged, which may be considered the germ of constitutional government.[21][22]The greatest of the king's subordinates, the earls and dukes in England and Scotland, the dukes and counts in the Continent, always sat as a right on the council. A conqueror wages war upon the vanquished for vengeance or for plunder but an established kingdom exacts tribute. One of the functions of the council is to keep the coffers of the king full. Another is the satisfaction of military service and the establishment of lordships by the king to satisfy the task of collecting taxes and soldiers.[23]There are many forms of political organization, including states, non-government organizations  and international organizations such as the United Nations. States are perhaps the predominant institutional form of political governance, where a state is understood as an institution and a government is understood as the regime in power.According to Aristotle, states are classified into monarchies, aristocracies, timocracies, democracies, oligarchies, and tyrannies. Due to changes across the history of politics, this classification has been abandoned.All states are varieties of a single organizational form, the sovereign state. All the great powers of the modern world rule on the principle of sovereignty. Sovereign power may be vested on an individual as in an autocratic government or it may be vested on a group as in a constitutional government. Constitutions are written documents that specify and limit the powers of the different branches of government. Although a constitution is a written document, there is also an unwritten constitution. The unwritten constitution is continually being written by the legislative branch of government; this is just one of those cases in which the nature of the circumstances determines the form of government that is most appropriate. England did set the fashion of written constitutions during the Civil War but after the Restoration abandoned them to be taken up later by the American Colonies after their emancipation and then France after the Revolution and the rest of Europe including the European colonies.[citation needed]There are many forms of government. One form is a strong central government as in France and China. Another form is local government, such as the ancient divisions in England that are comparatively weaker but less bureaucratic. These two forms helped to shape the practice of federal government, first in Switzerland, then in the United States in 1776, in Canada in 1867 and in Germany in 1871 and in 1901, Australia. Federal states introduced the new principle of agreement or contract. Compared to a federation, a confederation has a more dispersed system of judicial power.[24] In the American Civil War, the contention of the Confederate States that a State could secede from the Union was untenable because of the power enjoyed by the Federal government in the executive, legislative and judiciary branches.[citation needed]According to professor A. V. Dicey in An Introduction to the Study of the Law of the Constitution, the essential features of a federal constitution are: a) A written supreme constitution in order to prevent disputes between the jurisdictions of the Federal and State authorities; b) A distribution of power between the Federal and State governments and c) A Supreme Court vested with the power to interpret the Constitution and enforce the law of the land remaining independent of both the executive and legislative branches.[25]Global politics include different practices of political globalization in relation to questions of social power: from global patterns of governance to issues of globalizing conflict. The 20th century witnessed the outcome of two world wars and not only the rise and fall of the Third Reich but also the rise and relative fall of communism. The development of the atomic bomb gave the United States a more rapid end to its conflict in Japan in World War II. Later, the hydrogen bomb became the ultimate weapon of mass destruction.Global politics also concerns the rise of global and international organizations. The United Nations has served as a forum for peace in a world threatened by nuclear war, \"The invention of nuclear and space weapons has made war unacceptable as an instrument for achieving political ends.\"[26] Although an all-out final nuclear holocaust is radically undesirable for man, \"nuclear blackmail\" comes into question not only on the issue of world peace but also on the issue of national sovereignty.[27] On a Sunday in 1962, the world stood still at the brink of nuclear war during the October Cuban Missile Crisis from the implementation of U.S. vs Soviet Union nuclear blackmail policy.According to political science professor Paul James, global politics is affected by values: norms of human rights, ideas of human development, and beliefs such as cosmopolitanism about how we should relate to each:William Pitt the Elder, speaking before the British House of Lords, 9 January 1770, observed: \"Unlimited power is apt to corrupt the minds of those who possess it.\"[29] This was echoed more famously by John Dalberg-Acton over a century later: \"Power tends to corrupt, and absolute power corrupts absolutely.\"[30]Political corruption is the use of legislated powers by government officials for illegitimate private gain. Misuse of government power for other purposes, such as repression of political opponents and general police brutality, is not considered political corruption. Neither are illegal acts by private persons or corporations not directly involved with the government. An illegal act by an officeholder constitutes political corruption only if the act is directly related to their official duties and/or power.[31]Forms of corruption vary, but include corruption, extortion, cronyism, nepotism, patronage, graft, and embezzlement. While corruption may facilitate criminal enterprise such as drug trafficking, money laundering, and trafficking, it is not restricted to these activities.[citation needed] The activities that constitute illegal corruption differ depending on the country or jurisdiction. For instance, certain political funding practices that are legal in one place may be illegal in another. In some cases, government officials have broad or poorly defined powers, which make it difficult to distinguish between legal and illegal actions.[citation needed] Worldwide, bribery alone is estimated to involve over 1 trillion US dollars annually.[32] A state of unrestrained political corruption is known as a kleptocracy, literally meaning \"rule by thieves\".[citation needed]A political party is a political organization that typically seeks to attain and maintain political power within government, usually by participating in electoral campaigns, educational outreach or protest actions. Parties often espouse an expressed ideology or vision bolstered by a written platform with specific goals, forming a coalition among disparate interests.[citation needed]Political science, the study of politics, examines the acquisition and application of power.[33] Political scientist Harold Lasswell defined politics as \"who gets what, when, and how\".[34] Related areas of study include political philosophy, which seeks a rationale for politics and an ethic of public behaviour, as well as examining the preconditions for the formation of political communities;[35] political economy, which attempts to develop understandings of the relationships between politics and the economy and the governance of the two; and public administration, which examines the practices of governance.[citation needed] The philosopher Charles Blattberg, who has defined politics as \"responding to conflict with dialogue,\" offers an account which distinguishes political philosophies from political ideologies.[36]The first academic chair devoted to politics in the United States was the chair of history and political science at Columbia University, first occupied by Prussian \u00e9migr\u00e9 Francis Lieber in 1857.[37]Several different political spectra have been proposed.Political analysts and politicians divide politics into left wing and right wing politics, often also using the idea of center politics as a middle path of policy between the right and left. This classification is comparatively recent , and dates from the French Revolution era, when those members of the National Assembly who supported the republic, the common people and a secular society sat on the left and supporters of the monarchy, aristocratic privilege and the Church sat on the right.[38]The meanings behind the labels have become more complicated over the years. A particularly influential event was the publication of the Communist Manifesto by Karl Marx and Friedrich Engels in 1848. The Manifesto suggested a course of action for a proletarian revolution to overthrow the bourgeois society and abolish private property, in the belief that this would lead to a classless and stateless society.[citation needed][39]The meaning of left-wing and right-wing varies considerably between different countries and at different times, but generally speaking, it can be said that the right wing often values tradition and social stratification while the left wing often values reform and egalitarianism, with the center seeking a balance between the two such as with social democracy or regulated capitalism.[40]According to Norberto Bobbio, one of the major exponents of this distinction, the Left believes in attempting to eradicate social inequality, while the Right regards most social inequality as the result of ineradicable natural inequalities, and sees attempts to enforce social equality as utopian or authoritarian.[41]Some ideologies, notably Christian Democracy, claim to combine left and right wing politics; according to Geoffrey K. Roberts and Patricia Hogwood, \"In terms of ideology, Christian Democracy has incorporated many of the views held by liberals, conservatives and socialists within a wider framework of moral and Christian principles.\"[42] Movements which claim or formerly claimed to be above the left-right divide include Fascist Terza Posizione economic politics in Italy, Peronism in Argentina, and National Action Party in Mexico.[43][citation needed]Authoritarianism and libertarianism refer to the amount of individual freedom each person possesses in that society relative to the state. One author describes authoritarian political systems as those where \"individual rights and goals are subjugated to group goals, expectations and conformities\",[44] while libertarians generally oppose the state and hold the individual as sovereign. In their purest form, libertarians are anarchists, who argue for the total abolition of the state, of political parties and of other political entities, while the purest authoritarians are, theoretically, totalitarians who support state control over all aspects of society.[citation needed][45]For instance, classical liberalism  is a doctrine stressing individual freedom and limited government. This includes the importance of human rationality, individual property rights, free markets, natural rights, the protection of civil liberties, constitutional limitation of government, and individual freedom from restraint as exemplified in the writings of John Locke, Adam Smith, David Hume, David Ricardo, Voltaire, Montesquieu and others. According to the libertarian Institute for Humane Studies, \"the libertarian, or 'classical liberal,' perspective is that individual well-being, prosperity, and social harmony are fostered by 'as much liberty as possible' and 'as little government as necessary.'\"[47] For anarchist political philosopher L. Susan Brown \"Liberalism and anarchism are two political philosophies that are fundamentally concerned with individual freedom yet differ from one another in very distinct ways. Anarchism shares with liberalism a radical commitment to individual freedom while rejecting liberalism's competitive property relations.\"[48]", "Political science is a social science which deals with systems of governance, and the analysis of political activities, political thoughts and political behavior.[1] It deals extensively with the theory and practice of politics which is commonly thought of as determining of the distribution of power and resources. Political scientists \"see themselves engaged in revealing the relationships underlying political events and conditions, and from these revelations they attempt to construct general principles about the way the world of politics works.\"[2]Political science comprises numerous subfields, including comparative politics, political economy, international relations, political theory, public administration, public policy, and political methodology. Furthermore, political science is related to, and draws upon, the fields of economics, law, sociology, history, philosophy, geography, psychology, and anthropology.Comparative politics is the science of comparison and teaching of different types of constitutions, political actors, legislature and associated fields, all of them from an intrastate perspective. International relations deals with the interaction between nation-states as well as intergovernmental and transnational organizations. Political theory is more concerned with contributions of various classical and contemporary thinkers and philosophers.Political science is methodologically diverse and appropriates many methods originating in social research. Approaches include positivism, interpretivism, rational choice theory, behaviouralism, structuralism, post-structuralism, realism, institutionalism, and pluralism. Political science, as one of the social sciences, uses methods and techniques that relate to the kinds of inquiries sought: primary sources such as historical documents and official records, secondary sources such as scholarly journal articles, survey research, statistical analysis, case studies, experimental research, and model building.Political scientists study matters concerning the allocation and transfer of power in decision making, the roles and systems of governance including governments and international organizations, political behaviour and public policies. They measure the success of governance and specific policies by examining many factors, including stability, justice, material wealth, peace and public health. Some political scientists seek to advance positive  theses by analysing politics. Others advance normative theses, by making specific policy recommendations.Political scientists provide the frameworks from which journalists, special interest groups, politicians, and the electorate analyse issues. According to Chaturvedy,In the United States, political scientists known as \"Americanists\" look at a variety of data including constitutional development, elections, public opinion, and public policy such as Social Security reform, foreign policy, US Congressional committees, and the US Supreme Court\u00a0\u2014 to name only a few issues.Because political science is essentially a study of human behaviour, in all aspects of politics, observations in controlled environments are often challenging to reproduce or duplicate, though experimental methods are increasingly common .[4] Citing this difficulty, former American Political Science Association President Lawrence Lowell once said \"We are limited by the impossibility of experiment. Politics is an observational, not an experimental science.\"[5] Because of this, political scientists have historically observed political elites, institutions, and individual or group behaviour in order to identify patterns, draw generalizations, and build theories of politics.Like all social sciences, political science faces the difficulty of observing human actors that can only be partially observed and who have the capacity for making conscious choices unlike other subjects such as non-human organisms in biology or inanimate objects as in physics. Despite the complexities, contemporary political science has progressed by adopting a variety of methods and theoretical approaches to understanding politics and methodological pluralism is a defining feature of contemporary political science.The advent of political science as a university discipline was marked by the creation of university departments and chairs with the title of political science arising in the late 19th century. In fact, the designation \"political scientist\" is typically for those with a doctorate in the field, but can also apply to those with a master's in the subject.[6] Integrating political studies of the past into a unified discipline is ongoing, and the history of political science has provided a rich field for the growth of both normative and positive political science, with each part of the discipline sharing some historical predecessors. The American Political Science Association and the American Political Science Review were founded in 1903 and 1906, respectively, in an effort to distinguish the study of politics from economics and other social phenomena. To date, the [7]American Political Science Review is the leading journal in Political Science research.In the 1950s and the 1960s, a behavioural revolution stressing the systematic and rigorously scientific study of individual and group behaviour swept the discipline. A focus on studying political behaviour, rather than institutions or interpretation of legal texts, characterized early behavioural political science, including work by Robert Dahl, Philip Converse, and in the collaboration between sociologist Paul Lazarsfeld and public opinion scholar Bernard Berelson.The late 1960s and early 1970s witnessed a take off in the use of deductive, game theoretic formal modelling techniques aimed at generating a more analytical corpus of knowledge in the discipline. This period saw a surge of research that borrowed theory and methods from economics to study political institutions, such as the United States Congress, as well as political behaviour, such as voting. William H. Riker and his colleagues and students at the University of Rochester were the main proponents of this shift.Despite considerable research progress in the discipline based on all the kinds of scholarship discussed above, it has been observed that progress toward systematic theory has been modest and uneven.[8]The theory of political transitions,[9] and the methods of their analysis and anticipating of crises,[10] form an important part of political science. Several general indicators of crises and methods were proposed for anticipating critical transitions.[11] Among them, a statistical indicator of crisis, simultaneous increase of variance and correlations in large groups, was proposed for crises anticipation and successfully used in various areas.[12] Its applicability for early diagnosis of political crises was demonstrated by the analysis of the prolonged stress period preceding the 2014 Ukrainian economic and political crisis. There was a simultaneous increase in the total correlation between the 19 major public fears in the Ukrainian society  during the pre-crisis years.[13] A feature shared by certain major revolutions is that they were not predicted. The theory of apparent inevitability of crises and revolutions was also developed.[14]In the Soviet Union, political studies were carried out under the guise of some other disciplines like theory of state and law, area studies, international relations, studies of labor movement, \"critique of bourgeois theories\", etc. Soviet scholars were represented at the International Political Science Association .In 1979, the 11th World Congress of IPSA took place in Moscow. Until the late years of the Soviet Union, political science as a field was subjected to tight control of the Communist Party of the Soviet Union and was thus subjected to distrust. Anti-communists accused political scientists of being \"false\" scientists and of having served the old regime.[15]After the fall of the Soviet Union, two of the major institutions dealing with political science, the Institute of Contemporary Social Theories and the Institute of International Affairs, were disbanded, and most of their members were left without jobs. These institutes were victims of the first wave of anticommunist opinion and ideological attacks. Today, the Russian Political Science Association unites professional political scientists from all around Russia.In 2000, the Perestroika Movement in political science was introduced as a reaction against what supporters of the movement called the mathematicization of political science. Those who identified with the movement argued for a plurality of methodologies and approaches in political science and for more relevance of the discipline to those outside of it.[16]Evolutionary psychology theories argue that humans have evolved a highly developed set of psychological mechanisms for dealing with politics. However, these mechanisms evolved for dealing with the small group politics that characterized the ancestral environment and not the much larger political structures in today's world. This is argued to explain many important features and systematic cognitive biases of current politics.[17]Political science, possibly like the social sciences as a whole, \"as a discipline lives on the fault line between the 'two cultures' in the academy, the sciences and the humanities.\"[18] Thus, in some American colleges where there is no separate School or College of Arts and Sciences per se, political science may be a separate department housed as part of a division or school of Humanities or Liberal Arts.[19] Whereas classical political philosophy is primarily defined by a concern for Hellenic and Enlightenment thought, political scientists are also marked by a great concern for \"modernity\" and the contemporary nation state, along with the study of classical thought, and as such share a greater deal of terminology with sociologists .Most United States colleges and universities offer B.A. programs in political science. M.A. or M.A.T. and Ph.D. or Ed.D. programs are common at larger universities. The term political science is more popular in North America than elsewhere; other institutions, especially those outside the United States, see political science as part of a broader discipline of political studies, politics, or government. While political science implies use of the scientific method, political studies implies a broader approach, although the naming of degree courses does not necessarily reflect their content.[20] Separate degree granting programs in international relations and public policy are not uncommon at both the undergraduate and graduate levels. Master's level programs in political science are common when political scientists engage in public administration.[21]The national honor society for college and university students of government and politics in the United States is Pi Sigma Alpha.Most political scientists work broadly in one or more of the following five areas:Some political science departments also classify methodology as well as scholarship on the domestic politics of a particular country as distinct fields. In the United States, American politics is often treated as a separate subfield.In contrast to this traditional classification, some academic departments organize scholarship into thematic categories, including political philosophy, political behaviour . Political science conferences and journals often emphasize scholarship in more specific categories. The American Political Science Association, for example, has 42 organized sections that address various methods and topics of political inquiry.[22]As a social science, contemporary political science started to take shape in the latter half of the 19th century. At that time it began to separate itself from political philosophy, which traces its roots back to the works of Chanakya, Aristotle, and Plato which were written nearly 2,500 years ago. The term \"political science\" was not always distinguished from political philosophy, and the modern discipline has a clear set of antecedents including also moral philosophy, political economy, political theology, history, and other fields concerned with normative determinations of what ought to be and with deducing the characteristics and functions of the ideal state."], "Psychology": ["Psychology is the science of behavior and mind, including conscious and unconscious phenomena, as well as feeling and thought. It is an academic discipline of immense scope and diverse interests that, when taken together, seek an understanding of the emergent properties of brains, and all the variety of epiphenomena they manifest. As a social science it aims to understand individuals and groups by establishing general principles and researching specific cases.[1][2]In this field, a professional practitioner or researcher is called a psychologist and can be classified as a social, behavioral, or cognitive scientist. Psychologists attempt to understand the role of mental functions in individual and social behavior, while also exploring the physiological and biological processes that underlie cognitive functions and behaviors.Psychologists explore behavior and mental processes, including perception, cognition, attention, emotion , brain functioning, and personality. This extends to interaction between people, such as interpersonal relationships, including psychological resilience, family resilience, and other areas. Psychologists of diverse orientations also consider the unconscious mind.[3] Psychologists employ empirical methods to infer causal and correlational relationships between psychosocial variables. In addition, or in opposition, to employing empirical and deductive methods, some\u2014especially clinical and counseling psychologists\u2014at times rely upon symbolic interpretation and other inductive techniques. Psychology has been described as a \"hub science\" in that medicine tends to draw psychological research via neurology and psychiatry, whereas social sciences most commonly draws directly from sub-disciplines within psychology.[4]While psychological knowledge is often applied to the assessment and treatment of mental health problems, it is also directed towards understanding and solving problems in several spheres of human activity. By many accounts psychology ultimately aims to benefit society.[5][6] The majority of psychologists are involved in some kind of therapeutic role, practicing in clinical, counseling, or school settings. Many do scientific research on a wide range of topics related to mental processes and behavior, and typically work in university psychology departments or teach in other academic settings . Some are employed in industrial and organizational settings, or in other areas[7] such as human development and aging, sports, health, and the media, as well as in forensic investigation and other aspects of law.The word psychology derives from Greek roots meaning study of the psyche, or soul .[8] The Latin word psychologia was first used by the Croatian humanist and Latinist Marko Maruli\u0107 in his book, Psichiologia de ratione animae humanae in the late 15th century or early 16th century.[9] The earliest known reference to the word psychology in English was by Steven Blankaart in 1694 in The Physical Dictionary which refers to \"Anatomy, which treats the Body, and Psychology, which treats of the Soul.\"[10]In 1890, William James defined psychology as \"the science of mental life, both of its phenomena and their conditions\". This definition enjoyed widespread currency for decades. However, this meaning was contested, notably by radical behaviorists such as John B. Watson, who in his 1913 manifesto defined the discipline of psychology as the acquisition of information useful to the control of behavior. Also since James defined it, the term more strongly connotes techniques of scientific experimentation.[11][12] Folk psychology refers to the understanding of ordinary people, as contrasted with that of psychology professionals.[13]The ancient civilizations of Egypt, Greece, China, India, and Persia all engaged in the philosophical study of psychology. Historians note that Greek philosophers, including Thales, Plato, and Aristotle ,[14] addressed the workings of the mind.[15] As early as the 4th century BC, Greek physician Hippocrates theorized that mental disorders had physical rather than supernatural causes.[16]In China, psychological understanding grew from the philosophical works of Laozi and Confucius, and later from the doctrines of Buddhism. This body of knowledge involves insights drawn from introspection and observation, as well as techniques for focused thinking and acting. It frames the universe as a division of, and interaction between, physical reality and mental reality, with an emphasis on purifying the mind in order to increase virtue and power. An ancient text known as The Yellow Emperor's Classic of Internal Medicine identifies the brain as the nexus of wisdom and sensation, includes theories of personality based on yin\u2013yang balance, and analyzes mental disorder in terms of physiological and social disequilibria. Chinese scholarship focused on the brain advanced in the Qing Dynasty with the work of Western-educated Fang Yizhi . Wang Qingren emphasized the importance of the brain as the center of the nervous system, linked mental disorder with brain diseases, investigated the causes of dreams and insomnia, and advanced a theory of hemispheric lateralization in brain function.[17]Distinctions in types of awareness appear in the ancient thought of India, influenced by Hinduism. A central idea of the Upanishads is the distinction between a person's transient mundane self and their eternal unchanging soul. Divergent Hindu doctrines, and Buddhism, have challenged this hierarchy of selves, but have all emphasized the importance of reaching higher awareness. Yoga is a range of techniques used in pursuit of this goal. Much of the Sanskrit corpus was suppressed under the British East India Company followed by the British Raj in the 1800s. However, Indian doctrines influenced Western thinking via the Theosophical Society, a New Age group which became popular among Euro-American intellectuals.[18]Psychology was a popular topic in Enlightenment Europe. In Germany, Gottfried Wilhelm Leibniz , and even observation by itself already changes and displaces the state of the observed object.\" Having consulted philosophers Hegel and Herbart, in 1825 the Prussian state established psychology as a mandatory discipline in its rapidly expanding and highly influential educational system. However, this discipline did not yet embrace experimentation.[19] In England, early psychology involved phrenology and the response to social problems including alcoholism, violence, and the country's well-populated mental asylums.[20]Gustav Fechner began conducting psychophysics research in Leipzig in the 1830s, articulating the principle that human perception of a stimulus varies logarithmically according to its intensity.[21] Fechner's 1860 Elements of Psychophysics challenged Kant's stricture against quantitative study of the mind.[19] In Heidelberg, Hermann von Helmholtz conducted parallel research on sensory perception, and trained physiologist Wilhelm Wundt. Wundt, in turn, came to Leipzig University, establishing the psychological laboratory which brought experimental psychology to the world. Wundt focused on breaking down mental processes into the most basic components, motivated in part by an analogy to recent advances in chemistry, and its successful investigation of the elements and structure of material.[22] Paul Flechsig and Emil Kraepelin soon created another influential psychology laboratory at Leipzig, this one focused on more on experimental psychiatry.[19]Psychologists in Germany, Denmark, Austria, England, and the United States soon followed Wundt in setting up laboratories.[23] G. Stanley Hall who studied with Wundt, formed a psychology lab at Johns Hopkins University in Maryland, which became internationally influential. Hall, in turn, trained Yujiro Motora, who brought experimental psychology, emphasizing psychophysics, to the Imperial University of Tokyo.[24] Wundt assistant Hugo M\u00fcnsterberg taught psychology at Harvard to students such as Narendra Nath Sen Gupta\u2014who, in 1905, founded a psychology department and laboratory at the University of Calcutta.[18] Wundt students Walter Dill Scott, Lightner Witmer, and James McKeen Cattell worked on developing tests for mental ability. Catell, who also studied with eugenicist Francis Galton, went on to found the Psychological Corporation. Wittmer focused on mental testing of children; Scott, on selection of employees.[25]Another student of Wundt, Edward Titchener, created the psychology program at Cornell University and advanced a doctrine of \"structuralist\" psychology. Structuralism sought to analyze and classify different aspects of the mind, primarily through the method of introspection.[26] William James, John Dewey and Harvey Carr advanced a more expansive doctrine called functionalism, attuned more to human\u2013environment actions. In 1890 James wrote an influential book, The Principles of Psychology, which expanded on the realm of structuralism, memorably described the human \"stream of consciousness\", and interested many American students in the emerging discipline.[26][27][28] Dewey integrated psychology with social issues, most notably by promoting the cause progressive education to assimilate immigrants and inculcate moral values in children.[29]A different strain of experimentalism, with more connection to physiology, emerged in South America, under the leadership of Horacio G. Pi\u00f1ero at the University of Buenos Aires.[30] Russia, too, placed greater emphasis on the biological basis for psychology, beginning with Ivan Sechenov's 1873 essay, \"Who Is to Develop Psychology and How?\" Sechenov advanced the idea of brain reflexes and aggressively promoted a deterministic viewpoint on human behavior.[31]Wolfgang Kohler, Max Wertheimer and Kurt Koffka co-founded the school of Gestalt psychology . This approach is based upon the idea that individuals experience things as unified wholes. Rather than breaking down thoughts and behavior into smaller elements, as in structuralism, the Gestaltists maintained that whole of experience is important, and differs from the sum of its parts. Other 19th-century contributors to the field include the German psychologist Hermann Ebbinghaus, a pioneer in the experimental study of memory, who developed quantitative models of learning and forgetting at the University of Berlin,[32] and the Russian-Soviet physiologist Ivan Pavlov, who discovered in dogs a learning process that was later termed \"classical conditioning\" and applied to human beings.[33]One of the earliest psychology societies was La Soci\u00e9t\u00e9 de Psychologie Physiologique in France, which lasted 1885\u20131893. The first meeting of the International Congress of Psychology took place in Paris, in August 1889, amidst the World's Fair celebrating the centennial of the French Revolution. William James was one of three Americans among the four hundred attendees. The American Psychological Association was founded soon after, in 1892. The International Congress continued to be held, at different locations in Europe, with wider international participation. The Sixth Congress, Geneva 1909, included presentations in Russian, Chinese, and Japanese, as well as Esperanto. After a hiatus for World War I, the Seventh Congress met in Oxford, with substantially greater participation from the war-victorious Anglo-Americans. In 1929, the Congress took place at Yale University in New Haven, Connecticut, attended by hundreds of members of the American Psychological Association[23] Tokyo Imperial University led the way in bringing the new psychology to the East, and from Japan these ideas diffused into China.[17][24]American psychology gained status during World War I, during which a standing committee headed by Robert Yerkes administered mental tests  to almost 1.8 million GIs.[34] Subsequent funding for behavioral research came in large part from the Rockefeller family, via the Social Science Research Council.[35][36] Rockefeller charities funded the National Committee on Mental Hygiene, which promoted the concept of mental illness and lobbied for psychological supervision of child development.[34][37] Through the Bureau of Social Hygiene and later funding of Alfred Kinsey, Rockefeller foundations established sex research as a viable discipline in the U.S.[38] Under the influence of the Carnegie-funded Eugenics Record Office, the Draper-funded Pioneer Fund, and other institutions, the eugenics movement also had a significant impact on American psychology; in the 1910s and 1920s, eugenics became a standard topic in psychology classes.[39]During World War II and the Cold War, the U.S. military and intelligence agencies established themselves as leading funders of psychology\u2014through the armed forces and in the new Office of Strategic Services intelligence agency. University of Michigan psychologist Dorwin Cartwright reported that university researchers began large-scale propaganda research in 1939\u20131941, and \"the last few months of the war saw a social psychologist become chiefly responsible for determining the week-by-week-propaganda policy for the United States Government.\" Cartwright also wrote that psychologists had significant roles in managing the domestic economy.[40] The Army rolled out its new General Classification Test and engaged in massive studies of troop morale. In the 1950s, the Rockefeller Foundation and Ford Foundation collaborated with the Central Intelligence Agency to fund research on psychological warfare.[41] In 1965, public controversy called attention to the Army's Project Camelot\u2014the \"Manhattan Project\" of social science\u2014an effort which enlisted psychologists and anthropologists to analyze foreign countries for strategic purposes.[42][43]In Germany after World War I, psychology held institutional power through the military, and subsequently expanded along with the rest of the military under the Third Reich.[19] Under the direction of Hermann G\u00f6ring's cousin Matthias G\u00f6ring, the Berlin Psychoanalytic Institute was renamed the G\u00f6ring Institute. Freudian psychoanalysts were expelled and persecuted under the anti-Jewish policies of the Nazi Party, and all psychologists had to distance themselves from Freud and Adler.[44] The G\u00f6ring Institute was well-financed throughout the war with a mandate to create a \"New German Psychotherapy\". This psychotherapy aimed to align suitable Germans with the overall goals of the Reich; as described by one physician: \"Despite the importance of analysis, spiritual guidance and the active cooperation of the patient represent the best way to overcome individual mental problems and to subordinate them to the requirements of the Volk and the Gemeinschaft.\" Psychologists were to provide Seelenf\u00fchrung, leadership of the mind, to integrate people into the new vision of a German community.[45] Harald Schultz-Hencke melded psychology with the Nazi theory of biology and racial origins, criticizing psychoanalysis as a study of the weak and deformed.[46] Johannes Heinrich Schultz, a German psychologist recognized for developing the technique of autogenic training, prominently advocated sterilization and euthanasia of men considered genetically undesirable, and devised techniques for facilitating this process.[47] After the war, some new institutions were created and some psychologists were discredited due to Nazi affiliation. Alexander Mitscherlich founded a prominent applied psychoanalysis journal called Psyche and with funding from the Rockefeller Foundation established the first clinical psychosomatic medicine division at Heidelberg University. In 1970, psychology was integrated into the required studies of medical students.[48]After the Russian Revolution, psychology was heavily promoted by the Bolsheviks as a way to engineer the \"New Man\" of socialism. Thus, university psychology departments trained large numbers of students, for whom positions were made available at schools, workplaces, cultural institutions, and in the military. An especial focus was pedology, the study of child development, regarding which Lev Vygotsky became a prominent writer.[31] The Bolsheviks also promoted free love and embranced the doctrine of psychoanalysis as an antidote to sexual repression.[49] Although pedology and intelligence testing fell out of favor in 1936, psychology maintained its privileged position as an instrument of the Soviet state.[31] Stalinist purges took a heavy toll and instilled a climate of fear in the profession, as elsewhere in Soviet society.[50] Following World War II, Jewish psychologists past and present . Interdisciplinary studies became popular and scholars such as Georgy Shchedrovitsky developed systems theory approaches to human behavior.[52]Twentieth-century Chinese psychology originally modeled the United States, with translations from American authors like William James, the establishment of university psychology departments and journals, and the establishment of groups including the Chinese Association of Psychological Testing [54] Psychology education was centralized under the Chinese Academy of Sciences, supervised by the State Council. In 1951 the Academy created a Psychology Research Office, which in 1956 became the Institute of Psychology. Most leading psychologists were educated in the United States, and the first concern of the Academy was re-education of these psychologists in the Soviet doctrines. Child psychology and pedagogy for nationally cohesive education remained a central goal of the discipline.[55]In 1920, \u00c9douard Clapar\u00e8de and Pierre Bovet created a new applied psychology organization called the International Congress of Psychotechnics Applied to Vocational Guidance, later called the International Congress of Psychotechnics and then the International Association of Applied Psychology.[23] The IAAP is considered the oldest international psychology association.[56] Today, at least 65 international groups deal with specialized aspects of psychology.[56] In response to male predominance in the field, female psychologists in the U.S. formed National Council of Women Psychologists in 1941. This organization became the International Council of Women Psychologists after World War II, and the International Council of Psychologists in 1959. Several associations including the Association of Black Psychologists and the Asian American Psychological Association have arisen to promote non-European racial groups in the profession.[56]The world federation of national psychological societies is the International Union of Psychological Science , founded in 1951 under the auspices of UNESCO, the United Nations cultural and scientific authority.[23][57] Psychology departments have since proliferated around the world, based primarily on the Euro-American model.[18][57] Since 1966, the Union has published the International Journal of Psychology.[23] IAAP and IUPsyS agreed in 1976 each to hold a congress every four years, on a staggered basis.[56]The International Union recognizes 66 national psychology associations and at least 15 others exist.[56] The American Psychological Association is the oldest and largest.[56] Its membership has increased from 5,000 in 1945 to 100,000 in the present day.[26] The APA includes 54 divisions, which since 1960 have steadily proliferated to include more specialties. Some of these divisions, such as the Society for the Psychological Study of Social Issues and the American Psychology\u2013Law Society, began as autonomous groups.[56]The Interamerican Society of Psychology, founded in 1951, aspires to promote psychology and coordinate psychologists across the Western Hemisphere. It holds the Interamerican Congress of Psychology and had 1000 members in year 2000. The European Federation of Professional Psychology Associations, founded in 1981, represents 30 national associations with a total of 100,000 individual members. At least 30 other international groups organize psychologists in different regions.[56]In some places, governments legally regulate who can provide psychological services or represent themselves as a \"psychologist\".[58] The American Psychological Association defines a psychologist as someone with a doctoral degree in psychology.[59]Early practitioners of experimental psychology distinguished themselves from parapsychology, which in the late nineteenth century enjoyed great popularity , and indeed constituted the bulk of what people called \"psychology\". Parapsychology, hypnotism, and psychism were major topics of the early International Congresses. But students of these fields were eventually ostractized, and more or less banished from the Congress in 1900\u20131905.[23] Parapsychology persisted for a time at Imperial University, with publications such as Clairvoyance and Thoughtography by Tomokichi Fukurai, but here too it was mostly shunned by 1913.[24]As a discipline, psychology has long sought to fend off accusations that it is a \"soft\" science. Philosopher of science Thomas Kuhn's 1962 critique implied psychology overall was in a pre-paradigm state, lacking the agreement on overarching theory found in mature sciences such as chemistry and physics.[60] Because some areas of psychology rely on research methods such as surveys and questionnaires, critics asserted that psychology is not an objective science. Skeptics have suggested that personality, thinking, and emotion, cannot be directly measured and are often inferred from subjective self-reports, which may be problematic. Experimental psychologists have devised a variety of ways to indirectly measure these elusive phenomenological entities.[61][62][63]Divisions still exist within the field, with some psychologists more oriented towards the unique experiences of individual humans, which cannot be understood only as data points within a larger population. Critics inside and outside the field have argued that mainstream psychology has become increasingly dominated by a \"cult of empiricism\" which limits the scope of its study by using only methods derived from the physical sciences.[64] Feminist critiques along these lines have argued that claims to scientific objectivity obscure the values and agenda of [34] researchers. Jean Grimshaw, for example, argues that mainstream psychological research has advanced a patriarchal agenda through its efforts to control behavior.[65]Psychologists generally consider the organism the basis of the mind, and therefore a vitally related area of study. Psychiatrists and neuropsychologists work at the interface of mind and body.[66] Biological psychology, also known as physiological psychology,[67] or neuropsychology is the study of the biological substrates of behavior and mental processes. Key research topics in this field include comparative psychology, which studies humans in relation to other animals, and perception which involves the physical mechanics of sensation as well as neural and mental processing.[68] For centuries, a leading question in biological psychology has been whether and how mental functions might be localized in the brain. From Phineas Gage to H. M. and Clive Wearing, individual people with mental issues traceable to physical damage have inspired new discoveries in this area.[67] Modern neuropsychology could be said to originate in the 1870s, when in France Paul Broca traced production of speech to the left frontal gyrus, thereby also demonstrating hemispheric lateralization of brain function. Soon after, Carl Wernicke identified a related area necessary for the understanding of speech.[69]The contemporary field of behavioral neuroscience focuses on physical causes underpinning behavior. For example, physiological psychologists use animal models, typically rats, to study the neural, genetic, and cellular mechanisms that underlie specific behaviors such as learning and memory and fear responses.[70] Cognitive neuroscientists investigate the neural correlates of psychological processes in humans using neural imaging tools, and neuropsychologists conduct psychological assessments to determine, for instance, specific aspects and extent of cognitive deficit caused by brain damage or disease. The biopsychosocial model is an integrated perspective toward understanding consciousness, behavior, and social interaction. It assumes that any given behavior or mental process affects and is affected by dynamically interrelated biological, psychological, and social factors.[71]Evolutionary psychology examines cognition and personality traits from an evolutionary perspective. This perspective suggests that psychological adaptations evolved to solve recurrent problems in human ancestral environments. Evolutionary psychology offers complementary explanations for the mostly proximate or developmental explanations developed by other areas of psychology: that is, it focuses mostly on ultimate or \"why?\" questions, rather than proximate or \"how?\" questions. \"How?\" questions are more directly tackled by behavioral genetics research, which aims to understand how genes and environment impact behavior.[72]The search for biological origins of psychological phenomena has long involved debates about the importance of race, and especially the relationship between race and intelligence. The idea of white supremacy and indeed the modern concept of race itself arose during the process of world conquest by Europeans.[73] Carl von Linnaeus's four-fold classification of humans classifies Europeans as intelligent and severe, Americans as contented and free, Asians as ritualistic, and Africans as lazy and capricious. Race was also used to justify the construction of socially specific mental disorders such as drapetomania and dysaesthesia aethiopica\u2014the behavior of uncooperative African slaves.[74] After the creation of experimental psychology, \"ethnical psychology\" emerged as a subdiscipline, based on the assumption that studying primitive races would provide an important link between animal behavior and the psychology of more evolved humans.[75]Psychologists take human behavior as a main area of study. Much of the research in this area began with tests on mammals, based on the idea that humans exhibit similar fundamental tendencies. Behavioral research ever aspires to improve the effectiveness of techniques for behavior modification.Early behavioral researchers studied stimulus\u2013response pairings, now known as classical conditioning. They demonstrated that behaviors could be linked through repeated association with stimuli eliciting pain or pleasure. Ivan Pavlov\u2014known best for inducing dogs to salivate in the presence of a stimulus previous linked with food\u2014became a leading figure in the Soviet Union and inspired followers to use his methods on humans.[31] In the United States, Edward Lee Thorndike initiated \"connectionism\" studies by trapping animals in \"puzzle boxes\" and rewarding them for escaping. Thorndike wrote in 1911: \"There can be no moral warrant for studying man's nature unless the study will enable us to control his acts.\"[76] From 1910\u20131913 the American Psychological Association went through a sea change of opinion, away from mentalism and towards \"behavioralism\", and in 1913 John B. Watson coined the term behaviorism for this school of thought.[77] Watson's famous Little Albert experiment in 1920 demonstrated that repeated use of upsetting loud noises could instill phobias  in an infant human.[12][78] Karl Lashley, a close collaborator with Watson, examined biological manifestations of learning in the brain.[67]Embraced and extended by Clark L. Hull, Edwin Guthrie, and others, behaviorism became a widely used research paradigm.[26] A new method of \"instrumental\" or \"operant\" conditioning added the concepts of reinforcement and punishment to the model of behavior change. Radical behaviorists avoided discussing the inner workings of the mind, especially the unconscious mind, which they considered impossible to assess scientifically.[79] Operant conditioning was first described by Miller and Kanorski and popularized in the U.S. by B. F. Skinner, who emerged as a leading intellectual of the behaviorist movement.[80][81]Noam Chomsky delivered an influential critique of radical behaviorism on the grounds that it could not adequately explain the complex mental process of language acquisition.[82][83][84] Martin Seligman and colleagues discovered that the conditioning of dogs led to outcomes  that opposed the predictions of behaviorism.[85][86] Skinner's behaviorism did not die, perhaps in part because it generated successful practical applications.[82] Edward C. Tolman advanced a hybrid \"cognitive behaviorial\" model, most notably with his 1948 publication discussing the cognitive maps used by rats to guess at the location of food at the end of a modified maze.[87]The Association for Behavior Analysis International was founded in 1974 and by 2003 had members from 42 countries. The field has been especially influential in Latin America, where it has a regional organization known as ALAMOC: La Asociaci\u00f3n Latinoamericana de An\u00e1lisis y Modificaci\u00f3n del Comportamiento. Behaviorism also gained a strong foothold in Japan, where it gave rise to the Japanese Society of Animal Psychology .[88] Today the field of behaviorism is also commonly referred to as behavior modification or behavior analysis.[88]Cognitive psychology studies cognition, the mental processes underlying mental activity. Perception, attention, reasoning, thinking, problem solving, memory, learning, language, and emotion are areas of research. Classical cognitive psychology is associated with a school of thought known as cognitivism, whose adherents argue for an information processing model of mental function, informed by functionalism and experimental psychology.On a broader level, cognitive science is an interdisciplinary enterprise of cognitive psychologists, cognitive neuroscientists, researchers in artificial intelligence, linguists, human\u2013computer interaction, computational neuroscience, logicians and social scientists. Computer simulations are sometimes used to model phenomena of interest.Starting in the 1950s, the experimental techniques developed by Wundt, James, Ebbinghaus, and others re-emerged as experimental psychology became increasingly cognitivist\u2014concerned with information and its processing\u2014and, eventually, constituted a part of the wider cognitive science.[89] Some called this development the cognitive revolution because it rejected the anti-mentalist dogma of behaviorism as well as the strictures of psychoanalysis.[89]Social learning theorists, such as Albert Bandura, argued that the child's environment could make contributions of its own to the behaviors of an observant subject.[90]Technological advances also renewed interest in mental states and representations. English neuroscientist Charles Sherrington and Canadian psychologist Donald O. Hebb used experimental methods to link psychological phenomena with the structure and function of the brain. The rise of computer science, cybernetics and artificial intelligence suggested the value of comparatively studying information processing in humans and machines. Research in cognition had proven practical since World War II, when it aided in the understanding of weapons operation.[91]A popular and representative topic in this area is cognitive bias, or irrational thought. Psychologists  have classified and described a sizeable catalogue of biases which recur frequently in human thought. The availability heuristic, for example, is the tendency to overestimate the importance of something which happens to come readily to mind.Elements of behaviorism and cognitive psychology were synthesized to form cognitive behavioral therapy, a form of psychotherapy modified from techniques developed by American psychologist Albert Ellis and American psychiatrist Aaron T. Beck. Cognitive psychology was subsumed along with other disciplines, such as philosophy of mind, computer science, and neuroscience, under the cover discipline of cognitive science.Social psychology is the study of how humans think about each other and how they relate to each other. Social psychologists study such topics as the influence of others on an individual's behavior , and the formation of beliefs, attitudes, and stereotypes about other people. Social cognition fuses elements of social and cognitive psychology in order to understand how people process, remember, or distort social information. The study of group dynamics reveals information about the nature and potential optimization of leadership, communication, and other phenomena that emerge at least at the microsocial level. In recent years, many social psychologists have become increasingly interested in implicit measures, mediational models, and the interaction of both person and social variables in accounting for behavior. The study of human society is therefore a potentially valuable source of information about the causes of psychiatric disorder. Some sociological concepts applied to psychiatric disorders are the social role, sick role, social class, life event, culture, migration, social, and total institution.Psychoanalysis comprises a method of investigating the mind and interpreting experience; a systematized set of theories about human behavior; and a form of psychotherapy to treat psychological or emotional distress, especially conflict originating in the unconscious mind.[92] This school of thought originated in the 1890s with Austrian medical doctors including Josef Breuer . Freud's psychoanalytic theory was largely based on interpretive methods, introspection and clinical observations. It became very well known, largely because it tackled subjects such as sexuality, repression, and the unconscious. These subjects were largely taboo at the time, and Freud provided a catalyst for their open discussion in polite society.[49] Clinically, Freud helped to pioneer the method of free association and a therapeutic interest in dream interpretation.[93][94]Swiss psychiatrist Carl Jung, influenced by Freud, elaborated a theory of the collective unconscious\u2014a primordial force present in all humans, featuring archetypes which exerted a profound influence on the mind. Jung's competing vision formed the basis for analytical psychology, which later led to the archetypal and process-oriented schools. Other well-known psychoanalytic scholars of the mid-20th century include Erik Erikson, Melanie Klein, D. W. Winnicott, Karen Horney, Erich Fromm, John Bowlby, and Sigmund Freud's daughter, Anna Freud. Throughout the 20th century, psychoanalysis evolved into diverse schools of thought which could be called Neo-Freudian. Among these schools are ego psychology, object relations, and interpersonal, Lacanian, and relational psychoanalysis.Psychologists such as Hans Eysenck and philosophers including Karl Popper criticized psychoanalysis. Popper argued that psychoanalysis had been misrepresented as a scientific discipline,[95] whereas Eysenck said that psychoanalytic tenets had been contradicted by experimental data. By the end of 20th century, psychology departments in American universities mostly marginalized Freudian theory, dismissing it as a \"desiccated and dead\" historical artifact.[96] However, researchers in the emerging field of neuro-psychoanalysis today defend some of Freud's ideas on scientific grounds,[97] while scholars of the humanities maintain that Freud was not a \"scientist at all, but ... an interpreter\".[96]Humanistic psychology developed in the 1950s as a movement within academic psychology, in reaction to both behaviorism and psychoanalysis.[99] The humanistic approach sought to glimpse the whole person, not just fragmented parts of the personality or isolated cognitions.[100] Humanism focused on uniquely human issues, such as free will, personal growth, self-actualization, self-identity, death, aloneness, freedom, and meaning. It emphasized subjective meaning, rejection of determinism, and concern for positive growth rather than pathology.[citation needed] Some founders of the humanistic school of thought were American psychologists Abraham Maslow, who formulated a hierarchy of human needs, and Carl Rogers, who created and developed client-centered therapy. Later, positive psychology opened up humanistic themes to scientific modes of exploration.The American Association for Humanistic Psychology, formed in 1963, declared:In the 1950s and 1960s, influenced by philosophers S\u00f8ren Kierkegaard and Martin Heidegger and, psychoanalytically trained American psychologist Rollo May pioneered an existential branch of psychology, which included existential psychotherapy: a method based on the belief that inner conflict within a person is due to that individual's confrontation with the givens of existence. Swiss psychoanalyst Ludwig Binswanger and American psychologist George Kelly may also be said to belong to the existential school.[102] Existential psychologists differed from more \"humanistic\" psychologists in their relatively neutral view of human nature and their relatively positive assessment of anxiety.[103] Existential psychologists emphasized the humanistic themes of death, free will, and meaning, suggesting that meaning can be shaped by myths, or narrative patterns,[104] and that it can be encouraged by an acceptance of the free will requisite to an authentic, albeit often anxious, regard for death and other future prospects.Austrian existential psychiatrist and Holocaust survivor Viktor Frankl drew evidence of meaning's therapeutic power from reflections garnered from his own internment.[105] He created a variation of existential psychotherapy called logotherapy, a type of existentialist analysis that focuses on a will to meaning , as opposed to Adler's Nietzschean doctrine of will to power or Freud's will to pleasure.[106]Personality psychology is concerned with enduring patterns of behavior, thought, and emotion\u2014commonly referred to as personality\u2014in individuals. Theories of personality vary across different psychological schools and orientations. They carry different assumptions about such issues as the role of the unconscious and the importance of childhood experience. According to Freud, personality is based on the dynamic interactions of the id, ego, and super-ego.[107] In order to develop a taxonomy of personality constructs, trait theorists, in contrast, attempt to describe the personality sphere in terms of a discrete number of key traits using the statistical data-reduction method of factor analysis. Although the number of proposed traits has varied widely, an early biologically-based model proposed by Hans Eysenck, the 3rd mostly highly cited psychologist of the 20th Century , rather than the \"Big Five\" dimensions.[109][110][111][112] Dimensional models of personality are receiving increasing support, and a version of dimensional assessment has been included in the DSM-V. However, despite a plethora of research into the various versions of the \"Big Five\" personality dimensions, it appears necessary to move on from static conceptualizations of personality structure to a more dynamic orientation, whereby it is acknowledged that personality constructs are subject to learning and change across the lifespan.[113][114]An early example of personality assessment was the Woodworth Personal Data Sheet, constructed during World War I. The popular, although psychometrically inadequate Myers\u2013Briggs Type Indicator[115] sought to assess individuals' \"personality types\" according to the personality theories of Carl Jung. Behaviorist resistance to introspection led to the development of the Strong Vocational Interest Blank and Minnesota Multiphasic Personality Inventory , in an attempt to ask empirical questions that focused less on the psychodynamics of the respondent.[116] However, the MMPI has been subjected to critical scrutiny, given that it adhered to archaic psychiatric nosology, and since it required individuals to provide subjective, introspective responses to the hundreds of items pertaining to psychopathology.[117]Study of the unconscious mind, a part of the psyche outside the awareness of the individual which nevertheless influenced thoughts and behavior was a hallmark of early psychology. In one of the first psychology experiments conducted in the United States, C. S. Peirce and Joseph Jastrow found in 1884 that subjects could choose the minutely heavier of two weights even if consciously uncertain of the difference.[118] Freud popularized this concept, with terms like Freudian slip entering popular culture, to mean an uncensored intrusion of unconscious thought into one's speech and action. His 1901 text The Psychopathology of Everyday Life catalogues hundreds of everyday events which Freud explains in terms of unconscious influence. Pierre Janet advanced the idea of a subconscious mind, which could contain autonomous mental elements unavailable to the scrutiny of the subject.[119]Behaviorism notwithstanding, the unconscious mind has maintained its importance in psychology. Cognitive psychologists have used a \"filter\" model of attention, according to which much information processing takes place below the threshold of consciousness, and only certain processes, limited by nature and by simultaneous quantity, make their way through the filter. Copious research has shown that subconscious priming of certain ideas can covertly influence thoughts and behavior.[119] A significant hurdle in this research is proving that a subject's conscious mind has not grasped a certain stimulus, due to the unreliability of self-reporting. For this reason, some psychologists prefer to distinguish between implicit and explicit memory. In another approach, one can also describe a subliminal stimulus as meeting an objective but not a subjective threshold.[120]The automaticity model, which became widespread following exposition by John Bargh and others in the 1980s, describes sophisticated processes for executing goals which can be selected and performed over an extended duration without conscious awareness.[121][122] Some experimental data suggests that the brain begins to consider taking actions before the mind becomes aware of them.[120][123] This influence of unconscious forces on people's choices naturally bears on philosophical questions free will. John Bargh, Daniel Wegner, and Ellen Langer are some prominent contemporary psychologists who describe free will as an illusion.[121][122][124]Psychologists such as William James initially used the term motivation to refer to intention, in a sense similar to the concept of will in European philosophy. With the steady rise of Darwinian and Freudian thinking, instinct also came to be seen as a primary source of motivation.[125] According to drive theory, the forces of instinct combine into a single source of energy which exerts a constant influence. Psychoanalysis, like biology, regarded these forces as physical demands made by the organism on the nervous system. However, they believed that these forces, especially the sexual instincts, could become entangled and transmuted within the psyche. Classical psychoanalysis conceives of a struggle between the pleasure principle and the reality principle, roughly corresponding to id and ego. Later, in Beyond the Pleasure Principle, Freud introduced the concept of the death drive, a compulsion towards aggression, destruction, and psychic repetition of traumatic events.[126] Meanwhile, behaviorist researchers used simple dichotomous models  and well-established principles such as the idea that a thirsty creature will take pleasure in drinking.[125][127] Clark Hull formalized the latter idea with his drive reduction model.[128]Hunger, thirst, fear, sexual desire, and thermoregulation all seem to constitute fundamental motivations for animals.[127] Humans also seem to exhibit a more complex set of motivations\u2014though theoretically these could be explained as resulting from primordial instincts\u2014including desires for belonging, self-image, self-consistency, truth, love, and control.[129][130]Motivation can be modulated or manipulated in many different ways. Researchers have found that eating, for example, depends not only on the organism's fundamental need for homeostasis\u2014an important factor causing the experience of hunger\u2014but also on circadian rhythms, food availability, food palatability, and cost.[127] Abstract motivations are also malleable, as evidenced by such phenomena as goal contagion: the adoption of goals, sometimes unconsciously, based on inferences about the goals of others.[131] Vohs and Baumeister suggest that contrary to the need-desire-fulfilment cycle of animal instincts, human motivations sometimes obey a \"getting begets wanting\" rule: the more you get a reward such as self-esteem, love, drugs, or money, the more you want it. They suggest that this principle can even apply to food, drink, sex, and sleep.[132]Mainly focusing on the development of the human mind through the life span, developmental psychology seeks to understand how people come to perceive, understand, and act within the world and how these processes change as they age. This may focus on cognitive, affective, moral, social, or neural development. Researchers who study children use a number of unique research methods to make observations in natural settings or to engage them in experimental tasks. Such tasks often resemble specially designed games and activities that are both enjoyable for the child and scientifically useful, and researchers have even devised clever methods to study the mental processes of infants. In addition to studying children, developmental psychologists also study aging and processes throughout the life span, especially at other times of rapid change . Developmental psychologists draw on the full range of psychological theories to inform their research.All researched psychological traits are influenced by both genes and environment, to varying degrees.[133][134] These two sources of influence are often confounded in observational research of individuals or families. An example is the transmission of depression from a depressed mother to her offspring. Theory may hold that the offspring, by virtue of having a depressed mother in his or her  of genetic variants, each of small effect, contribute to individual differences in the behavioral trait or propensity to the disorder. Active research continues to understand the genetic and environmental bases of behavior and their interaction.Psychology encompasses many subfields and includes different approaches to the study of mental processes and behavior:Psychological testing has ancient origins, such as examinations for the Chinese civil service dating back to 2200 BC. Written exams began during the Han dynasty . By 1370, the Chinese system required a stratified series of tests, involving essay writing and knowledge of diverse topics. The system was ended in 1906.[140] In Europe, mental assessment took a more physiological approach, with theories of physiognomy\u2014judgment of character based on the face\u2014described by Aristotle in 4th century BC Greece. Physiognomy remained current through the Enlightenment, and added the doctrine of phrenology: a study of mind and intelligence based on simple assessment of neuroanatomy.[141]When experimental psychology came to Britain, Francis Galton was a leading practitioner, and, with his procedures for measuring reaction time and sensation, is considered an inventor of modern mental testing  and introduced the intelligence quotient as a score report.[144] From this test, Terman concluded that mental retardation \"represents the level of intelligence which is very, very common among Spanish-Indians and Mexican families of the Southwest and also among negroes. Their dullness seems to be racial.\"[145]Following the Army Alpha and Army Beta tests for soldiers in World War I, mental testing became popular in the US, where it was soon applied to school children. The federally created National Intelligence Test was administered to 7 million children in the 1920s, and in 1926 the College Entrance Examination Board created the Scholastic Aptitude Test to standardize college admissions.[146] The results of intelligence tests were used to argue for segregated schools and economic functions\u2014i.e. the preferential training of Black Americans for manual labor. These practices were criticized by black intellectuals such a Horace Mann Bond and Allison Davis.[145] Eugenicists used mental testing to justify and organize compulsory sterilization of individuals classified as mentally retarded.[39] In the United States, tens of thousands of men and women were sterilized. Setting a precedent which has never been overturned, the U.S. Supreme Court affirmed the constitutionality of this practice in the 1907 case Buck v. Bell.[147]Today mental testing is a routine phenomenon for people of all ages in Western societies.[148] Modern testing aspires to criteria including standardization of procedure, consistency of results, output of an interpretable score, statistical norms describing population outcomes, and, ideally, effective prediction of behavior and life outcomes outside of testing situations.[149]The provision of psychological health services is generally called clinical psychology in the U.S. The definitions of this term are various and may include school psychology and counseling psychology. Practitioners typically includes people who have graduated from doctoral programs in clinical psychology but may also include others. In Canada, the above groups usually fall within the larger category of professional psychology. In Canada and the US, practitioners get bachelor's degrees and doctorates, then spend one year in an internship and one year in postdoctoral education. In Mexico and most other Latin American and European countries, psychologists do not get bachelor's and doctorate degrees; instead, they take a three-year professional course following high school.[59] Clinical psychology is at present the largest specialization within psychology.[150] It includes the study and application of psychology for the purpose of understanding, preventing, and relieving psychologically based distress, dysfunction or mental illness and to promote subjective well-being and personal development. Central to its practice are psychological assessment and psychotherapy although clinical psychologists may also engage in research, teaching, consultation, forensic testimony, and program development and administration.[151]Credit for the first psychology clinic in the United States typically goes to Lightner Witmer, who established his practice in Philadelphia in 1896. Another modern psychotherapist was Morton Prince.[150] For the most part, in the first part of the twentieth century, most mental health care in the United States was performed by specialized medical doctors called psychiatrists. Psychology entered the field with its refinements of mental testing, which promised to improve diagnosis of mental problems. For their part, some psychiatrists became interested in using psychoanalysis and other forms of psychodynamic psychotherapy to understand and treat the mentally ill.[34] In this type of treatment, a specially trained therapist develops a close relationship with the patient, who discusses wishes, dreams, social relationships, and other aspects of mental life. The therapist seeks to uncover repressed material and to understand why the patient creates defenses against certain thoughts and feelings. An important aspect of the therapeutic relationship is transference, in which deep unconscious feelings in a patient reorient themselves and become manifest in relation to the therapist.[152]Psychiatric psychotherapy blurred the distinction between psychiatry and psychology, and this trend continued with the rise of community mental health facilities and behavioral therapy, a thoroughly non-psychodynamic model which used behaviorist learning theory to change the actions of patients. A key aspect of behavior therapy is empirical evaluation of the treatment's effectiveness. In the 1970s, cognitive-behavior therapy arose, using similar methods and now including the cognitive constructs which had gained popularity in theoretical psychology. A key practice in behavioral and cognitive-behavioral therapy is exposing patients to things they fear, based on the premise that their responses  can be deconditioned.[153]Mental health care today involves psychologists and social workers in increasing numbers. In 1977, National Institute of Mental Health director Bertram Brown described this shift as a source of \"intense competition and role confusion\".[34] Graduate programs issuing doctorates in psychology  emerged in the 1950s and underwent rapid increase through the 1980s. This degree is intended to train practitioners who might conduct scientific research.[59]Some clinical psychologists may focus on the clinical management of patients with brain injury\u2014this area is known as clinical neuropsychology. In many countries, clinical psychology is a regulated mental health profession. The emerging field of disaster psychology  involves professionals who respond to large-scale traumatic events.[154]The work performed by clinical psychologists tends to be influenced by various therapeutic approaches, all of which involve a formal relationship between professional and client . Typically, these approaches encourage new ways of thinking, feeling, or behaving. Four major theoretical perspectives are psychodynamic, cognitive behavioral, existential\u2013humanistic, and systems or family therapy. There has been a growing movement to integrate the various therapeutic approaches, especially with an increased understanding of issues regarding culture, gender, spirituality, and sexual orientation. With the advent of more robust research findings regarding psychotherapy, there is evidence that most of the major therapies have equal effectiveness, with the key common element being a strong therapeutic alliance.[155][156] Because of this, more training programs and psychologists are now adopting an eclectic therapeutic orientation.[157][158][159][160][161]Diagnosis in clinical psychology usually follows the Diagnostic and Statistical Manual of Mental Disorders , a handbook first published by the American Psychiatric Association in 1952. New editions over time have increased in size and focused more on medical language.[162] The study of mental illnesses is called abnormal psychology.Educational psychology is the study of how humans learn in educational settings, the effectiveness of educational interventions, the psychology of teaching, and the social psychology of schools as organizations. The work of child psychologists such as Lev Vygotsky, Jean Piaget, and Jerome Bruner has been influential in creating teaching methods and educational practices. Educational psychology is often included in teacher education programs in places such as North America, Australia, and New Zealand.School psychology combines principles from educational psychology and clinical psychology to understand and treat students with learning disabilities; to foster the intellectual growth of gifted students; to facilitate prosocial behaviors in adolescents; and otherwise to promote safe, supportive, and effective learning environments. School psychologists are trained in educational and behavioral assessment, intervention, prevention, and consultation, and many have extensive training in research.[163]Industrialists soon brought the nascent field of psychology to bear on the study of scientific management techniques for improving workplace efficiency. This field was at first called economic psychology or business psychology; later, industrial psychology, employment psychology, or psychotechnology.[164] An important early study examined workers at Western Electric's Hawthorne plant in Cicero, Illinois from 1924\u20131932. With funding from the Laura Spelman Rockefeller Fund and guidance from Australian psychologist Elton Mayo, Western Electric experimented on thousands of factory workers to assess their responses to illumination, breaks, food, and wages. The researchers came to focus on workers' responses to observation itself, and the term Hawthorne effect is now used to describe the fact that people work harder when they think they're being watched.[165]The name industrial and organizational psychology  arose in the 1960s and became enshrined as the Society for Industrial and Organizational Psychology, Division 14 of the American Psychological Association, in 1973.[164] The goal is to optimize human potential in the workplace. Personnel psychology, a subfield of I\u2013O psychology, applies the methods and principles of psychology in selecting and evaluating workers. I\u2013O psychology's other subfield, organizational psychology, examines the effects of work environments and management styles on worker motivation, job satisfaction, and productivity.[166] The majority of I\u2013O psychologists work outside of academia, for private and public organizations and as consultants.[164] A psychology consultant working in business today might expect to provide executives with information and ideas about their industry, their target markets, and the organization of their company.[167]One role for psychologists in the military is to evaluate and counsel soldiers and other personnel. In the U.S., this function began during World War I, when Robert Yerkes established the School of Military Psychology at Fort Oglethorpe in Georgia, to provide psychological training for military staff military.[34][168] Today, U.S Army psychology includes psychological screening, clinical psychotherapy, suicide prevention, and treatment for post-traumatic stress, as well as other aspects of health and workplace psychology such as smoking cessation.[169]Psychologists may also work on a diverse set of campaigns known broadly as psychological warfare. Psychologically warfare chiefly involves the use of propaganda to influence enemy soldiers and civilians. In the case of so-called black propaganda the propaganda is designed to seem like it originates from a different source.[170] The CIA's MKULTRA program involved more individualized efforts at mind control, involving techniques such as hypnosis, torture, and covert involuntary administration of LSD.[171] The U.S. military used the name Psychological Operations .[172] Psychologists are sometimes involved in assisting the interrogation and torture of suspects, though this has sometimes been denied by those involved and sometimes opposed by others.[173]Medical facilities increasingly employ psychologists to perform various roles. A prominent aspect of health psychology is the psychoeducation of patients: instructing them in how to follow a medical regimen. Health psychologists can also educate doctors and conduct research on patient compliance.[174]Psychologists in the field of public health use a wide variety of interventions to influence human behavior. These range from public relations campaigns and outreach to governmental laws and policies. Psychologists study the composite influence of all these different tools in an effort to influence whole populations of people.[175]Black American psychologists Kenneth and Mamie Clark studied the psychological impact of segregation and testified with their findings in the desegregation case Brown v. Board of Education .[176]Positive psychology is the study of factors which contribute to human happiness and well-being, focusing more on people who are currently healthy. In 2010 Clinical Psychological Review published a special issue devoted to positive psychological interventions, such as gratitude journaling and the physical expression of gratitude. Positive psychological interventions have been limited in scope, but their effects are thought to be superior to that of placebos, especially with regard to helping people with body image problems.Quantitative psychological research lends itself to the statistical testing of hypotheses. Although the field makes abundant use of randomized and controlled experiments in laboratory settings, such research can only assess a limited range of short-term phenomena. Thus, psychologists also rely on creative statistical methods to glean knowledge from clinical trials and population data.[177] These include the Pearson product\u2013moment correlation coefficient, the analysis of variance, multiple linear regression, logistic regression, structural equation modeling, and hierarchical linear modeling. The measurement and operationalization of important constructs is an essential part of these research designs.A true experiment with random allocation of subjects to conditions allows researchers to make strong inferences about causal relationships. In an experiment, the researcher alters parameters of influence, called independent variables, and measures resulting changes of interest, called dependent variables. Prototypical experimental research is conducted in a laboratory with a carefully controlled environment.Repeated-measures experiments are those which take place through intervention on multiple occasions. In research on the effectiveness of psychotherapy, experimenters often compare a given treatment with placebo treatments, or compare different treatments against each other. Treatment type is the independent variable. The dependent variables are outcomes, ideally assessed in several ways by different professionals.[180] Using crossover design, researchers can further increase the strength of their results by testing both of two treatments on two groups of subjects.Quasi-experimental design refers especially to situations precluding random assignment to different conditions. Researchers can use common sense to consider how much the nonrandom assignment threatens the study's validity.[181] For example, in research on the best way to affect reading achievement in the first three grades of school, school administrators may not permit educational psychologists to randomly assign children to phonics and whole language classrooms, in which case the psychologists must work with preexisting classroom assignments. Psychologists will compare the achievement of children attending phonics and whole language classes.Experimental researchers typically use a statistical hypothesis testing model which involves making predictions before conducting the experiment, then assessing how well the data supports the predictions.  statistical techniques are used to distinguish unique results of the experiment from the null hypothesis that variations result from random fluctuations in data. In psychology, the widely used standard ascribes statistical significance to results which have less than 5% probability of being explained by random variation.[182]Statistical surveys are used in psychology for measuring attitudes and traits, monitoring changes in mood, checking the validity of experimental manipulations, and for other psychological topics. Most commonly, psychologists use paper-and-pencil surveys. However, surveys are also conducted over the phone or through e-mail. Web-based surveys are increasingly used to conveniently reach many subjects.Neuropsychological tests, such as the Wechsler scales and Wisconsin Card Sorting Test, are mostly questionnaires or simple tasks used which assess a specific type of mental function in the respondent. These can be used in experiments, as in the case of lesion experiments evaluating the results of damage to a specific part of the brain.[183]Observational studies analyze uncontrolled data in search of correlations; multivariate statistics are typically used to interpret the more complex situation. Cross-sectional observational studies use data from a single point in time, whereas longitudinal studies are used to study trends across the life span. Longitudinal studies track the same people, and therefore detect more individual, rather than cultural, differences. However, they suffer from lack of controls and from confounding factors such as selective attrition .Exploratory data analysis refers to a variety of practices which researchers can use to visualize and analyze existing sets of data. In Peirce's three modes of inference, exploratory data anlysis corresponds to abduction, or hypothesis formation.[184] Meta-analysis is the technique of integrating the results from multiple studies and interpreting the statistical properties of the pooled dataset.[185]A classic and popular tool used to relate mental and neural activity is the electroencephalogram , a technique using amplified electrodes on a person's scalp to measure voltage changes in different parts of the brain. Hans Berger, the first researcher to use EEG on an unopened skull, quickly found that brains exhibit signature \"brain waves\": electric oscillations which correspond to different states of consciousness. Researchers subsequently refined statistical methods for synthesizing the electrode data, and identified unique brain wave patterns such as the delta wave observed during non-REM sleep.[186]Newer functional neuroimaging techniques include functional magnetic resonance imaging and positron emission tomography, both of which track the flow of blood through the brain. These technologies provide more localized information about activity in the brain and create representations of the brain with widespread appeal. They also provide insight which avoids the classic problems of subjective self-reporting. It remains challenging to draw hard conclusions about where in the brain specific thoughts originate\u2014or even how usefully such localization corresponds with reality. However, neuroimaging has delivered unmistakable results showing the existence of correlations between mind and brain. Some of these draw on a systemic neural network model rather than a localized function model.[187][188][189]Psychiatric interventions such as transcranial magnetic stimulation and drugs also provide information about brain\u2013mind interactions. Psychopharmacology is the study of drug-induced mental effects.Computational modeling is a tool used in mathematical psychology and cognitive psychology to simulate behavior.[190] This method has several advantages. Since modern computers process information quickly, simulations can be run in a short time, allowing for high statistical power. Modeling also allows psychologists to visualize hypotheses about the functional organization of mental events that couldn't be directly observed in a human. Connectionism uses neural networks to simulate the brain. Another method is symbolic modeling, which represents many mental objects using variables and rules. Other types of modeling include dynamic systems and stochastic modeling.Animal experiments aid in investigating many aspects of human psychology, including perception, emotion, learning, memory, and thought, to name a few. In the 1890s, Russian physiologist Ivan Pavlov famously used dogs to demonstrate classical conditioning. Non-human primates, cats, dogs, pigeons, rats, and other rodents are often used in psychological experiments. Ideally, controlled experiments introduce only one independent variable at a time, in order to ascertain its unique effects upon dependent variables. These conditions are approximated best in laboratory settings. In contrast, human environments and genetic backgrounds vary so widely, and depend upon so many factors, that it is difficult to control important variables for human subjects. There are pitfalls in generalizing findings from animal studies to humans through animal models.[191]Comparative psychology refers to the scientific study of the behavior and mental processes of non-human animals, especially as these relate to the phylogenetic history, adaptive significance, and development of behavior. Research in this area explores the behavior of many species, from insects to primates. It is closely related to other disciplines that study animal behavior such as ethology.[192] Research in comparative psychology sometimes appears to shed light on human behavior, but some attempts to connect the two have been quite controversial, for example the Sociobiology of E. O. Wilson.[193] Animal models are often used to study neural processes related to human behavior, e.g. in cognitive neuroscience.Research designed to answer questions about the current state of affairs such as the thoughts, feelings, and behaviors of individuals is known as descriptive research. Descriptive research can be qualitative or quantitative in orientation. Qualitative research is descriptive research that is focused on observing and describing events as they occur, with the goal of capturing all of the richness of everyday behavior and with the hope of discovering and understanding phenomena that might have been missed if only more cursory examinations have been made.Qualitative psychological research methods include interviews, first-hand observation, and participant observation. Creswell  identifies five main possibilities for qualitative research, including narrative, phenomenology, ethnography, case study, and grounded theory. Qualitative researchers[194] sometimes aim to enrich interpretations or critiques of symbols, subjective experiences, or social structures. Sometimes hermeneutic and critical aims can give rise to quantitative research, as in Erich Fromm's study of Nazi voting[citation needed] or Stanley Milgram's studies of obedience to authority.Just as Jane Goodall studied chimpanzee social and family life by careful observation of chimpanzee behavior in the field, psychologists conduct naturalistic observation of ongoing human social, professional, and family life. Sometimes the participants are aware they are being observed, and other times the participants do not know they are being observed. Strict ethical guidelines must be followed when covert observation is being carried out.In 1959, statistician Theodore Sterling examined the results of psychological studies and discovered that 97% of them supported their initial hypotheses, implying a possible publication bias.[196][197][198] Similarly, Fanelli  was around five times higher than in fields such as space- or geosciences. Fanelli argues that this is because researchers in \"softer\" sciences have fewer constraints to their conscious and unconscious biases.Some popular media outlets have in recent years spotlighted a replication crisis in psychology, arguing that many findings in the field cannot be reproduced. Repeats of some famous studies have not reached the same conclusions, and some researchers have been accused of outright fraud in their results. Focus on this issue has led to renewed efforts in the discipline to re-test important findings.[200][201][202][203] As many as two-thirds of highly publicized findings in psychology have failed to be replicated.[204] One subfield of psychology that has largely been unaffected by the replication crisis has been behavioral genetics,[205] with the exception of the candidate gene and candidate gene by environment interaction research on behavior and mental illness.[206]Some critics view statistical hypothesis testing as misplaced. Psychologist and statistician Jacob Cohen wrote in 1994 that psychologists routinely confuse statistical significance with practical importance, enthusiastically reporting great certainty in unimportant facts.[207] Some psychologists have responded with an increased use of effect size statistics, rather than sole reliance on the Fisherian p < .05 significance criterion .[citation needed]The GRIM test has been applied to 260 articles published in Psychological Science, the Journal of Experimental Psychology: General, and the Journal of Personality and Social Psychology. Of these articles, 71 were amenable to GRIM test analysis; 36 of these contained at least one impossible value and 16 contained multiple impossible values.[208]In 2010, a group of researchers reported a systemic bias in psychology studies towards WEIRD  subjects.[209] Although only 1/8 people worldwide fall into the WEIRD classification, the researchers claimed that 60\u201390% of psychology studies are performed on WEIRD subjects. The article gave examples of results that differ significantly between WEIRD subjects and tribal cultures, including the M\u00fcller-Lyer illusion.Some observers perceive a gap between scientific theory and its application\u2014in particular, the application of unsupported or unsound clinical practices.[210] Critics say there has been an increase in the number of mental health training programs that do not instill scientific competence.[211] One skeptic asserts that practices, such as \"facilitated communication for infantile autism\"; memory-recovery techniques including body work; and other therapies, such as rebirthing and reparenting, may be dubious or even dangerous, despite their popularity.[212] In 1984, Allen Neuringer made a similar point[vague] regarding the experimental analysis of behavior.[213] Psychologists, sometimes divided along the lines of laboratory vs. clinic, continue to debate these issues.[214]Ethical standards in the discipline have changed over time. Some famous past studies are today considered unethical and in violation of established codes .The most important contemporary standards are informed and voluntary consent. After World War II, the Nuremberg Code was established because of Nazi abuses of experimental subjects. Later, most countries . All of these measures encouraged researchers to obtain informed consent from human participants in experimental studies. A number of influential studies led to the establishment of this rule; such studies included the MIT and Fernald School radioisotope studies, the Thalidomide tragedy, the Willowbrook hepatitis study, and Stanley Milgram's studies of obedience to authority.University psychology departments have ethics committees dedicated to the rights and well-being of research subjects. Researchers in psychology must gain approval of their research projects before conducting any experiment to protect the interests of human participants and laboratory animals.[215]The ethics code of the American Psychological Association originated in 1951 as \"Ethical Standards of Psychologists\". This code has guided the formation of licensing laws in most American states. It has changed multiple times over the decades since its adoption. In 1989 the APA revised its policies on advertising and referral fees to negotiate the end of an investigation by the Federal Trade Commission. The 1992 incarnation was the first to distinguish between \"aspirational\" ethical standards and \"enforceable\" ones. Members of the public have a five-year window to file ethics complaints about APA members with the APA ethics committee; members of the APA have a three-year window.[216]Some of the ethical issues considered most important are the requirement to practice only within the area of competence, to maintain confidentiality with the patients, and to avoid sexual relations with them. Another important principle is informed consent, the idea that a patient or research subject must understand and freely choose a procedure they are undergoing.[216] Some of the most common complaints against clinical psychologists include sexual misconduct, and involvement in child custody evaluations.[216]Current ethical guidelines state that using non-human animals for scientific purposes is only acceptable when the harm  done to animals is outweighed by the benefits of the research.[217] Keeping this in mind, psychologists can use certain research techniques on animals that could not be used on humans.", "This non-exhaustive list contains many of the sub-fields within the field of psychology:"], "Sociology": ["Sociology is the scientific study of society, including patterns of social relationships, social interaction, and culture.[1][2][3] It is a social science that uses various methods of empirical investigation[4] and critical analysis[5] to develop a body of knowledge about social order, acceptance, and change. Many sociologists aim to conduct research that may be applied directly to social policy and welfare, while others focus primarily on refining the theoretical understanding of social processes. Subject matter ranges from the micro-sociology level of individual agency and interaction to the macro level of systems and the social structure.[6]The traditional focuses of sociology include social stratification, social class, social mobility, religion, secularization, law, sexuality, gender, and deviance. As all spheres of human activity are affected by the interplay between social structure and individual agency, sociology has gradually expanded its focus to other subjects, such as health, medical, economy, military and penal institutions, the Internet, education, social capital, and the role of social activity in the development of scientific knowledge.The range of social scientific methods has also expanded. Social researchers draw upon a variety of qualitative and quantitative techniques. The linguistic and cultural turns of the mid-twentieth century led to increasingly interpretative, hermeneutic, and philosophic approaches towards the analysis of society. Conversely, the end of the 1990s and the beginning of 2000s have seen the rise of new analytically, mathematically, and computationally rigorous techniques, such as agent-based modelling and social network analysis.[7][8]Social research informs politicians and policy makers, educators, planners, legislators, administrators, developers, business magnates, managers, social workers, non-governmental organizations, non-profit organizations, and people interested in resolving social issues in general. There is often a great deal of crossover between social research, market research, and other statistical fields.[9]Sociology is distinguished from various general social studies courses, which bear little relation to sociological theory or to social-science research-methodology. The US National Science Foundation classifies sociology as a STEM field.[10][11]Sociological reasoning predates the foundation of the discipline. Social analysis has origins in the common stock of Western knowledge and philosophy, and has been carried out from as far back as the time of ancient Greek philosopher Plato, if not before. The origin of the survey, i.e., the collection of information from a sample of individuals, can be traced back to at least the Domesday Book in 1086,[12][13] while ancient philosophers such as Confucius wrote on the importance of social roles. There is evidence of early sociology in medieval Arab writings. Some sources consider Ibn Khaldun, a 14th-century Arab Islamic scholar from North Africa ; his Muqaddimah was perhaps the first work to advance social-scientific reasoning on social cohesion and social conflict.[18][19][20][21][22][23]The word sociology . Comte believed a positivist stage would mark the final era, after conjectural theological and metaphysical phases, in the progression of human understanding.[27] In observing the circular dependence of theory and observation in science, and having classified the sciences, Comte may be regarded as the first philosopher of science in the modern sense of the term.[28]Both Auguste Comte and Karl Marx  set out to develop scientifically justified systems in the wake of European industrialization and secularization, informed by various key movements in the philosophies of history and science. Marx rejected Comtean positivism[30] but in attempting to develop a science of society nevertheless came to be recognized as a founder of sociology as the word gained wider meaning. For Isaiah Berlin, Marx may be regarded as the \"true father\" of modern sociology, \"in so far as anyone can claim the title.\"[31]Herbert Spencer  was one of the most popular and influential 19th-century sociologists. It is estimated that he sold one million books in his lifetime, far more than any other sociologist at the time. So strong was his influence that many other 19th century thinkers, including \u00c9mile Durkheim, defined their ideas in relation to his. Durkheim's Division of Labour in Society is to a large extent an extended debate with Spencer from whose sociology, many commentators now agree, Durkheim borrowed extensively.[33] Also a notable biologist, Spencer coined the term \"survival of the fittest\". While Marxian ideas defined one strand of sociology, Spencer was a critic of socialism as well as strong advocate for a laissez-faire style of government. His ideas were highly observed by conservative political circles, especially in the United States and England.[34]The first formal Department of Sociology in the world was established by Albion Small - at the invitation of William Rainey Harper - at the University of Chicago in 1892, and the American Journal of Sociology was founded shortly thereafter in 1895 by Small as well.[35] However, the institutionalization of sociology as an academic discipline was chiefly led by \u00c9mile Durkheim .[37] For Durkheim, sociology could be described as the \"science of institutions, their genesis and their functioning\".[38]Durkheim's monograph, Suicide  causes. He developed the notion of objective sui generis \"social facts\" to delineate a unique empirical object for the science of sociology to study.[36] Through such studies he posited that sociology would be able to determine whether any given society is 'healthy' or 'pathological', and seek social reform to negate organic breakdown or \"social anomie\".Sociology quickly evolved as an academic response to the perceived challenges of modernity, such as industrialization, urbanization, secularization, and the process of \"rationalization\".[39] The field predominated in continental Europe, with British anthropology and statistics generally following on a separate trajectory. By the turn of the 20th century, however, many theorists were active in the English-speaking world. Few early sociologists were confined strictly to the subject, interacting also with economics, jurisprudence, psychology and philosophy, with theories being appropriated in a variety of different fields. Since its inception, sociological epistemology, methods, and frames of inquiry, have significantly expanded and diverged.[6]Durkheim, Marx, and the German theorist Max Weber  are typically cited as the three principal architects of sociology.[40] Herbert Spencer, William Graham Sumner, Lester F. Ward, W. E. B. Du Bois, Vilfredo Pareto, Alexis de Tocqueville, Werner Sombart, Thorstein Veblen, Ferdinand T\u00f6nnies, Georg Simmel and Karl Mannheim are often included on academic curricula as founding theorists. Curricula also may include Charlotte Perkins Gilman, Marianne Weber and Friedrich Engels as founders of the feminist tradition in sociology. Each key figure is associated with a particular theoretical perspective and orientation.[41]The overarching methodological principle of positivism is to conduct sociology in broadly the same manner as natural science. An emphasis on empiricism and the scientific method is sought to provide a tested foundation for sociological research based on the assumption that the only authentic knowledge is scientific knowledge, and that such knowledge can only arrive by positive affirmation through scientific methodology.The term has long since ceased to carry this meaning; there are no fewer than twelve distinct epistemologies that are referred to as positivism.[36][43] Many of these approaches do not self-identify as \"positivist\", some because they themselves arose in opposition to older forms of positivism, and some because the label has over time become a term of abuse[36] by being mistakenly linked with a theoretical empiricism. The extent of antipositivist criticism has also diverged, with many rejecting the scientific method and others only seeking to amend it to reflect 20th century developments in the philosophy of science. However, positivism  remains dominant in contemporary sociology, especially in the United States.[36]Lo\u00efc Wacquant distinguishes three major strains of positivism: Durkheimian, Logical, and Instrumental.[36] None of these are the same as that set forth by Comte, who was unique in advocating such a rigid  version.[44][45] While \u00c9mile Durkheim rejected much of the detail of Comte's philosophy, he retained and refined its method. Durkheim maintained that the social sciences are a logical continuation of the natural ones into the realm of human activity, and insisted that they should retain the same objectivity, rationalism, and approach to causality.[36] He developed the notion of objective sui generis \"social facts\" to delineate a unique empirical object for the science of sociology to study.[36]The variety of positivism that remains dominant today is termed instrumental positivism. This approach eschews epistemological and metaphysical concerns  in favour of methodological clarity, replicability, reliability and validity.[46] This positivism is more or less synonymous with quantitative research, and so only resembles older positivism in practice. Since it carries no explicit philosophical commitment, its practitioners may not belong to any particular school of thought. Modern sociology of this type is often credited to Paul Lazarsfeld,[36] who pioneered large-scale survey studies and developed statistical techniques for analysing them. This approach lends itself to what Robert K. Merton called middle-range theory: abstract statements that generalize from segregated hypotheses and empirical regularities rather than starting with an abstract idea of a social whole.[47]Reactions against social empiricism began when German philosopher Hegel voiced opposition to both empiricism, which he rejected as uncritical, and determinism, which he viewed as overly mechanistic.[48] Karl Marx's methodology borrowed from Hegelian dialecticism but also a rejection of positivism in favour of critical analysis, seeking to supplement the empirical acquisition of \"facts\" with the elimination of illusions.[49] He maintained that appearances need to be critiqued rather than simply documented. Early hermeneuticians such as Wilhelm Dilthey pioneered the distinction between natural and social science . Various neo-Kantian philosophers, phenomenologists and human scientists further theorized how the analysis of the social world differs to that of the natural world due to the irreducibly complex aspects of human society, culture, and being.[50][51]At the turn of the 20th century the first generation of German sociologists formally introduced methodological anti-positivism, proposing that research should concentrate on human cultural norms, values, symbols, and social processes viewed from a resolutely subjective perspective. Max Weber argued that sociology may be loosely described as a science as it is able to identify causal relationships of human \"social action\"\u2014especially among \"ideal types\", or hypothetical simplifications of complex social phenomena.[52] As a non-positivist, however, Weber sought relationships that are not as \"historical, invariant, or generalisable\"[53] as those pursued by natural scientists. Fellow German sociologist, Ferdinand T\u00f6nnies, theorized on two crucial abstract concepts with his work on \"Gemeinschaft and Gesellschaft\" .[54]Both Weber and Georg Simmel pioneered the \"Verstehen\"  method in social science; a systematic process by which an outside observer attempts to relate to a particular cultural group, or indigenous people, on their own terms and from their own point of view.[56] Through the work of Simmel, in particular, sociology acquired a possible character beyond positivist data-collection or grand, deterministic systems of structural law. Relatively isolated from the sociological academy throughout his lifetime, Simmel presented idiosyncratic analyses of modernity more reminiscent of the phenomenological and existential writers than of Comte or Durkheim, paying particular concern to the forms of, and possibilities for, social individuality.[57] His sociology engaged in a neo-Kantian inquiry into the limits of perception, asking 'What is society?' in a direct allusion to Kant's question 'What is nature?'[58]The first college course entitled \"Sociology\" was taught in the United States at Yale in 1875 by William Graham Sumner.[60] In 1883 Lester F. Ward, the first president of the American Sociological Association, published Dynamic Sociology\u2014Or Applied social science as based upon statical sociology and the less complex sciences and attacked the laissez-faire sociology of Herbert Spencer and Sumner.[34] Ward's 1200 page book was used as core material in many early American sociology courses. In 1890, the oldest continuing American course in the modern tradition began at the University of Kansas, lectured by Frank W. Blackmar.[61] The Department of Sociology at the University of Chicago was established in 1892 by Albion Small, who also published the first sociology textbook: An introduction to the study of society 1894.[62] George Herbert Mead and Charles Cooley, who had met at the University of Michigan in 1891  in 1905.[62] The sociological \"canon of classics\" with Durkheim and Max Weber at the top owes in part to Talcott Parsons, who is largely credited with introducing both to American audiences.[65] Parsons consolidated the sociological tradition and set the agenda for American sociology at the point of its fastest disciplinary growth. Sociology in the United States was less historically influenced by Marxism than its European counterpart, and to this day broadly remains more statistical in its approach.[66]The first sociology department to be established in the United Kingdom was at the London School of Economics and Political Science , founded in 1949.[73]The contemporary discipline of sociology is theoretically multi-paradigmatic[74] as a result of the contentions of classical social theory. In Randall Collins' well-cited survey of sociological theory[75] he retroactively labels various theorists as belonging to four theoretical traditions: Functionalism, Conflict, Symbolic Interactionism, and Utilitarianism.[76] Modern sociological theory descends predominately from functionalist  theories of social interaction. Utilitarianism, also known as Rational Choice or Social Exchange, although often associated with economics, is an established tradition within sociological theory.[77][78] Lastly, as argued by Raewyn Connell, a tradition that is often forgotten is that of Social Darwinism, which brings the logic of Darwinian biological evolution and applies it to people and societies.[79] This tradition often aligns with classical functionalism. It was the dominant theoretical stance in American sociology from around 1881 to 1915[80] and is associated with several founders of sociology, primarily Herbert Spencer, Lester F. Ward and William Graham Sumner. Contemporary sociological theory retains traces of each of these traditions and they are by no means mutually exclusive.A broad historical paradigm in both sociology and anthropology, functionalism addresses the social structure, referred to as social organization in among the classical theorists, as a whole and in terms of the necessary function of its constituent elements. A common analogy .\"[83]Functionalist theories emphasize \"cohesive systems\" and are often contrasted with \"conflict theories\", which critique the overarching socio-political system or emphasize the inequality between particular groups. The following quotes from Durkheim and Marx epitomize the political, as well as theoretical, disparities, between functionalist and conflict thought respectively:Symbolic interaction; often associated with Interactionism, Phenomenological sociology, Dramaturgy, Interpretivism, is a sociological tradition that places emphasis on subjective meanings and the empirical unfolding of social processes, generally accessed through micro-analysis.[86] This tradition emerged in the Chicago School of the 1920s and 1930s, which prior to World War II \"had been the center of sociological research and graduate study\".[87] The approach focuses on creating a framework for building a theory that sees society as the product of the everyday interactions of individuals. Society is nothing more than the shared reality that people construct as they interact with one another. This approach sees people interacting in countless settings using symbolic communications to accomplish the tasks at hand. Therefore, society is a complex, ever-changing mosaic of subjective meanings.[88] Some critics of this approach argue that it only looks at what is happening in a particular social situation, and disregards the effects that culture, race or gender  may have in that situation.[89] Some important sociologists associated with this approach include Max Weber, George Herbert Mead, Erving Goffman, George Homans and Peter Blau. It is also in this tradition that the radical-empirical approach of Ethnomethodology emerges from the work of Harold Garfinkel.Utilitarianism is often referred to as exchange theory or rational choice theory in the context of sociology. This tradition tends to privilege the agency of individual rational actors and assumes that within interactions individuals always seek to maximize their own self-interest. As argued by Josh Whitford, rational actors are assumed to have four basic elements, the individual has  \"A decision rule, to select among the possible alternatives\"[90] Exchange theory is specifically attributed to the work of George C. Homans, Peter Blau and Richard Emerson.[91] Organizational sociologists James G. March and Herbert A. Simon noted that an individual's rationality is bounded by the context or organizational setting. The utilitarian perspective in sociology was, most notably, revitalized in the late 20th century by the work of former ASA president James Coleman.Following the decline of theories of sociocultural evolution, in the United States, the interactionism of the Chicago School dominated American sociology. As Anselm Strauss describes, \"We didn't think symbolic interaction was a perspective in sociology; we thought it was sociology.\"[87] After World War II, mainstream sociology shifted to the survey-research of Paul Lazarsfeld at Columbia University and the general theorizing of Pitirim Sorokin, followed by Talcott Parsons at Harvard University. Ultimately, \"the failure of the Chicago, Columbia, and Wisconsin [sociology] departments to produce a significant number of graduate students interested in and committed to general theory in the years 1936\u201345 was to the advantage of the Harvard department.\"[92] As Parsons began to dominate general theory, his work predominately referenced European sociology\u2014almost entirely omitting citations of both the American tradition of sociocultural-evolution as well as pragmatism. In addition to Parsons' revision of the sociological canon , the lack of theoretical challenges from other departments nurtured the rise of the Parsonian structural-functionalist movement, which reached its crescendo in the 1950s, but by the 1960s was in rapid decline.[93]By the 1980s, most functionalisms in Europe had broadly been replaced by conflict-oriented approaches[94] and to many in the discipline, functionalism was considered \"as dead as a dodo.\"[95] \"According to Giddens, the orthodox consensus terminated in the late 1960s and 1970s as the middle ground shared by otherwise competing perspectives gave way and was replaced by a baffling variety of competing perspectives. This third 'generation' of social theory includes phenomenologically inspired approaches, critical theory, ethnomethodology, symbolic interactionism, structuralism, post-structuralism, and theories written in the tradition of hermeneutics and ordinary language philosophy.\"[96]While some conflict approaches also gained popularity in the United States, the mainstream of the discipline instead shifted to a variety of empirically oriented middle-range theories with no single overarching, or \"grand\", theoretical orientation. John Levi Martin refers to this \"golden age of methodological unity and theoretical calm\" as the Pax Wisconsana,[97] as it reflected the composition of the sociology department at the University of Wisconsin\u2013Madison: numerous scholars working on separate projects with little contention.[98] Omar Lizardo describes the Pax Wisconsana as: \"a Midwestern flavored, Mertonian resolution of the theory/method wars in which [sociologists] all agreed on at least two working hypotheses:  [and] good theory has to be good to think with or goes in the trash bin.\"[99] Despite the aversion to grand theory in the later half of the 20th century, several new traditions have emerged that propose various syntheses: structuralism, post-structuralism, cultural sociology and systems theory.The structuralist movement originated primarily from the work of Durkheim as interpreted by two European anthropologists. Anthony Giddens' theory of structuration draws on the linguistic theory of Ferdinand de Saussure and the French anthropologist Claude L\u00e9vi-Strauss. In this context, 'structure' refers not to 'social structure' but to the semiotic understanding of human culture as a system of signs. One may delineate four central tenets of structuralism: First, structure is what determines the structure of a whole. Second, structuralists believe that every system has a structure. Third, structuralists are interested in 'structural' laws that deal with coexistence rather than changes. Finally, structures are the 'real things' beneath the surface or the appearance of meaning.[100]The second tradition of structuralist thought, contemporaneous with Giddens, emerges from the American school of social network analysis,[101] spearheaded by the Harvard Department of Social Relations led by Harrison White and his students in the 1970s and 1980s. This tradition of structuralist thought argues that, rather than semiotics, social structure is networks of patterned social relations. And, rather than Levi-Strauss, this school of thought draws on the notions of structure as theorized by Levi-Strauss' contemporary anthropologist, Radcliffe-Brown.[102] Some[103] refer to this as \"network structuralism,\" and equate it to \"British structuralism\" as opposed to the \"French structuralism\" of Levi-Strauss.Post-structuralist thought has tended to reject 'humanist' assumptions in the conduct of social theory.[104] Michel Foucault provides a potent critique in his Archaeology of the Human Sciences, though Habermas and Rorty have both argued that Foucault merely replaces one such system of thought with another.[105][106] The dialogue between these intellectuals highlights a trend in recent years for certain schools of sociology and philosophy to intersect. The anti-humanist position has been associated with \"postmodernism\", a term used in specific contexts to describe an era or phenomena, but occasionally construed as a method.Overall, there is a strong consensus regarding the central problems of sociological theory, which are largely inherited from the classical theoretical traditions. This consensus is: how to link, transcend or cope with the following \"big three\" dichotomies:[107] subjectivity and objectivity, structure and agency, and synchrony and diachrony. The first deals with knowledge, the second with action, and the last with time. Lastly, sociological theory often grapples with the problem of integrating or transcending the divide between micro, meso and macro-scale social phenomena, which is a subset of all three central problems.The problem of subjectivity and objectivity can be divided into a concern over the general possibilities of social actions, and, on the other hand the specific problem of social scientific knowledge. In the former, the subjective is often equated  with the individual, and the individual's intentions and interpretations of the objective. The objective is often considered any public or external action or outcome, on up to society writ large. A primary question for social theorists is how knowledge reproduces along the chain of subjective-objective-subjective, that is to say: how is intersubjectivity achieved? While, historically, qualitative methods have attempted to tease out subjective interpretations, quantitative survey methods also attempt to capture individual subjectivities. Also, some qualitative methods take a radical approach to objective description in situ.The latter concern with scientific knowledge results from the fact that a sociologist is part of the very object they seek to explain. Bourdieu puts this problem rather succinctly:[peacock\u00a0term]Structure and agency, sometimes referred to as determinism versus voluntarism,[108] form an enduring ontological debate in social theory: \"Do social structures determine an individual's behaviour or does human agency?\" In this context 'agency' refers to the capacity of individuals to act independently and make free choices, whereas 'structure' relates to factors that limit or affect the choices and actions of individuals  reproduced through the choices of individuals?Synchrony and diachrony, or statics and dynamics, within social theory are terms that refer to a distinction emerging out of the work of Levi-Strauss who inherited it from the linguistics of Ferdinand de Saussure.[102] The former slices moments of time for analysis, thus it is an analysis of static social reality. Diachrony, on the other hand, attempts to analyse dynamic sequences. Following Saussure, synchrony would refer to social phenomena as a static concept like a language, while diachrony would refer to unfolding processes like actual speech. In Anthony Giddens' introduction to Central Problems in Social Theory, he states that, \"in order to show the interdependence of action and structure ... we must grasp the time space relations inherent in the constitution of all social interaction.\" And like structure and agency, time is integral to discussion of social reproduction. In terms of sociology, historical sociology is often better positioned to analyse social life as diachronic, while survey research takes a snapshot of social life and is thus better equipped to understand social life as synchronized. Some argue that the synchrony of social structure is a methodological perspective rather than an ontological claim.[102] Nonetheless, the problem for theory is how to integrate the two manners of recording and thinking about social data.Many people divide sociological research methods into two broad categories, although many others see research methods as a continuum:[110]Many sociologists are divided into camps of support for particular research techniques. These disputes relate to the epistemological debates at the historical core of social theory. While very different in many aspects, both qualitative and quantitative approaches involve a systematic interaction between theory and data.[111] Quantitative methodologies hold the dominant position in sociology, especially in the United States.[36] In the discipline's two most cited journals, quantitative articles have historically outnumbered qualitative ones by a factor of two.[112]  Most textbooks on the methodology of social research are written from the quantitative perspective,[113] and the very term \"methodology\" is often used synonymously with \"statistics.\" Practically all sociology PhD programmes in the United States require training in statistical methods. The work produced by quantitative researchers is also deemed more 'trustworthy' and 'unbiased' by the greater public,[114] though this judgment continues to be challenged by antipositivists.[114]The choice of method often depends largely on what the researcher intends to investigate. For example, a researcher concerned with drawing a statistical generalization across an entire population may administer a survey questionnaire to a representative sample population. By contrast, a researcher who seeks full contextual understanding of an individual's social actions may choose ethnographic participant observation or open-ended interviews. Studies will commonly combine, or 'triangulate', quantitative and qualitative methods as part of a 'multi-strategy' design. For instance, a quantitative study may be performed to gain statistical patterns or a target sample, and then combined with a qualitative interview to determine the play of agency.[111]Quantitative methods are often used to ask questions about a population that is very large, making a census or a complete enumeration of all the members in that population infeasible. A 'sample' then forms a manageable subset of a population. In quantitative research, statistics are used to draw inferences from this sample regarding the population as a whole. The process of selecting a sample is referred to as 'sampling'. While it is usually best to sample randomly, concern with differences between specific subpopulations sometimes calls for stratified sampling. Conversely, the impossibility of random sampling sometimes necessitates nonprobability sampling, such as convenience sampling or snowball sampling.[111]The following list of research methods is neither exclusive nor exhaustive:Sociologists increasingly draw upon computationally intensive methods to analyse and model social phenomena.[119] Using computer simulations, artificial intelligence, text mining, complex statistical methods, and new analytic approaches like social network analysis and social sequence analysis, computational sociology develops and tests theories of complex social processes through bottom-up modelling of social interactions.[120]Although the subject matter and methodologies in social science differ from those in natural science or computer science, several of the approaches used in contemporary social simulation originated from fields such as physics and artificial intelligence.[121][122] By the same token, some of the approaches that originated in computational sociology have been imported into the natural sciences, such as measures of network centrality from the fields of social network analysis and network science. In relevant literature, computational sociology is often related to the study of social complexity.[123] Social complexity concepts such as complex systems, non-linear interconnection among macro and micro process, and emergence, have entered the vocabulary of computational sociology.[124] A practical and well-known example is the construction of a computational model in the form of an \"artificial society\", by which researchers can analyse the structure of a social system.[125][126]Sociologists' approach to culture can be divided into a \"sociology of culture\" and \"cultural sociology\"\u2014the terms are similar, though not entirely interchangeable.[127] The sociology of culture is an older term, and considers some topics and objects as more-or-less \"cultural\" than others. Conversely, cultural sociology sees all social phenomena as inherently cultural.[128] Sociology of culture often attempts to explain certain cultural phenomena as a product of social processes, while cultural sociology sees culture as a potential explanation of social phenomena.[129]For Simmel, culture referred to \"the cultivation of individuals through the agency of external forms which have been objectified in the course of history\".[57] While early theorists such as Durkheim and Mauss were influential in cultural anthropology, sociologists of culture are generally distinguished by their concern for modern  would consider the social practices of the group as they relate to the dominant class. The \"cultural turn\" of the 1960s ultimately placed culture much higher on the sociological agenda.Sociology of literature, film, and art is a subset of the sociology of culture. This field studies the social production of artistic objects and its social implications. A notable example is Pierre Bourdieu's 1992 Les R\u00e8gles de L'Art: Gen\u00e8se et Structure du Champ Litt\u00e9raire, translated by Susan Emanuel as Rules of Art: Genesis and Structure of the Literary Field . None of the founding fathers of sociology produced a detailed study of art, but they did develop ideas that were subsequently applied to literature by others. Marx's theory of ideology was directed at literature by Pierre Macherey, Terry Eagleton and Fredric Jameson. Weber's theory of modernity as cultural rationalization, which he applied to music, was later applied to all the arts, literature included, by Frankfurt School writers such as Adorno and J\u00fcrgen Habermas. Durkheim's view of sociology as the study of externally defined social facts was redirected towards literature by Robert Escarpit. Bourdieu's own work is clearly indebted to Marx, Weber and Durkheim.Criminologists analyse the nature, causes, and control of criminal activity, drawing upon methods across sociology, psychology, and the behavioural sciences. The sociology of deviance focuses on actions or behaviours that violate norms, including both formally enacted rules  and informal violations of cultural norms. It is the remit of sociologists to study why these norms exist; how they change over time; and how they are enforced. The concept of social disorganization is when the broader social systems leads to violations of norms. For instance, Robert K. Merton produced a typology of deviance, which includes both individual and system level causal explanations of deviance.[130]The study of law played a significant role in the formation of classical sociology. Durkheim famously described law as the \"visible symbol\" of social solidarity.[131] The sociology of law refers to both a sub-discipline of sociology and an approach within the field of legal studies. Sociology of law is a diverse field of study that examines the interaction of law with other aspects of society, such as the development of legal institutions and the effect of laws on social change and vice versa. For example, an influential recent work in the field relies on statistical analyses to argue that the increase in incarceration in the US over the last 30 years is due to changes in law and policing and not to an increase in crime; and that this increase significantly contributes to maintaining racial stratification.[132]The sociology of communications and information technologies includes \"the social aspects of computing, the Internet, new media, computer networks, and other communication and information technologies\".[133]The Internet is of interest to sociologists in various ways; most practically as a tool for research and as a discussion platform.[134] The sociology of the Internet in the broad sense regards the analysis of online communities  and virtual worlds, thus there is often overlap with community sociology. Online communities may be studied statistically through network analysis or interpreted qualitatively through virtual ethnography. Moreover, organizational change is catalysed through new media, thereby influencing social change at-large, perhaps forming the framework for a transformation from an industrial to an informational society. One notable text is Manuel Castells' The Internet Galaxy\u2014the title of which forms an inter-textual reference to Marshall McLuhan's The Gutenberg Galaxy.[135] Closely related to the sociology of the Internet, is digital sociology, which expands the scope of study to address not only the internet but also the impact of the other digital media and devices that have emerged since the first decade of the twenty-first century.As with cultural studies, media study is a distinct discipline that owes to the convergence of sociology and other social sciences and humanities, in particular, literary criticism and critical theory. Though the production process or the critique of aesthetic forms is not in the remit of sociologists, analyses of socializing factors, such as ideological effects and audience reception, stem from sociological theory and method. Thus the 'sociology of the media' is not a subdiscipline per se, but the media is a common and often-indispensable topic.The term \"economic sociology\" was first used by William Stanley Jevons in 1879, later to be coined in the works of Durkheim, Weber and Simmel between 1890 and 1920.[136] Economic sociology arose as a new approach to the analysis of economic phenomena, emphasizing class relations and modernity as a philosophical concept. The relationship between capitalism and modernity is a salient issue, perhaps best demonstrated in Weber's The Protestant Ethic and the Spirit of Capitalism . Social network analysis has been the primary methodology for studying this phenomenon. Granovetter's theory of the strength of weak ties and Ronald Burt's concept of structural holes are two best known theoretical contributions of this field.The sociology of work, or industrial sociology, examines \"the direction and implications of trends in technological change, globalization, labour markets, work organization, managerial practices and employment relations to the extent to which these trends are intimately related to changing patterns of inequality in modern societies and to the changing experiences of individuals and families the ways in which workers challenge, resist and make their own contributions to the patterning of work and shaping of work institutions.\"[137]The sociology of education is the study of how educational institutions determine social structures, experiences, and other outcomes. It is particularly concerned with the schooling systems of modern industrial societies.[138] A classic 1966 study in this field by James Coleman, known as the \"Coleman Report\", analysed the performance of over 150,000 students and found that student background and socioeconomic status are much more important in determining educational outcomes than are measured differences in school resources .[139] The controversy over \"school effects\" ignited by that study has continued to this day. The study also found that socially disadvantaged black students profited from schooling in racially mixed classrooms, and thus served as a catalyst for desegregation busing in American public schools.Environmental sociology is the study of human interactions with the natural environment, typically emphasizing human dimensions of environmental problems, social impacts of those problems, and efforts to resolve them. As with other sub-fields of sociology, scholarship in environmental sociology may be at one or multiple levels of analysis, from global  to local, societal to individual. Attention is paid also to the processes by which environmental problems become defined and known to humans. As argued by notable environmental sociologist John Bellamy Foster, the predecessor to modern environmental sociology is Marx's analysis of the metabolic rift, which influenced contemporary thought on sustainability. Environmental sociology is often interdisciplinary and overlaps with the sociology of risk, rural sociology and the sociology of disaster.Human ecology deals with interdisciplinary study of the relationship between humans and their natural, social, and built environments. In addition to Environmental sociology, this field overlaps with architectural sociology, urban sociology, and to some extent visual sociology. In turn, visual sociology\u2014which is concerned with all visual dimensions of social life\u2014overlaps with media studies in that it uses photography, film and other technologies of media.Social pre-wiring deals with the study of fetal social behavior and social interactions in a multi-fetal environment. Specifically, social pre-wiring refers to the ontogeny of social interaction. Also informally referred to as, \"wired to be social.\" The theory questions whether there is a propensity to socially oriented action already present before birth. Research in the theory concludes that newborns are born into the world with a unique genetic wiring to be social. [140]Circumstantial evidence supporting the social pre-wiring hypothesis can be revealed when examining newborns' behavior. Newborns, not even hours after birth, have been found to display a preparedness for social interaction. This preparedness is expressed in ways such as their imitation of facial gestures. This observed behavior cannot be contributed to any current form of socialization or social construction. Rather, newborns most likely inherit to some extent social behavior and identity through genetics.[140]Principal evidence of this theory is uncovered by examining Twin pregnancies. The main argument is, if there are social behaviors that are inherited and developed before birth, then one should expect twin foetuses to engage in some form of social interaction before they are born. Thus, ten foetuses were analyzed over a period of time using ultrasound techniques. Using kinematic analysis, the results of the experiment were that the twin foetuses would interact with each other for longer periods and more often as the pregnancies went on. Researchers were able to conclude that the performance of movements between the co-twins were not accidental but specifically aimed.[140]The social pre-wiring hypothesis was proved correct, \"The central advance of this study is the demonstration that 'social actions' are already performed in the second trimester of gestation. Starting from the 14th week of gestation twin foetuses plan and execute movements specifically aimed at the co-twin. These findings force us to predate the emergence of social behavior: when the context enables it, as in the case of twin foetuses, other-directed actions are not only possible but predominant over self-directed actions.\".[140]Family, gender and sexuality form a broad area of inquiry studied in many sub-fields of sociology. A family is a group of people who are related by kinship ties\u00a0:- Relations of blood / marriage / civil partnership or adoption. The family unit is one of the most important social institutions found in some form in nearly all known societies. It is the basic unit of social organization and plays a key role in socializing children into the culture of their society. The sociology of the family examines the family, as an institution and unit of socialization, with special concern for the comparatively modern historical emergence of the nuclear family and its distinct gender roles. The notion of \"childhood\" is also significant. As one of the more basic institutions to which one may apply sociological perspectives, the sociology of the family is a common component on introductory academic curricula. Feminist sociology, on the other hand, is a normative sub-field that observes and critiques the cultural categories of gender and sexuality, particularly with respect to power and inequality. The primary concern of feminist theory is the patriarchy and the systematic oppression of women apparent in many societies, both at the level of small-scale interaction and in terms of the broader social structure. Feminist sociology also analyses how gender interlocks with race and class to produce and perpetuate social inequalities.[141] \"How to account for the differences in definitions of femininity and masculinity and in sex role across different societies and historical periods\" is also a concern.[142] Social psychology of gender, on the other hand, uses experimental methods to uncover the microprocesses of gender stratification. For example, one recent study has shown that resume evaluators penalize women for motherhood while giving a boost to men for fatherhood.[143]The sociology of health and illness focuses on the social effects of, and public attitudes toward, illnesses, diseases, mental health and disabilities. This sub-field also overlaps with gerontology and the study of the ageing process. Medical sociology, by contrast, focuses on the inner-workings of medical organizations and clinical institutions. In Britain, sociology was introduced into the medical curriculum following the Goodenough Report .[144]The sociology of the body and embodiment[145] takes a broad perspective on the idea of \"the body\" and includes \"a wide range of embodied dynamics including human and non-human bodies, morphology, human reproduction, anatomy, body fluids, biotechnology, genetics. This often intersects with health and illness, but also theories of bodies as political, social, cultural, economic and ideological productions.[146] The ISA maintains a Research Committee devoted to \"The Body in the Social Sciences\".[147]A subfield of the sociology of health and illness that overlaps with cultural sociology is the study of death, dying and bereavement,[148] sometimes referred to broadly as the sociology of death. This topic is exemplifed by the work of Douglas Davies and Michael C. Kearl.The sociology of knowledge is the study of the relationship between human thought and the social context within which it arises, and of the effects prevailing ideas have on societies. The term first came into widespread use in the 1920s, when a number of German-speaking theorists, most notably Max Scheler, and Karl Mannheim, wrote extensively on it. With the dominance of functionalism through the middle years of the 20th century, the sociology of knowledge tended to remain on the periphery of mainstream sociological thought. It was largely reinvented and applied much more closely to everyday life in the 1960s, particularly by Peter L. Berger and Thomas Luckmann in The Social Construction of Reality . The \"archaeological\" and \"genealogical\" studies of Michel Foucault are of considerable contemporary influence.The sociology of science involves the study of science as a social activity, especially dealing \"with the social conditions and effects of science, and with the social structures and processes of scientific activity.\"[149] Important theorists in the sociology of science include Robert K. Merton and Bruno Latour. These branches of sociology have contributed to the formation of science and technology studies. Both the ASA and the BSA have sections devoted to the subfield of Science, Knowledge and Technology.[150][151] The ISA maintains a Research Committee on Science and Technology[152]Sociology of leisure is the study of how humans organize their free time. Leisure includes a broad array of activities, such as sport, tourism, and the playing of games. The sociology of leisure is closely tied to the sociology of work, as each explores a different side of the work\u2013leisure relationship. More recent studies in the field move away from the work\u2013leisure relationship and focus on the relation between leisure and culture. This area of sociology began with Thorstein Veblen's Theory of the Leisure Class.[153]This subfield of sociology studies, broadly, the dynamics of war, conflict resolution, peace movements, war refugees, conflict resolution and military institutions.[154] As a subset of this subfield, military sociology aims towards the systematic study of the military as a social group rather than as an organization. It is a highly specialized sub-field which examines issues related to service personnel as a distinct group with coerced collective action based on shared interests linked to survival in vocation and combat, with purposes and values that are more defined and narrow than within civil society. Military sociology also concerns civilian-military relations and interactions between other groups or governmental agencies. Topics include the dominant assumptions held by those in the military, changes in military members' willingness to fight, military unionization, military professionalism, the increased utilization of women, the military industrial-academic complex, the military's dependence on research, and the institutional and organizational structure of military.[155]Historically, political sociology concerned the relations between political organization and society. A typical research question in this area might be: \"Why do so few American citizens choose to vote?\"[156] In this respect questions of political opinion formation brought about some of the pioneering uses of statistical survey research by Paul Lazarsfeld. A major subfield of political sociology developed in relation to such questions, which draws on comparative history to analyse socio-political trends. The field developed from the work of Max Weber and Moisey Ostrogorsky.[157]Contemporary political sociology includes these areas of research, but it has been opened up to wider questions of power and politics.[158] Today political sociologists are as likely to be concerned with how identities are formed that contribute to structural domination by one group over another; the politics of who knows how and with what authority; and questions of how power is contested in social interactions in such a way as to bring about widespread cultural and social change. Such questions are more likely to be studied qualitatively. The study of social movements and their effects has been especially important in relation to these wider definitions of politics and power.[159]Political sociology has also moved beyond methodological nationalism and analysed the role of non-governmental organizations, the diffusion of the nation-state throughout the Earth as a social construct, and the role of stateless entities in the modern world society. Contemporary political sociologists also study inter-state interactions and human rights.Demographers or sociologists of population study the size, composition and change over time of a given population. Demographers study how these characteristics impact, or are impacted by, various social, economic or political systems. The study of population is also closely related to human ecology and environmental sociology, which studies a populations relationship with the surrounding environment and often overlaps with urban or rural sociology. Researchers in this field may study the movement of populations: transportation, migrations, diaspora, etc., which falls into the subfield known as Mobilities studies and is closely related to human geography. Demographers may also study spread of disease within a given population or epidemiology.Public sociology refers to an approach to the discipline which seeks to transcend the academy in order to engage with wider audiences. It is perhaps best understood as a style of sociology rather than a particular method, theory, or set of political values. This approach is primarily associated with Michael Burawoy who contrasted it with professional sociology, a form of academic sociology that is concerned primarily with addressing other professional sociologists. Public sociology is also part of the broader field of science communication or science journalism. In a distinct but similar vein,[160] applied sociology, also known as clinical sociology, policy sociology or sociological practice, applies knowledge derived from sociological research to solve societal problems.The sociology of race and of ethnic relations is the area of the discipline that studies the social, political, and economic relations between races and ethnicities at all levels of society. This area encompasses the study of racism, residential segregation, and other complex social processes between different racial and ethnic groups. This research frequently interacts with other areas of sociology such as stratification and social psychology, as well as with postcolonial theory. At the level of political policy, ethnic relations are discussed in terms of either assimilationism or multiculturalism.[161] Anti-racism forms another style of policy, particularly popular in the 1960s and 70s.The sociology of religion concerns the practices, historical backgrounds, developments, universal themes and roles of religion in society.[162] There is particular emphasis on the recurring role of religion in all societies and throughout recorded history. The sociology of religion is distinguished from the philosophy of religion in that sociologists do not set out to assess the validity of religious truth-claims, instead assuming what Peter L. Berger has described as a position of \"methodological atheism\".[163] It may be said that the modern formal discipline of sociology began with the analysis of religion in Durkheim's 1897 study of suicide rates among Roman Catholic and Protestant populations. Max Weber published four major texts on religion in a context of economic sociology and social stratification: The Protestant Ethic and the Spirit of Capitalism . Contemporary debates often centre on topics such as secularization, civil religion, the intersection of religion and economics and the role of religion in a context of globalization and multiculturalism.The sociology of change and development attempts to understand how societies develop and how they can be changed. This includes studying many different aspects of society, for example demographic trends,[164] political or technological trends,[165] or changes in culture. Within this field, sociologists often use macrosociological methods or historical-comparative methods. In contemporary studies of social change, there are overlaps with international development or community development. However, most of the founders of sociology had theories of social change based on their study of history. For instance, Marx contended that the material circumstances of society ultimately caused the ideal or cultural aspects of society, while Weber argued that it was in fact the cultural mores of Protestantism that ushered in a transformation of material circumstances. In contrast to both, Durkheim argued that societies moved from simple to complex through a process of sociocultural evolution. Sociologists in this field also study processes of globalization and imperialism. Most notably, Immanuel Wallerstein extends Marx's theoretical frame to include large spans of time and the entire globe in what is known as world systems theory. Development sociology is also heavily influenced by post-colonialism. In recent years, Raewyn Connell issued a critique of the bias in sociological research towards countries in the Global North. She argues that this bias blinds sociologists to the lived experiences of the Global South, specifically, so-called, \"Northern Theory\" lacks an adequate theory of imperialism and colonialism.There are many organizations studying social change, including the Fernand Braudel Center for the Study of Economies, Historical Systems, and Civilizations, and the Global Social Change Research Project.A social network is a social structure composed of individuals  as discrete units of analysis, it focuses instead on how the structure of ties affects and constitutes individuals and their relationships. In contrast to analyses that assume that socialization into norms determines behaviour, network analysis looks to see the extent to which the structure and composition of ties affect norms. On the other hand, recent research by Omar Lizardo also demonstrates that network ties are shaped and created by previously existing cultural tastes.[166] Social network theory is usually defined in formal mathematics and may include integration of geographical data into Sociomapping.Sociological social psychology focuses on micro-scale social actions. This area may be described as adhering to \"sociological miniaturism\", examining whole societies through the study of individual thoughts and emotions as well as behaviour of small groups.[167] Of special concern to psychological sociologists is how to explain a variety of demographic, social, and cultural facts in terms of human social interaction. Some of the major topics in this field are social inequality, group dynamics, prejudice, aggression, social perception, group behaviour, social change, non-verbal behaviour, socialization, conformity, leadership, and social identity. Social psychology may be taught with psychological emphasis.[168] In sociology, researchers in this field are the most prominent users of the experimental method . Social psychology looks at social influences, as well as social perception and social interaction.[168]Social stratification is the hierarchical arrangement of individuals into social classes, castes, and divisions within a society.[169] Modern Western societies stratification traditionally relates to cultural and economic classes arranged in three main layers: upper class, middle class, and lower class, but each class may be further subdivided into smaller classes .[170] Social stratification is interpreted in radically different ways within sociology. Proponents of structural functionalism suggest that, since the stratification of classes and castes is evident in all societies, hierarchy must be beneficial in stabilizing their existence. Conflict theorists, by contrast, critique the inaccessibility of resources and lack of social mobility in stratified societies.Karl Marx distinguished social classes by their connection to the means of production in the capitalist system: the bourgeoisie own the means, but this effectively includes the proletariat itself as the workers can only sell their own labour power : A person's ability to get their way despite the resistance of others. For example, individuals in state jobs, such as an employee of the Federal Bureau of Investigation, or a member of the United States Congress, may hold little property or status but they still hold immense power[172] Pierre Bourdieu provides a modern example in the concepts of cultural and symbolic capital. Theorists such as Ralf Dahrendorf have noted the tendency towards an enlarged middle-class in modern Western societies, particularly in relation to the necessity of an educated work force in technological or service-based economies.[173] Perspectives concerning globalization, such as dependency theory, suggest this effect owes to the shift of workers to the developing countries.[174]Urban sociology involves the analysis of social life and human interaction in metropolitan areas. It is a discipline seeking to provide advice for planning and policy making. After the industrial revolution, works such as Georg Simmel's The Metropolis and Mental Life  focused on urbanization and the effect it had on alienation and anonymity. In the 1920s and 1930s The Chicago School produced a major body of theory on the nature of the city, important to both urban sociology and criminology, utilizing symbolic interactionism as a method of field research. Contemporary research is commonly placed in a context of globalization, for instance, in Saskia Sassen's study of the \"Global city\".[175] Rural sociology, by contrast, is the analysis of non-metropolitan areas. As agriculture and wilderness tend to be a more prominent social fact in rural regions, rural sociologists often overlap with environmental sociologists.Often grouped with urban and rural sociology is that of community sociology or the sociology of community.[176] Taking various communities\u2014including online communities\u2014as the unit of analysis, community sociologists study the origin and effects of different associations of people. For instance, German sociologist Ferdinand T\u00f6nnies distinguished between two types of human association: Gemeinschaft . In his 1887 work, Gemeinschaft und Gesellschaft, T\u00f6nnies argued that Gemeinschaft is perceived to be a tighter and more cohesive social entity, due to the presence of a \"unity of will\".[177] The 'development' or 'health' of a community is also a central concern of community sociologists also engage in development sociology, exemplified by the literature surrounding the concept of social capital.Sociology overlaps with a variety of disciplines that study society, in particular anthropology, political science, economics, social work and social philosophy. Many comparatively new fields such as communication studies, cultural studies, demography and literary theory, draw upon methods that originated in sociology. The terms \"social science\" and \"social research\" have both gained a degree of autonomy since their origination in classical sociology. The distinct field of Social anthropology or anthroposociology is the dominant constituent of anthropology throughout the United Kingdom and Commonwealth and much of Europe .[citation needed]Sociology and applied sociology are connected to the professional and academic discipline of social work.[180] Both disciplines study social interactions, community and the effect of various systems  on the individual.[181] However, social work is generally more focused on practical strategies to alleviate social dysfunctions; sociology in general provides a thorough examination of the root causes of these problems.[182] For example, a sociologist might study why a community is plagued with poverty. The applied sociologist would be more focused on practical strategies on what needs to be done to alleviate this burden. The social worker would be focused on action; implementing theses strategies \"directly\" or \"indirectly\" by means of mental health therapy, counselling, advocacy, community organization or community mobilization.[181]Social anthropology is the branch of anthropology that studies how contemporary living human beings behave in social groups. Practitioners of social anthropology, like sociologists, investigate various facets of social organization. Traditionally, social anthropologists analysed non-industrial and non-Western societies, whereas sociologists focused on industrialized societies in the Western world. In recent years, however, social anthropology has expanded its focus to modern Western societies, meaning that the two disciplines increasingly converge.[183][184]Sociocultural anthropology, which we understand to include linguistic anthropology, is concerned with the problem of difference and similarity within and between human populations. The discipline arose concomitantly with the expansion of European colonial empires, and its practices and theories have been questioned and reformulated along with processes of decolonization. Such issues have re-emerged as transnational processes have challenged the centrality of the nation-state to theorizations about culture and power. New challenges have emerged as public debates about multiculturalism, and the increasing use of the culture concept outside of the academy and among peoples studied by anthropology. These are not \"business-as-usual\" times in the academy, in anthropology, or in the world, if ever there were such times.Irving Louis Horowitz, in his The Decomposition of Sociology , has argued that the discipline, while arriving from a \"distinguished lineage and tradition\", is in decline due to deeply ideological theory and a lack of relevance to policy making: \"The decomposition of sociology began when this great tradition became subject to ideological thinking, and an inferior tradition surfaced in the wake of totalitarian triumphs.\"[185] Furthermore: \"A problem yet unmentioned is that sociology's malaise has left all the social sciences vulnerable to pure positivism\u2014to an empiricism lacking any theoretical basis. Talented individuals who might, in an earlier time, have gone into sociology are seeking intellectual stimulation in business, law, the natural sciences, and even creative writing; this drains sociology of much needed potential.\"[185] Horowitz cites the lack of a 'core discipline' as exacerbating the problem. Randall Collins, the Dorothy Swaine Thomas Professor in Sociology at the University of Pennsylvania and a member of the Advisory Editors Council of the Social Evolution & History journal, has voiced similar sentiments: \"we have lost all coherence as a discipline, we are breaking up into a conglomerate of specialities, each going on its own way and with none too high regard for each other.\"[186]In 2007, The Times Higher Education Guide published a list of 'The most cited authors of books in the Humanities' .[187]The most highly ranked general journals which publish original research in the field of sociology are the American Journal of Sociology and the American Sociological Review.[188] The Annual Review of Sociology, which publishes original review essays, is also highly ranked.[188] Many other generalist and specialized journals exist."], "Biology": ["The life sciences comprise the branches of science that involve the scientific study of organisms \u2013 such as microorganisms, plants, and animals including human beings \u2013 as well as related considerations like bioethics. While biology remains the centerpiece of the life sciences, technological advances in molecular biology and biotechnology have led to a burgeoning of specializations and interdisciplinary fields.[1][2]Some life sciences focus on a specific type of life. For example, zoology is the study of animals, while botany is the study of plants. Other life sciences focus on aspects common to all or many life forms, such as anatomy and genetics. Yet other fields are interested in technological advances involving living things, such as bio-engineering. Another major, though more specific, branch of life sciences involves understanding the mind\u00a0\u2013 neuroscience.The life sciences are helpful in improving the quality and standard of life. They have applications in health, agriculture, medicine, and the pharmaceutical and food science industries.There is considerable overlap between many of the topics of study in the life sciences.Biology \u2013 burst and eclectic field, composed of many branches and subdisciplines. However, despite the broad scope of biology, there are certain general and unifying concepts within it that govern all study and research, consolidating it into a single, coherent field. In general, biology recognizes the cell as the basic unit of life, genes as the basic unit of heredity, and evolution as the engine that propels the synthesis and creation of new species. It is also understood today that all organisms survive by consuming and transforming energy and by regulating their internal environment to maintain a stable and vital condition. Here are some of biology's major branches:Medicine \u2013 applied science or practice of the diagnosis, treatment, and prevention of disease. It encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. Some of its branches are:"], "Chemistry": ["Chemistry is the scientific discipline involved with compounds composed of atoms, i.e. elements, and molecules, i.e. combinations of atoms: their composition, structure, properties, behavior and the changes they undergo during a reaction with other compounds.[1][2] Chemistry addresses topics such as how atoms and molecules interact via chemical bonds to form new chemical compounds. There are four types of chemical bonds: covalent bonds, in which compounds share one or more electron; hydrogen bonds; and Van der Waals force bonds.In the scope of its subject, chemistry occupies an intermediate position between physics and biology.[3] It is sometimes called the central science because it provides a foundation for understanding both basic and applied scientific disciplines at a fundamental level.[4] Examples include plant chemistry .The history of chemistry spans a period from very old times to the present. Since several millennia BC, civilizations were using technologies that would eventually form the basis of the various branches of chemistry. Examples include extracting metals from ores, making pottery and glazes, fermenting beer and wine, extracting chemicals from plants for medicine and perfume, rendering fat into soap, making glass, and making alloys like bronze. Chemistry was preceded by its protoscience, alchemy, which is an intuitive but non-scientific approach to understanding the constituents of matter and their interactions. It was unsuccessful in explaining the nature of matter and its transformations, but, by performing experiments and recording the results, alchemists set the stage for modern chemistry. Chemistry as a body of knowledge distinct from alchemy began to emerge when a clear differentiation was made between them by Robert Boyle in his work The Sceptical Chymist . While both alchemy and chemistry are concerned with matter and its transformations, the crucial difference was given by the scientific method that chemists employed in their work. Chemistry is considered to have become an established science with the work of Antoine Lavoisier, who developed a law of conservation of mass that demanded careful measurement and quantitative observations of chemical phenomena. The history of chemistry is intertwined with the history of thermodynamics, especially through the work of Willard Gibbs.[5]The word chemistry comes from alchemy, which referred to an earlier set of practices that encompassed elements of chemistry, metallurgy, philosophy, astrology, astronomy, mysticism and medicine. It is often seen as linked to the quest to turn lead or another common starting material into gold,[6] though in ancient times the study encompassed many of the questions of modern chemistry being defined as the study of the composition of waters, movement, growth, embodying, disembodying, drawing the spirits from bodies and bonding the spirits within bodies by the early 4th century Greek-Egyptian alchemist Zosimos.[7] An alchemist was called a 'chemist' in popular speech, and later the suffix \"-ry\" was added to this to describe the art of the chemist as \"chemistry\".The modern word alchemy in turn is derived from the Arabic word al-k\u012bm\u012b\u0101 . In origin, the term is borrowed from the Greek \u03c7\u03b7\u03bc\u03af\u03b1 or \u03c7\u03b7\u03bc\u03b5\u03af\u03b1.[8][9] This may have Egyptian origins since al-k\u012bm\u012b\u0101 is derived from the Greek \u03c7\u03b7\u03bc\u03af\u03b1, which is in turn derived from the word Kemet, which is the ancient name of Egypt in Egyptian.[8] Alternately, al-k\u012bm\u012b\u0101 may derive from \u03c7\u03b7\u03bc\u03b5\u03af\u03b1, meaning \"cast together\".[10]The current model of atomic structure is the quantum mechanical model.[11] Traditional chemistry starts with the study of elementary particles, atoms, molecules,[12] substances, metals, crystals and other aggregates of matter. This matter can be studied in solid, liquid, or gas states, in isolation or in combination. The interactions, reactions and transformations that are studied in chemistry are usually the result of interactions between atoms, leading to rearrangements of the chemical bonds which hold atoms together. Such behaviors are studied in a chemistry laboratory.The chemistry laboratory stereotypically uses various forms of laboratory glassware. However glassware is not central to chemistry, and a great deal of experimental  chemistry is done without it.A chemical reaction is a transformation of some substances into one or more different substances.[13] The basis of such a chemical transformation is the rearrangement of electrons in the chemical bonds between atoms. It can be symbolically depicted through a chemical equation, which usually involves atoms as subjects. The number of atoms on the left and the right in the equation for a chemical transformation is equal.  The type of chemical reactions a substance may undergo and the energy changes that may accompany it are constrained by certain basic rules, known as chemical laws.Energy and entropy considerations are invariably important in almost all chemical studies. Chemical substances are classified in terms of their structure, phase, as well as their chemical compositions. They can be analyzed using the tools of chemical analysis, e.g. spectroscopy and chromatography. Scientists engaged in chemical research are known as chemists.[14] Most chemists specialize in one or more sub-disciplines. Several concepts are essential for the study of chemistry; some of them are:[15]In chemistry, matter is defined as anything that has rest mass and volume  and is made up of particles. The particles that make up matter have rest mass as well \u2013 not all particles have rest mass, such as the photon. Matter can be a pure chemical substance or a mixture of substances.[16]The atom is the basic unit of chemistry. It consists of a dense core called the atomic nucleus surrounded by a space occupied by an electron cloud. The nucleus is made up of positively charged protons and uncharged neutrons , while the electron cloud consists of negatively charged electrons which orbit the nucleus. In a neutral atom, the negatively charged electrons balance out the positive charge of the protons. The nucleus is dense; the mass of a nucleon is appromixately 1,836 times that of an electron, yet the radius of an atom is about 10,000 times that of its nucleus.[17][18]The atom is also the smallest entity that can be envisaged to retain the chemical properties of the element, such as electronegativity, ionization potential, preferred oxidation state.A chemical element is a pure substance which is composed of a single type of atom, characterized by its particular number of protons in the nuclei of its atoms, known as the atomic number and represented by the symbol Z. The mass number is the sum of the number of protons and neutrons in a nucleus. Although all the nuclei of all atoms belonging to one element will have the same atomic number, they may not necessarily have the same mass number; atoms of an element which have different mass numbers are known as isotopes. For example, all atoms with 6 protons in their nuclei are atoms of the chemical element carbon, but atoms of carbon may have mass numbers of 12 or 13.[18]The standard presentation of the chemical elements is in the periodic table, which orders elements by atomic number. The periodic table is arranged in groups, or columns, and periods, or rows. The periodic table is useful in identifying periodic trends.[19]A compound is a pure chemical substance composed of more than one element. The properties of a compound bear little similarity to those of its elements.[20] The standard nomenclature of compounds is set by the International Union of Pure and Applied Chemistry . Organic compounds are named according to the organic nomenclature system.[21] The names for Inorganic compounds are created according to the inorganic nomenclature system. When a compound has more than one component, then they are divided into two classes, the electropositive and the electronegative components.[22] In addition the Chemical Abstracts Service has devised a method to index chemical substances. In this scheme each chemical substance is identifiable by a number known as its CAS registry number.A molecule is the smallest indivisible portion of a pure chemical substance that has its unique set of chemical properties, that is, its potential to undergo a certain set of chemical reactions with other substances. However, this definition only works well for substances that are composed of molecules, which is not true of many substances . Molecules are typically a set of atoms bound together by covalent bonds, such that the structure is electrically neutral and all valence electrons are paired with other electrons either in bonds or in lone pairs.Thus, molecules exist as electrically neutral units, unlike ions. When this rule is broken, giving the \"molecule\" a charge, the result is sometimes named a molecular ion or a polyatomic ion. However, the discrete and separate nature of the molecular concept usually requires that molecular ions be present only in well-separated form, such as a directed beam in a vacuum in a mass spectrometer. Charged polyatomic collections residing in solids  can be stable.The \"inert\" or noble gas elements  are composed of lone atoms as their smallest discrete unit, but the other isolated chemical elements consist of either molecules or networks of atoms bonded to each other in some way. Identifiable molecules compose familiar substances such as water, air, and many organic compounds like alcohol, sugar, gasoline, and the various pharmaceuticals.However, not all substances or chemical compounds consist of discrete molecules, and indeed most of the solid substances that make up the solid crust, mantle, and core of the Earth are chemical compounds without molecules. These other types of substances, such as ionic compounds and network solids, are organized in such a way as to lack the existence of identifiable molecules per se. Instead, these substances are discussed in terms of formula units or unit cells as the smallest repeating structure within the substance. Examples of such substances are mineral salts , solids like carbon and diamond, metals, and familiar silica and silicate minerals such as quartz and granite.One of the main characteristics of a molecule is its geometry often called its structure. While the structure of diatomic, triatomic or tetra atomic molecules may be trivial,  can be crucial for its chemical nature.A chemical substance is a kind of matter with a definite composition and set of properties.[23] A collection of substances is called a mixture. Examples of mixtures are air and alloys.[24]The mole is a unit of measurement that denotes an amount of substance  of carbon-12, where the carbon-12 atoms are unbound, at rest and in their ground state.[25] The number of entities per mole is known as the Avogadro constant, and is determined empirically to be approximately 6.022\u00d71023 mol\u22121.[26] Molar concentration is the amount of a particular substance per volume of solution, and is commonly reported in moldm\u22123.[27]In addition to the specific chemical properties that distinguish different chemical classifications, chemicals can exist in several phases. For the most part, the chemical classifications are independent of these bulk phase classifications; however, some more exotic phases are incompatible with certain chemical properties. A phase is a set of states of a chemical system that have similar bulk structural properties, over a range of conditions, such as pressure or temperature.Physical properties, such as density and refractive index tend to fall within values characteristic of the phase. The phase of matter is defined by the phase transition, which is when energy put into or taken out of the system goes into rearranging the structure of the system, instead of changing the bulk conditions.Sometimes the distinction between phases can be continuous instead of having a discrete boundary, in this case the matter is considered to be in a supercritical state. When three states meet based on the conditions, it is known as a triple point and since this is invariant, it is a convenient way to define a set of conditions.The most familiar examples of phases are solids, liquids, and gases. Many substances exhibit multiple solid phases. For example, there are three phases of solid iron .Less familiar phases include plasmas, Bose\u2013Einstein condensates and fermionic condensates and the paramagnetic and ferromagnetic phases of magnetic materials. While most familiar phases deal with three-dimensional systems, it is also possible to define analogs in two-dimensional systems, which has received attention for its relevance to systems in biology.Atoms sticking together in molecules or crystals are said to be bonded with one another. A chemical bond may be visualized as the multipole balance between the positive charges in the nuclei and the negative charges oscillating about them.[28] More than simple attraction and repulsion, the energies and distributions characterize the availability of an electron to bond to another atom.A chemical bond can be a covalent bond, an ionic bond, a hydrogen bond or just because of Van der Waals force. Each of these kinds of bonds is ascribed to some potential. These potentials create the interactions which hold atoms together in molecules or crystals. In many simple compounds, valence bond theory, the Valence Shell Electron Pair Repulsion model , and the concept of oxidation number can be used to explain molecular structure and composition.An ionic bond is formed when a metal loses one or more of its electrons, becoming a positively charged cation, and the electrons are then gained by the non-metal atom, becoming a negatively charged anion. The two oppositely charged ions attract one another, and the ionic bond is the electrostatic force of attraction between them. For example, sodium , or common table salt, is formed.In a covalent bond, one or more pairs of valence electrons are shared by two atoms: the resulting electrically neutral group of bonded atoms is termed a molecule. Atoms will share valence electrons in such a way as to create a noble gas electron configuration  for each atom. Atoms that tend to combine in such a way that they each have eight electrons in their valence shell are said to follow the octet rule. However, some elements like hydrogen and lithium need only two electrons in their outermost shell to attain this stable configuration; these atoms are said to follow the duet rule, and in this way they are reaching the electron configuration of the noble gas helium, which has two electrons in its outer shell.Similarly, theories from classical physics can be used to predict many ionic structures. With more complicated compounds, such as metal complexes, valence bond theory is less applicable and alternative approaches, such as the molecular orbital theory, are generally used. See diagram on electronic orbitals.In the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structures, it is invariably accompanied by an increase or decrease of energy of the substances involved. Some energy is transferred between the surroundings and the reactants of the reaction in the form of heat or light; thus the products of a reaction may have more or less energy than the reactants.A reaction is said to be exergonic if the final state is lower on the energy scale than the initial state; in the case of endergonic reactions the situation is the reverse. A reaction is said to be exothermic if the reaction releases heat to the surroundings; in the case of endothermic reactions, the reaction absorbs heat from the surroundings.Chemical reactions are invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The speed of a chemical reaction  is related to the activation energy E, by the Boltzmann's population factor \n\n\n\n\ne\n\n\u2212\nE\n\n/\n\nk\nT\n\n\n\n\n{\\displaystyle e^{-E/kT}}\n\n \u2013 that is the probability of a molecule to have energy greater than or equal to E at the given temperature T. This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation. The activation energy necessary for a chemical reaction to occur can be in the form of heat, light, electricity or mechanical force in the form of ultrasound.[29]A related concept free energy, which also incorporates entropy considerations, is a very useful means for predicting the feasibility of a reaction and determining the state of equilibrium of a chemical reaction, in chemical thermodynamics. A reaction is feasible only if the total change in the Gibbs free energy is negative, \n\n\n\n\u0394\nG\n\u2264\n0\n\n\n\n{\\displaystyle \\Delta G\\leq 0\\,}\n\n; if it is equal to zero the chemical reaction is said to be at equilibrium.There exist only limited possible states of energy for electrons, atoms and molecules. These are determined by the rules of quantum mechanics, which require quantization of energy of a bound system. The atoms/molecules in a higher energy state are said to be excited. The molecules/atoms of substance in an excited energy state are often much more reactive; that is, more amenable to chemical reactions.The phase of a substance is invariably determined by its energy and the energy of its surroundings. When the intermolecular forces of a substance are such that the energy of the surroundings is not sufficient to overcome them, it occurs in a more ordered phase like liquid or solid as is the case with water  is a gas at room temperature and standard pressure, as its molecules are bound by weaker dipole-dipole interactions.The transfer of energy from one chemical substance to another depends on the size of energy quanta emitted from one substance. However, heat energy is often transferred more easily from almost any substance to another because the phonons responsible for vibrational and rotational energy levels in a substance have much less energy than photons invoked for the electronic energy transfer. Thus, because vibrational and rotational energy levels are more closely spaced than electronic energy levels, heat is more easily transferred between substances relative to light or other forms of electronic energy. For example, ultraviolet electromagnetic radiation is not transferred with as much efficacy from one substance to another as thermal or electrical energy.The existence of characteristic energy levels for different chemical substances is useful for their identification by the analysis of spectral lines. Different kinds of spectra are often used in chemical spectroscopy, e.g. IR, microwave, NMR, ESR, etc. Spectroscopy is also used to identify the composition of remote objects \u2013 like stars and distant galaxies \u2013 by analyzing their radiation spectra.The term chemical energy is often used to indicate the potential of a chemical substance to undergo a transformation through a chemical reaction or to transform other chemical substances.When a chemical substance is transformed as a result of its interaction with another substance or with energy, a chemical reaction is said to have occurred. A chemical reaction is therefore a concept related to the \"reaction\" of a substance when it comes in close contact with another, whether as a mixture or a solution; exposure to some form of energy, or both. It results in some energy exchange between the constituents of the reaction as well as with the system environment, which may be designed vessels\u2014often laboratory glassware.Chemical reactions can result in the formation or dissociation of molecules, that is, molecules breaking apart to form two or more smaller molecules, or rearrangement of atoms within or across molecules. Chemical reactions usually involve the making or breaking of chemical bonds. Oxidation, reduction, dissociation, acid-base neutralization and molecular rearrangement are some of the commonly used kinds of chemical reactions.A chemical reaction can be symbolically depicted through a chemical equation. While in a non-nuclear chemical reaction the number and kind of atoms on both sides of the equation are equal, for a nuclear reaction this holds true only for the nuclear particles viz. protons and neutrons.[31]The sequence of steps in which the reorganization of chemical bonds may be taking place in the course of a chemical reaction is called its mechanism. A chemical reaction can be envisioned to take place in a number of steps, each of which may have a different speed. Many reaction intermediates with variable stability can thus be envisaged during the course of a reaction. Reaction mechanisms are proposed to explain the kinetics and the relative product mix of a reaction. Many physical chemists specialize in exploring and proposing the mechanisms of various chemical reactions. Several empirical rules, like the Woodward\u2013Hoffmann rules often come in handy while proposing a mechanism for a chemical reaction.According to the IUPAC gold book, a chemical reaction is \"a process that results in the interconversion of chemical species.\"[32] Accordingly, a chemical reaction may be an elementary reaction or a stepwise reaction. An additional caveat is made, in that this definition includes cases where the interconversion of conformers is experimentally observable. Such detectable chemical reactions normally involve sets of molecular entities as indicated by this definition, but it is often conceptually convenient to use the term also for changes involving single molecular entities .An ion is a charged species, an atom or a molecule, that has lost or gained one or more electrons. When an atom loses an electron and thus has more protons than electrons, the atom is a positively charged ion or cation. When an atom gains an electron and thus has more electrons than protons, the atom is a negatively charged ion or anion. Cations and anions can form a crystalline lattice of neutral salts, such as the Na+ and Cl\u2212 ions forming sodium chloride, or NaCl. Examples of polyatomic ions that do not split up during acid-base reactions are hydroxide .Plasma is composed of gaseous matter that has been completely ionized, usually through high temperature.A substance can often be classified as an acid or a base. There are several different theories which explain acid-base behavior. The simplest is Arrhenius theory, which states than an acid is a substance that produces hydronium ions when it is dissolved in water, and a base is one that produces hydroxide ions when dissolved in water. According to Br\u00f8nsted\u2013Lowry acid\u2013base theory, acids are substances that donate a positive hydrogen ion to another substance in a chemical reaction; by extension, a base is the substance which receives that hydrogen ion.A third common theory is Lewis acid-base theory, which is based on the formation of new chemical bonds. Lewis theory explains that an acid is a substance which is capable of accepting a pair of electrons from another substance during the process of bond formation, while a base is a substance which can provide a pair of electrons to form a new bond. According to this theory, the crucial things being exchanged are charges.[33] There are several other ways in which a substance may be classified as an acid or a base, as is evident in the history of this concept.[34]Acid strength is commonly measured by two methods. One measurement, based on the Arrhenius definition of acidity, is pH, which is a measurement of the hydronium ion concentration in a solution, as expressed on a negative logarithmic scale. Thus, solutions that have a low pH have a high hydronium ion concentration, and can be said to be more acidic. The other measurement, based on the Br\u00f8nsted\u2013Lowry definition, is the acid dissociation constant , which measures the relative ability of a substance to act as an acid under the Br\u00f8nsted\u2013Lowry definition of an acid. That is, substances with a higher Ka are more likely to donate hydrogen ions in chemical reactions than those with lower Ka values.Redox . Substances that have the ability to oxidize other substances are said to be oxidative and are known as oxidizing agents, oxidants or oxidizers. An oxidant removes electrons from another substance. Similarly, substances that have the ability to reduce other substances are said to be reductive and are known as reducing agents, reductants, or reducers.A reductant transfers electrons to another substance, and is thus oxidized itself. And because it \"donates\" electrons it is also called an electron donor. Oxidation and reduction properly refer to a change in oxidation number\u2014the actual transfer of electrons may never occur. Thus, oxidation is better defined as an increase in oxidation number, and reduction as a decrease in oxidation number.Although the concept of equilibrium is widely used across sciences, in the context of chemistry, it arises whenever a number of different states of the chemical composition are possible, as for example, in a mixture of several chemical compounds that can react with one another, or when a substance can be present in more than one kind of phase.A system of chemical substances at equilibrium, even though having an unchanging composition, is most often not static; molecules of the substances continue to react with one another thus giving rise to a dynamic equilibrium. Thus the concept describes the state in which the parameters such as chemical composition remain unchanged over time.Chemical reactions are governed by certain laws, which have become fundamental concepts in chemistry. Some of them are:The definition of chemistry has changed over time, as new discoveries and theories add to the functionality of the science. The term \"chymistry\", in the view of noted scientist Robert Boyle in 1661, meant the subject of the material principles of mixed bodies.[35] In 1663 the chemist Christopher Glaser described \"chymistry\" as a scientific art, by which one learns to dissolve bodies, and draw from them the different substances on their composition, and how to unite them again, and exalt them to a higher perfection.[36]The 1730 definition of the word \"chemistry\", as used by Georg Ernst Stahl, meant the art of resolving mixed, compound, or aggregate bodies into their principles; and of composing such bodies from those principles.[37] In 1837, Jean-Baptiste Dumas considered the word \"chemistry\" to refer to the science concerned with the laws and effects of molecular forces.[38] This definition further evolved until, in 1947, it came to mean the science of substances: their structure, their properties, and the reactions that change them into other substances - a characterization accepted by Linus Pauling.[39] More recently, in 1998, Professor Raymond Chang broadened the definition of \"chemistry\" to mean the study of matter and the changes it undergoes.[40]Early civilizations, such as the Egyptians[41] Babylonians, Indians[42] amassed practical knowledge concerning the arts of metallurgy, pottery and dyes, but didn't develop a systematic theory.A basic chemical hypothesis first emerged in Classical Greece with the theory of four elements as propounded definitively by Aristotle stating that fire, air, earth and water were the fundamental elements from which everything is formed as a combination. Greek atomism dates back to 440 BC, arising in works by philosophers such as Democritus and Epicurus. In 50 BC, the Roman philosopher Lucretius expanded upon the theory in his book De rerum natura .[43][44] Unlike modern concepts of science, Greek atomism was purely philosophical in nature, with little concern for empirical observations and no concern for chemical experiments.[45]In the Hellenistic world the art of alchemy first proliferated, mingling magic and occultism into the study of natural substances with the ultimate goal of transmuting elements into gold and discovering the elixir of eternal life.[46] Work, particularly the development of distillation, continued in the early Byzantine period with the most famous practitioner being the 4th century Greek-Egyptian Zosimos of Panopolis.[47] Alchemy continued to be developed and practised throughout the Arab world after the Muslim conquests,[48] and from there, and from the Byzantine remnants,[49] diffused into medieval and Renaissance Europe through Latin translations. Some influential Muslim chemists, Ab\u016b al-Rayh\u0101n al-B\u012br\u016bn\u012b,[50] Avicenna[51] and Al-Kindi refuted the theories of alchemy, particularly the theory of the transmutation of metals; and al-Tusi described a version of the conservation of mass, noting that a body of matter is able to change but is not able to disappear.[52]The development of the modern scientific method was slow and arduous, but an early scientific method for chemistry began emerging among early Muslim chemists, beginning with the 9th century Perso-Arab chemist J\u0101bir ibn Hayy\u0101n , who is sometimes referred to as \"the father of chemistry\".[53][54][55][56] He introduced a systematic and experimental approach to scientific research based in the laboratory, in contrast to the ancient Greek and Egyptian alchemists whose works were largely allegorical and often unintelligble.[57] Under the influence of the new empirical methods propounded by Sir Francis Bacon and others, a group of chemists at Oxford, Robert Boyle, Robert Hooke and John Mayow began to reshape the old alchemical traditions into a scientific discipline. Boyle in particular is regarded as the founding father of chemistry due to his most important work, the classic chemistry text The Sceptical Chymist where the differentiation is made between the claims of alchemy and the empirical scientific discoveries of the new chemistry.[58] He formulated Boyle's law, rejected the classical \"four elements\" and proposed a mechanistic alternative of atoms and chemical reactions that could be subject to rigorous experiment.[59]The theory of phlogiston  was propounded by the German Georg Ernst Stahl in the early 18th century and was only overturned by the end of the century by the French chemist Antoine Lavoisier, the chemical analogue of Newton in physics; who did more than any other to establish the new science on proper theoretical footing, by elucidating the principle of conservation of mass and developing a new system of chemical nomenclature used to this day.[61]Before his work, though, many important discoveries had been made, specifically relating to the nature of 'air' which was discovered to be composed of many different gases. The Scottish chemist Joseph Black  and the Dutchman J. B. van Helmont discovered carbon dioxide, or what Black called 'fixed air' in 1754; Henry Cavendish discovered hydrogen and elucidated its properties and Joseph Priestley and, independently, Carl Wilhelm Scheele isolated pure oxygen.English scientist John Dalton proposed the modern theory of atoms; that all substances are composed of indivisible 'atoms' of matter and that different atoms have varying atomic weights.The development of the electrochemical theory of chemical combinations occurred in the early 19th century as the result of the work of two scientists in particular, J. J. Berzelius and Humphry Davy, made possible by the prior invention of the voltaic pile by Alessandro Volta. Davy discovered nine new elements including the alkali metals by extracting them from their oxides with electric current.[64]British William Prout first proposed ordering all the elements by their atomic weight as all atoms had a weight that was an exact multiple of the atomic weight of hydrogen. J. A. R. Newlands devised an early table of elements, which was then developed into the modern periodic table of elements[65] in the 1860s by Dmitri Mendeleev and independently by several other scientists including Julius Lothar Meyer.[66][67] The inert gases, later called the noble gases were discovered by William Ramsay in collaboration with Lord Rayleigh at the end of the century, thereby filling in the basic structure of the table.At the turn of the twentieth century the theoretical underpinnings of chemistry were finally understood due to a series of remarkable discoveries that succeeded in probing and discovering the very nature of the internal structure of atoms. In 1897, J. J. Thomson of Cambridge University discovered the electron and soon after the French scientist Becquerel as well as the couple Pierre and Marie Curie investigated the phenomenon of radioactivity. In a series of pioneering scattering experiments Ernest Rutherford at the University of Manchester discovered the internal structure of the atom and the existence of the proton, classified and explained the different types of radioactivity and successfully transmuted the first element by bombarding nitrogen with alpha particles.His work on atomic structure was improved on by his students, the Danish physicist Niels Bohr and Henry Moseley. The electronic theory of chemical bonds and molecular orbitals was developed by the American scientists Linus Pauling and Gilbert N. Lewis.The year 2011 was declared by the United Nations as the International Year of Chemistry.[68] It was an initiative of the International Union of Pure and Applied Chemistry, and of the United Nations Educational, Scientific, and Cultural Organization and involves chemical societies, academics, and institutions worldwide and relied on individual initiatives to organize local and regional activities.Organic chemistry was developed by Justus von Liebig and others, following Friedrich W\u00f6hler's synthesis of urea which proved that living organisms were, in theory, reducible to chemistry.[69] Other crucial 19th century advances were; an understanding of valence bonding .Chemistry is typically divided into several major sub-disciplines. There are also several main cross-disciplinary and more specialized fields of chemistry.[70]Other disciplines within chemistry are traditionally grouped by the type of matter being studied or the kind of study. These include inorganic chemistry, the study of inorganic matter; organic chemistry, the study of organic .Other fields include agrochemistry, astrochemistry , atmospheric chemistry, chemical engineering, chemical biology, chemo-informatics, electrochemistry, environmental chemistry, femtochemistry, flavor chemistry, flow chemistry, geochemistry, green chemistry, histochemistry, history of chemistry, hydrogenation chemistry, immunochemistry, marine chemistry, materials science, mathematical chemistry, mechanochemistry, medicinal chemistry, molecular biology, molecular mechanics, nanotechnology, natural product chemistry, oenology, organometallic chemistry, petrochemistry, pharmacology, photochemistry, physical organic chemistry, phytochemistry, polymer chemistry, radiochemistry, solid-state chemistry, sonochemistry, supramolecular chemistry, surface chemistry, synthetic chemistry, thermochemistry, and many others.The chemical industry represents an important economic activity worldwide. The global top 50 chemical producers in 2013 had sales of US$980.5 billion with a profit margin of 10.3%.[72]"], "Earth sciences": ["Earth science or geoscience is a widely embraced term for the fields of science related to the planet Earth. It is the branch of science dealing with the physical constitution of the earth and its atmosphere. Earth science is the study of our planet\u2019s physical characteristics, from earthquakes to raindrops, and floods to fossils. Earth science can be considered to be a branch of planetary science, but with a much older history. \u201cEarth science\u201d is a broad term that encompasses four main branches of study, each of which is further broken down into more specialized fields.There are both reductionist and holistic approaches to Earth sciences. It is also the study of the Earth and its neighbors in space. Some Earth scientists use their knowledge of the Earth to locate and develop energy and mineral resources. Others study the impact of human activity on Earth's environment, and design methods to protect the planet. Some use their knowledge about Earth processes such as volcanoes, earthquakes, and hurricanes to plan communities that will not expose people to these dangerous events.The Earth sciences can include the study of geology, the lithosphere, and the large-scale structure of the Earth's interior, as well as the atmosphere, hydrosphere, and biosphere. Typically, Earth scientists use tools from geography, chronology, physics, chemistry, biology, and mathematics to build a quantitative understanding of how the Earth works and evolves. Earth science affects our everyday lives. For example, meteorologists study the weather and watch for dangerous storms. Hydrologists study water and warn of floods. Seismologists study earthquakes and try to predict where they will strike. Geologists study rocks and help to locate useful minerals. Earth scientists mainly work \u201cin the field\u201d\u2014climbing mountains, exploring the seabed, crawling through caves, or wading in swamps. They measure and collect samples , then they record their findings on charts and maps.The following fields of science are generally categorized within the Earth sciences:Plate tectonics, mountain ranges, volcanoes, and earthquakes are geological phenomena that can be explained in terms of physical and chemical processes in the Earth's crust.[10]Beneath the Earth's crust lies the mantle which is heated by the radioactive decay of heavy elements. The mantle is not quite solid and consists of magma which is in a state of semi-perpetual convection. This convection process causes the lithospheric plates to move, albeit slowly. The resulting process is known as plate tectonics.[11][12][13][14]Plate tectonics might be thought of as the process by which the Earth is resurfaced. As the result of seafloor spreading, new crust and lithosphere is created by the flow of magma from the mantle to the near surface, through fissures, where it cools and solidifies. Through subduction, oceanic crust and lithosphere returns to the convecting mantle.[12][14][15]Areas of the crust where new crust is created are called divergent boundaries, those where it is brought back into the Earth are convergent boundaries and those where plates slide past each other, but no new lithospheric material is created or destroyed, are referred to as transform  boundaries[12][14][16] Earthquakes result from the movement of the lithospheric plates, and they often occur near convergent boundaries where parts of the crust are forced into the Earth as part of subduction.[17]Volcanoes result primarily from the melting of subducted crust material. Crust material that is forced into the asthenosphere melts, and some portion of the melted material becomes light enough to rise to the surface\u2014giving birth to volcanoes.[12][17]The troposphere, stratosphere, mesosphere, thermosphere, and exosphere are the five layers which make up Earth's atmosphere. In all, the atmosphere is made up of about 78.0% nitrogen, 20.9% oxygen, and 0.92% argon. 75% of the gases in the atmosphere are located within the troposphere, the bottom-most layer. The remaining one percent of the atmosphere  contains small amounts of other gases including CO2 and water vapors.[18] Water vapors and CO2 allow the Earth's atmosphere to catch and hold the Sun's energy through a phenomenon called the greenhouse effect.[19] This allows Earth's surface to be warm enough to have liquid water and support life. In addition to storing heat, the atmosphere also protects living organisms by shielding some of the Earth's surface from cosmic rays\u2014of which are often incorrectly thought to be deflected by the magnetic field. [20] The magnetic field\u2014created by the internal motions of the core\u2014produces the magnetosphere which protects the Earth's atmosphere from the solar wind.[21] As the Earth is 4.5 billion years old,[22] it would have lost its atmosphere by now if there were no protective magnetosphere.An electromagnet is a magnet that is created by an electric current.[23] The Earth has a solid iron inner core surrounded by fluid outer core that convects;[24] therefore, the Earth is an electromagnet. The motion of fluid convection sustains the Earth's magnetic field.[24][25]Methodologies vary depending on the nature of the subjects being studied. Studies typically fall into one of three categories: observational, experimental, or theoretical. Earth scientists often conduct sophisticated computer analysis or go to many of the world's most exotic locations to study Earth phenomena .A foundational idea within the study Earth science is the notion of uniformitarianism. Uniformitarianism dictates that \"ancient geologic features are interpreted by understanding active processes that are readily observed.\"[citation needed] In other words, any geologic processes at work in the present have operated in the same ways throughout geologic time. This enables those who study Earth's history to apply knowledge of how Earth processes operate in the present to gain insight into how the planet has evolved and changed throughout deep history.Earth science generally recognizes four spheres, the lithosphere, the hydrosphere, the atmosphere, and the biosphere;[26] these correspond to rocks, water, air and life. Also included by some are the cryosphere  as an active and intermixed sphere."], "Space sciences": [], "Physics": ["Physics  is the natural science that studies matter[4] and its motion and behavior through space and time and that studies the related entities of energy and force.[5] Physics is one of the most fundamental scientific disciplines, and its main goal is to understand how the universe behaves.[a][6][7][8]Physics is one of the oldest academic disciplines and, through its inclusion of astronomy, perhaps the oldest.[9] Over the last two millennia, physics, chemistry, biology, and certain branches of mathematics were a part of natural philosophy, but during the scientific revolution in the 17th century, these natural sciences emerged as unique research endeavors in their own right.[b] Physics intersects with many interdisciplinary areas of research, such as biophysics and quantum chemistry, and the boundaries of physics are not rigidly defined. New ideas in physics often explain the fundamental mechanisms studied by other sciences[6] and suggest new avenues of research in academic disciplines such as mathematics and philosophy.Advances in physics often enable advances in new technologies. For example, advances in the understanding of electromagnetism and nuclear physics led directly to the development of new products that have dramatically transformed modern-day society, such as television, computers, domestic appliances, and nuclear weapons;[6] advances in thermodynamics led to the development of industrialization; and advances in mechanics inspired the development of calculus.Astronomy is one of the oldest natural sciences. The earliest civilizations dating back to beyond 3000\u00a0BCE, such as the Sumerians, ancient Egyptians, and the Indus Valley Civilization, all had a predictive knowledge and a basic understanding of the motions of the Sun, Moon, and stars. The stars and planets were often a target of worship, believed to represent their gods. While the explanations for these phenomena were often unscientific and lacking in evidence, these early observations laid the foundation for later astronomy.[9]According to Asger Aaboe, the origins of Western astronomy can be found in Mesopotamia, and all Western efforts in the exact sciences are descended from late Babylonian astronomy.[11] Egyptian astronomers left monuments showing knowledge of the constellations and the motions of the celestial bodies,[12] while Greek poet Homer wrote of various celestial objects in his Iliad and Odyssey; later Greek astronomers provided names, which are still used today, for most constellations visible from the northern hemisphere.[13]Natural philosophy has its origins in Greece during the Archaic period, , when pre-Socratic philosophers like Thales rejected non-naturalistic explanations for natural phenomena and proclaimed that every event had a natural cause.[14] They proposed ideas verified by reason and observation, and many of their hypotheses proved successful in experiment;[15] for example, atomism was found to be correct approximately 2000 years after it was proposed by Leucippus and his pupil Democritus.[16]Because of the Migration Period the Western Roman Empire fell, and thus a decline in intellectual level found place in the western part of Europe in the 400s. In contrast, the Eastern Roman Empire resisted the attacks from the barbarians, and preserved and improved the learning inclusive the physics.[17]In the sixth century Isidore of Miletus created an important compilation of Archimedes' works that are preserved in the Archimedes Palimpsest.At the same time John Philoponus, a byzantine scholar, questioned Aristotle's teaching of physics and noting its flaws. He introduced the theory of impetus. Aristotle\u2019s physics was not scrutinized until John Philoponus appeared, and unlike Aristotle who based his physics on verbal argument, Philoponus relied on observation. On Aristotle's physics John Philoponus wrote:\u201cBut this is completely erroneous, and our view may be corroborated by actual observation more effectively than by any sort of verbal argument. For if you let fall from the same height two weights of which one is many times as heavy as the other, you will see that the ratio of the times required for the motion does not depend on the ratio of the weights, but that the difference in time is a very small one. And so, if the difference in the weights is not considerable, that is, of one is, let us say, double the other, there will be no difference, or else an imperceptible difference, in time, though the difference in weight is by no means negligible, with one body weighing twice as much as the other\u201d[18]John Philoponus' criticism of Aristotelian principles of physics served as an inspiration for Galileo Galilei ten centuries later, during the Scientific Revolution. Galileo cited Philoponus substantially in his works when arguing that Aristotelian physics was flawed.[19][20] In the 1300s Jean Buridan, a teacher in the faculty of arts at the University of Paris, developed the concept of impetus. It was a step toward the modern ideas of inertia and momentum.[21]Islamic scholarship inherited Aristotelian physics from the Greeks and during the Islamic Golden Age developed it further, especially placing emphasis on observation and a priori reasoning, developing early forms of the scientific method.The most notable innovations were in the field of optics and vision, which came from the works of many scientists like Ibn Sahl, Al-Kindi, Ibn al-Haytham, Al-Farisi and Avicenna. The most notable work was The Book of Optics  and delved further into the way the eye itself works. Using dissections and the knowledge of previous scholars, he was able to begin to explain how light enters the eye. He asserted that the light ray is focused, but the actual explanation of how light projected to the back of the eye had to wait until 1604. His Treatise on Light explained the camera obscura, hundreds of years before the modern development of photography.[22]The seven-volume Book of Optics  hugely influenced thinking across disciplines from the theory of visual perception to the nature of perspective in medieval art, in both the East and the West, for more than 600 years. Many later European scholars and fellow polymaths, from Robert Grosseteste and Leonardo da Vinci to Ren\u00e9 Descartes, Johannes Kepler and Isaac Newton, were in his debt. Indeed, the influence of Ibn al-Haytham's Optics ranks alongside that of Newton's work of the same title, published 700 years later.The translation of The Book of Optics had a huge impact on Europe. From it, later European scholars were able to build devices that replicated those Ibn al-Haytham had built, and understand the way light works. From this, such important things as eyeglasses, magnifying glasses, telescopes, and cameras were developed.Physics became a separate science when early modern Europeans used experimental and quantitative methods to discover what are now considered to be the laws of physics.[24][page\u00a0needed]Major developments in this period include the replacement of the geocentric model of the solar system with the heliocentric Copernican model, the laws governing the motion of planetary bodies determined by Johannes Kepler between 1609 and 1619, pioneering work on telescopes and observational astronomy by Galileo Galilei in the 16th and 17th Centuries, and Isaac Newton's discovery and unification of the laws of motion and universal gravitation that would come to bear his name.[25] Newton also developed calculus,[c] the mathematical study of change, which provided new mathematical methods for solving physical problems.[26]The discovery of new laws in thermodynamics, chemistry, and electromagnetics resulted from greater research efforts during the Industrial Revolution as energy needs increased.[27] The laws comprising classical physics remain very widely used for objects on everyday scales travelling at non-relativistic speeds, since they provide a very close approximation in such situations, and theories such as quantum mechanics and the theory of relativity simplify to their classical equivalents at such scales. However, inaccuracies in classical mechanics for very small objects and very high velocities led to the development of modern physics in the 20th century.Modern physics began in the early 20th century with the work of Max Planck in quantum theory and Albert Einstein's theory of relativity. Both of these theories came about due to inaccuracies in classical mechanics in certain situations. Classical mechanics predicted a varying speed of light, which could not be resolved with the constant speed predicted by Maxwell's equations of electromagnetism; this discrepancy was corrected by Einstein's theory of special relativity, which replaced classical mechanics for fast-moving bodies and allowed for a constant speed of light.[28] Black body radiation provided another problem for classical physics, which was corrected when Planck proposed that the excitation of material oscillators is possible only in discrete steps proportional to their frequency; this, along with the photoelectric effect and a complete theory predicting discrete energy levels of electron orbitals, led to the theory of quantum mechanics taking over from classical physics at very small scales.[29]Quantum mechanics would come to be pioneered by Werner Heisenberg, Erwin Schr\u00f6dinger and Paul Dirac.[29] From this early work, and work in related fields, the Standard Model of particle physics was derived.[30] Following the discovery of a particle with properties consistent with the Higgs boson at CERN in 2012,[31] all fundamental particles predicted by the standard model, and no others, appear to exist; however, physics beyond the Standard Model, with theories such as supersymmetry, is an active area of research.[32] Areas of mathematics in general are important to this field, such as the study of probabilities and groups.In many ways, physics stems from ancient Greek philosophy. From Thales' first attempt to characterise matter, to Democritus' deduction that matter ought to reduce to an invariant state, the Ptolemaic astronomy of a crystalline firmament, and Aristotle's book Physics , various Greek philosophers advanced their own theories of nature. Physics was known as natural philosophy until the late 18th century.[33]By the 19th century, physics was realised as a discipline distinct from philosophy and the other sciences. Physics, as with the rest of science, relies on philosophy of science and its \"scientific method\" to advance our knowledge of the physical world.[34] The scientific method employs a priori reasoning as well as a posteriori reasoning and the use of Bayesian inference to measure the validity of a given theory.[35]The development of physics has answered many questions of early philosophers, but has also raised new questions. Study of the philosophical issues surrounding physics, the philosophy of physics, involves issues such as the nature of space and time, determinism, and metaphysical outlooks such as empiricism, naturalism and realism.[36]Many physicists have written about the philosophical implications of their work, for instance Laplace, who championed causal determinism,[37] and Erwin Schr\u00f6dinger, who wrote on quantum mechanics.[38][39] The mathematical physicist Roger Penrose has been called a Platonist by Stephen Hawking,[40] a view Penrose discusses in his book, The Road to Reality.[41] Hawking refers to himself as an \"unashamed reductionist\" and takes issue with Penrose's views.[42]Though physics deals with a wide variety of systems, certain theories are used by all physicists. Each of these theories were experimentally tested numerous times and found to be an adequate approximation of nature. For instance, the theory of classical mechanics accurately describes the motion of objects, provided they are much larger than atoms and moving at much less than the speed of light. These theories continue to be areas of active research today. Chaos theory, a remarkable aspect of classical mechanics was discovered in the 20th century, three centuries after the original formulation of classical mechanics by Isaac Newton .These central theories are important tools for research into more specialised topics, and any physicist, regardless of their specialisation, is expected to be literate in them. These include classical mechanics, quantum mechanics, thermodynamics and statistical mechanics, electromagnetism, and special relativity.Classical physics includes the traditional branches and topics that were recognised and well-developed before the beginning of the 20th century\u2014classical mechanics, acoustics, optics, thermodynamics, and electromagnetism. Classical mechanics is concerned with bodies acted on by forces and bodies in motion and may be divided into statics , the latter include such branches as hydrostatics, hydrodynamics, aerodynamics, and pneumatics. Acoustics is the study of how sound is produced, controlled, transmitted and received.[43] Important modern branches of acoustics include ultrasonics, the study of sound waves of very high frequency beyond the range of human hearing; bioacoustics, the physics of animal calls and hearing,[44] and electroacoustics, the manipulation of audible sound waves using electronics.[45]Optics, the study of light, is concerned not only with visible light but also with infrared and ultraviolet radiation, which exhibit all of the phenomena of visible light except visibility, e.g., reflection, refraction, interference, diffraction, dispersion, and polarization of light. Heat is a form of energy, the internal energy possessed by the particles of which a substance is composed; thermodynamics deals with the relationships between heat and other forms of energy. Electricity and magnetism have been studied as a single branch of physics since the intimate connection between them was discovered in the early 19th century; an electric current gives rise to a magnetic field, and a changing magnetic field induces an electric current. Electrostatics deals with electric charges at rest, electrodynamics with moving charges, and magnetostatics with magnetic poles at rest.Classical physics is generally concerned with matter and energy on the normal scale of observation, while much of modern physics is concerned with the behavior of matter and energy under extreme conditions or on a very large or very small scale. For example, atomic and nuclear physics studies matter on the smallest scale at which chemical elements can be identified. The physics of elementary particles is on an even smaller scale since it is concerned with the most basic units of matter; this branch of physics is also known as high-energy physics because of the extremely high energies necessary to produce many types of particles in particle accelerators. On this scale, ordinary, commonsense notions of space, time, matter, and energy are no longer valid.[46]The two chief theories of modern physics present a different picture of the concepts of space, time, and matter from that presented by classical physics. Classical mechanics approximates nature as continuous, while quantum theory is concerned with the discrete nature of many phenomena at the atomic and subatomic level and with the complementary aspects of particles and waves in the description of such phenomena. The theory of relativity is concerned with the description of phenomena that take place in a frame of reference that is in motion with respect to an observer; the special theory of relativity is concerned with relative uniform motion in a straight line and the general theory of relativity with accelerated motion and its connection with gravitation. Both quantum theory and the theory of relativity find applications in all areas of modern physics.[47]While physics aims to discover universal laws, its theories lie in explicit domains of applicability. Loosely speaking, the laws of classical physics accurately describe systems whose important length scales are greater than the atomic scale and whose motions are much slower than the speed of light. Outside of this domain, observations do not match predictions provided by classical mechanics. Albert Einstein contributed the framework of special relativity, which replaced notions of absolute time and space with spacetime and allowed an accurate description of systems whose components have speeds approaching the speed of light. Max Planck, Erwin Schr\u00f6dinger, and others introduced quantum mechanics, a probabilistic notion of particles and interactions that allowed an accurate description of atomic and subatomic scales. Later, quantum field theory unified quantum mechanics and special relativity. General relativity allowed for a dynamical, curved spacetime, with which highly massive systems and the large-scale structure of the universe can be well-described. General relativity has not yet been unified with the other fundamental descriptions; several candidate theories of quantum gravity are being developed.Mathematics provides a compact and exact language used to describe of the order in nature. This was noted and advocated by Pythagoras,[48] Plato,[49] Galileo,[50] and Newton.Physics uses mathematics[51] to organise and formulate experimental results. From those results, precise or estimated solutions, quantitative results from which new predictions can be made and experimentally confirmed or negated. The results from physics experiments are numerical measurements. Technologies based on mathematics, like computation have made computational physics an active area of research.Ontology is a prerequisite for physics, but not for mathematics. It means physics is ultimately concerned with descriptions of the real world, while mathematics is concerned with abstract patterns, even beyond the real world. Thus physics statements are synthetic, while mathematical statements are analytic. Mathematics contains hypotheses, while physics contains theories. Mathematics statements have to be only logically true, while predictions of physics statements must match observed and experimental data.The distinction is clear-cut, but not always obvious. For example, mathematical physics is the application of mathematics in physics. Its methods are mathematical, but its subject is physical.[52] The problems in this field start with a \"mathematical model of a physical situation\"  and a \"mathematical description of a physical law\" that will be applied to that system. Every mathematical statement used for solving has a hard-to-find physical meaning. The final mathematical solution has an easier-to-find meaning, because it is what the solver is looking for.[clarification needed]Physics is a branch of fundamental science, not practical science. Physics is also called \"the fundamental science\" because the subject of study of all branches of natural science like chemistry, astronomy, geology, and biology are constrained by laws of physics,[53] similar to how chemistry is often called the central science because of its role in linking the physical sciences. For example, chemistry studies properties, structures, and reactions of matter . Structures are formed because particles exert electrical forces on each other, properties include physical characteristics of given substances, and reactions are bound by laws of physics, like conservation of energy, mass, and charge.Physics is applied in industries like engineering and medicine.Applied physics is a general term for physics research which is intended for a particular use. An applied physics curriculum usually contains a few classes in an applied discipline, like geology or electrical engineering. It usually differs from engineering in that an applied physicist may not be designing something in particular, but rather is using physics or conducting physics research with the aim of developing new technologies or solving a problem.The approach is similar to that of applied mathematics. Applied physicists use physics in scientific research. For instance, people working on accelerator physics might seek to build better particle detectors for research in theoretical physics.Physics is used heavily in engineering. For example, statics, a subfield of mechanics, is used in the building of bridges and other static structures. The understanding and use of acoustics results in sound control and better concert halls; similarly, the use of optics creates better optical devices. An understanding of physics makes for more realistic flight simulators, video games, and movies, and is often critical in forensic investigations.With the standard consensus that the laws of physics are universal and do not change with time, physics can be used to study things that would ordinarily be mired in uncertainty. For example, in the study of the origin of the earth, one can reasonably model earth's mass, temperature, and rate of rotation, as a function of time allowing one to extrapolate forward or backward in time and so predict future or prior events. It also allows for simulations in engineering which drastically speed up the development of a new technology.But there is also considerable interdisciplinarity in the physicist's methods, so many other important fields are influenced by physics .Physicists use the scientific method to test the validity of a physical theory. By using a methodical approach to compare the implications of a theory with the conclusions drawn from its related experiments and observations, physicists are better able to test the validity of a theory in a logical, unbiased, and repeatable way. To that end, experiments are performed and observations are made in order to determine the validity or invalidity of the theory.[54]A scientific law is a concise verbal or mathematical statement of a relation which expresses a fundamental principle of some theory, such as Newton's law of universal gravitation.[55]Theorists seek to develop mathematical models that both agree with existing experiments and successfully predict future experimental results, while experimentalists devise and perform experiments to test theoretical predictions and explore new phenomena. Although theory and experiment are developed separately, they are strongly dependent upon each other. Progress in physics frequently comes about when experimentalists make a discovery that existing theories cannot explain, or when new theories generate experimentally testable predictions, which inspire new experiments.[56]Physicists who work at the interplay of theory and experiment are called phenomenologists, who study complex phenomena observed in experiment and work to relate them to a fundamental theory.[57]Theoretical physics has historically taken inspiration from philosophy; electromagnetism was unified this way.[d] Beyond the known universe, the field of theoretical physics also deals with hypothetical issues,[e] such as parallel universes, a multiverse, and higher dimensions. Theorists invoke these ideas in hopes of solving particular problems with existing theories. They then explore the consequences of these ideas and work toward making testable predictions.Experimental physics expands, and is expanded by, engineering and technology. Experimental physicists involved in basic research design and perform experiments with equipment such as particle accelerators and lasers, whereas those involved in applied research often work in industry developing technologies such as magnetic resonance imaging  and transistors. Feynman has noted that experimentalists may seek areas which are not well-explored by theorists.[58]Physics covers a wide range of phenomena, from elementary particles  to the largest superclusters of galaxies. Included in these phenomena are the most basic objects composing all other things. Therefore, physics is sometimes called the \"fundamental science\".[53] Physics aims to describe the various phenomena that occur in nature in terms of simpler phenomena. Thus, physics aims to both connect the things observable to humans to root causes, and then connect these causes together.For example, the ancient Chinese observed that certain rocks .[60]Contemporary research in physics can be broadly divided into nuclear and particle physics; condensed matter physics; atomic, molecular, and optical physics; astrophysics; and applied physics. Some physics departments also support physics education research and physics outreach.[61]Since the 20th century, the individual fields of physics have become increasingly specialised, and today most physicists work in a single field for their entire careers. \"Universalists\" such as Albert Einstein , who worked in multiple fields of physics, are now very rare.[f]The major fields of physics, along with their subfields and the theories and concepts they employ, are shown in the following table.Particle physics is the study of the elementary constituents of matter and energy and the interactions between them.[62] In addition, particle physicists design and develop the high energy accelerators,[63] detectors,[64] and computer programs[65] necessary for this research. The field is also called \"high-energy physics\" because many elementary particles do not occur naturally but are created only during high-energy collisions of other particles.[66]Currently, the interactions of elementary particles and fields are described by the Standard Model.[67] The model accounts for the 12 known particles of matter .[68] The Standard Model also predicts a particle known as the Higgs boson.[67] In July 2012 CERN, the European laboratory for particle physics, announced the detection of a particle consistent with the Higgs boson,[69] an integral part of a Higgs mechanism.Nuclear physics is the field of physics that studies the constituents and interactions of atomic nuclei. The most commonly known applications of nuclear physics are nuclear power generation and nuclear weapons technology, but the research has provided application in many fields, including those in nuclear medicine and magnetic resonance imaging, ion implantation in materials engineering, and radiocarbon dating in geology and archaeology.Atomic, molecular, and optical physics .Atomic physics studies the electron shells of atoms. Current research focuses on activities in quantum control, cooling and trapping of atoms and ions,[70][71][72] low-temperature collision dynamics and the effects of electron correlation on structure and dynamics. Atomic physics is influenced by the nucleus , but intra-nuclear phenomena such as fission and fusion are considered part of nuclear physics.Molecular physics focuses on multi-atomic structures and their internal and external interactions with matter and light. Optical physics is distinct from optics in that it tends to focus not on the control of classical light fields by macroscopic objects but on the fundamental properties of optical fields and their interactions with matter in the microscopic realm.Condensed matter physics is the field of physics that deals with the macroscopic physical properties of matter.[73] In particular, it is concerned with the \"condensed\" phases that appear whenever the number of particles in a system is extremely large and the interactions between them are strong.[74]The most familiar examples of condensed phases are solids and liquids, which arise from the bonding by way of the electromagnetic force between atoms.[75] More exotic condensed phases include the superfluid[76] and the Bose\u2013Einstein condensate[77] found in certain atomic systems at very low temperature, the superconducting phase exhibited by conduction electrons in certain materials,[78] and the ferromagnetic and antiferromagnetic phases of spins on atomic lattices.[79]Condensed matter physics is the largest field of contemporary physics. Historically, condensed matter physics grew out of solid-state physics, which is now considered one of its main subfields.[80] The term condensed matter physics was apparently coined by Philip Anderson when he renamed his research group\u2014previously solid-state theory\u2014in 1967.[81] In 1978, the Division of Solid State Physics of the American Physical Society was renamed as the Division of Condensed Matter Physics.[80] Condensed matter physics has a large overlap with chemistry, materials science, nanotechnology and engineering.[74]Astrophysics and astronomy are the application of the theories and methods of physics to the study of stellar structure, stellar evolution, the origin of the Solar System, and related problems of cosmology. Because astrophysics is a broad subject, astrophysicists typically apply many disciplines of physics, including mechanics, electromagnetism, statistical mechanics, thermodynamics, quantum mechanics, relativity, nuclear and particle physics, and atomic and molecular physics.[82]The discovery by Karl Jansky in 1931 that radio signals were emitted by celestial bodies initiated the science of radio astronomy. Most recently, the frontiers of astronomy have been expanded by space exploration. Perturbations and interference from the earth's atmosphere make space-based observations necessary for infrared, ultraviolet, gamma-ray, and X-ray astronomy.Physical cosmology is the study of the formation and evolution of the universe on its largest scales. Albert Einstein's theory of relativity plays a central role in all modern cosmological theories. In the early 20th century, Hubble's discovery that the universe is expanding, as shown by the Hubble diagram, prompted rival explanations known as the steady state universe and the Big Bang.The Big Bang was confirmed by the success of Big Bang nucleosynthesis and the discovery of the cosmic microwave background in 1964. The Big Bang model rests on two theoretical pillars: Albert Einstein's general relativity and the cosmological principle. Cosmologists have recently established the \u039bCDM model of the evolution of the universe, which includes cosmic inflation, dark energy, and dark matter.Numerous possibilities and discoveries are anticipated to emerge from new data from the Fermi Gamma-ray Space Telescope over the upcoming decade and vastly revise or clarify existing models of the universe.[83][84] In particular, the potential for a tremendous discovery surrounding dark matter is possible over the next several years.[85] Fermi will search for evidence that dark matter is composed of weakly interacting massive particles, complementing similar experiments with the Large Hadron Collider and other underground detectors.IBEX is already yielding new astrophysical discoveries: \"No one knows what is creating the ENA  ribbon\" along the termination shock of the solar wind, \"but everyone agrees that it means the textbook picture of the heliosphere\u2014in which the Solar System's enveloping pocket filled with the solar wind's charged particles is plowing through the onrushing 'galactic wind' of the interstellar medium in the shape of a comet\u2014is wrong.\"[86]Research in physics is continually progressing on a large number of fronts.In condensed matter physics, an important unsolved theoretical problem is that of high-temperature superconductivity.[87] Many condensed matter experiments are aiming to fabricate workable spintronics and quantum computers.[74][88]In particle physics, the first pieces of experimental evidence for physics beyond the Standard Model have begun to appear. Foremost among these are indications that neutrinos have non-zero mass. These experimental results appear to have solved the long-standing solar neutrino problem, and the physics of massive neutrinos remains an area of active theoretical and experimental research. The Large Hadron Collider has already found the Higgs Boson, but future research aims to prove or disprove the supersymmetry, which extends the Standard Model of particle physics. Research on the nature of the major mysteries of dark matter and dark energy is also currently ongoing.[89]Theoretical attempts to unify quantum mechanics and general relativity into a single theory of quantum gravity, a program ongoing for over half a century, have not yet been decisively resolved. The current leading candidates are M-theory, superstring theory and loop quantum gravity.Many astronomical and cosmological phenomena have yet to be satisfactorily explained, including the origin of ultra-high energy cosmic rays, the baryon asymmetry, the acceleration of the universe and the anomalous rotation rates of galaxies.Although much progress has been made in high-energy, quantum, and astronomical physics, many everyday phenomena involving complexity,[90] chaos,[91] or turbulence[92] are still poorly understood. Complex problems that seem like they could be solved by a clever application of dynamics and mechanics remain unsolved; examples include the formation of sandpiles, nodes in trickling water, the shape of water droplets, mechanisms of surface tension catastrophes, and self-sorting in shaken heterogeneous collections.[93]These complex phenomena have received growing attention since the 1970s for several reasons, including the availability of modern mathematical methods and computers, which enabled complex systems to be modeled in new ways. Complex physics has become part of increasingly interdisciplinary research, as exemplified by the study of turbulence in aerodynamics and the observation of pattern formation in biological systems. In the 1932 Annual Review of Fluid Mechanics, Horace Lamb said:[94]GeneralOrganizationsOnline course learning resources"], "Computer Science": ["Computer science is the study of the theory, experimentation, and engineering that form the basis for the design and use of computers. It is the scientific and practical approach to computation and its applications and the systematic study of the feasibility, structure, expression, and mechanization of the methodical procedures  that underlie the acquisition, representation, processing, storage, communication of, and access to, information. An alternate, more succinct definition of computer science is the study of automating algorithmic processes that scale. A computer scientist specializes in the theory of computation and the design of computational systems.[1] See glossary of computer science.Its fields can be divided into a variety of theoretical and practical disciplines. Some fields, such as computational complexity theory , are highly abstract, while fields such as computer graphics emphasize real-world visual applications. Other fields still focus on challenges in implementing computation. For example, programming language theory considers various approaches to the description of computation, while the study of computer programming itself investigates various aspects of the use of programming language and complex systems. Human\u2013computer interaction considers the challenges in making computers and computations useful, usable, and universally accessible to humans.The earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Further, algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.Wilhelm Schickard designed and constructed the first working mechanical calculator in 1623.[4] In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner.[5] He may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry[note 1] when he released his simplified arithmometer, which was the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine.[6] He started developing this machine in 1834, and \"in less than two years, he had sketched out many of the salient features of the modern computer\".[7] \"A crucial step was the adoption of a punched card system derived from the Jacquard loom\"[7] making it infinitely programmable.[note 2] In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first computer program.[8] Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. In 1937, one hundred years after Babbage's impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business[9] to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as \"Babbage's dream come true\".[10]During the 1940s, as new and more powerful computing machines were developed, the term computer came to refer to the machines rather than their human predecessors.[11] As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s.[12][13] The world's first computer science degree program, the Cambridge Diploma in Computer Science, began at the University of Cambridge Computer Laboratory in 1953. The first computer science degree program in the United States was formed at Purdue University in 1962.[14] Since practical computers became available, many applications of computing have become distinct areas of study in their own rights.Although many initially believed it was impossible that computers themselves could actually be a scientific field of study, in the late fifties it gradually became accepted among the greater academic population.[15][16] It is the now well-known IBM brand that formed part of the computer science revolution during this time. IBM  released the IBM 704[17] and later the IBM 709[18] computers, which were widely used during the exploration period of such devices. \"Still, working with the IBM [computer] was frustrating [\u2026] if you had misplaced as much as one letter in one instruction, the program would crash, and you would have to start the whole process over again\".[15] During the late 1950s, the computer science discipline was very much in its developmental stages, and such issues were commonplace.[16]Time has seen significant improvements in the usability and effectiveness of computing technology.[19] Modern society has seen a significant shift in the users of computer technology, from usage only by experts and professionals, to a near-ubiquitous user base. Initially, computers were quite costly, and some degree of human aid was needed for efficient use\u2014in part from professional computer operators. As computer adoption became more widespread and affordable, less human assistance was needed for common usage.Despite its short history as a formal academic discipline, computer science has made a number of fundamental contributions to science and society\u2014in fact, along with electronics, it is a founding science of the current epoch of human history called the Information Age and a driver of the information revolution, seen as the third major leap in human technological progress after the Industrial Revolution .These contributions include:Although first proposed in 1956,[16] the term \"computer science\" appears in a 1959 article in Communications of the ACM,[28] in which Louis Fein argues for the creation of a Graduate School in Computer Sciences analogous to the creation of Harvard Business School in 1921,[29] justifying the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.[28] His efforts, and those of others such as numerical analyst George Forsythe, were rewarded: universities went on to create such programs, starting with Purdue in 1962.[30] Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed.[31] Certain departments of major universities prefer the term computing science, to emphasize precisely that difference. Danish scientist Peter Naur suggested the term datalogy,[32] to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is data science; this is now used for a distinct field of data analysis, including statistics and databases.Also, in the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the Communications of the ACM\u2014turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist.[33] Three months later in the same journal, comptologist was suggested, followed next year by hypologist.[34] The term computics has also been suggested.[35] In Europe, terms derived from contracted translations of the expression \"automatic information\" .[36] \"In the U.S., however, informatics is linked with applied computing, or computing in the context of another domain.\"[37]A folkloric quotation, often attributed to\u2014but almost certainly not first formulated by\u2014Edsger Dijkstra, states that \"computer science is no more about computers than astronomy is about telescopes.\"[note 3] The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. However, there has been much cross-fertilization of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such as philosophy, cognitive science, linguistics, mathematics, physics, biology, statistics, and logic.Computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science.[12] Early computer science was strongly influenced by the work of mathematicians such as Kurt G\u00f6del, Alan Turing, R\u00f3zsa P\u00e9ter and Alonzo Church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.[16]The relationship between computer science and software engineering is a contentious issue, which is further muddied by disputes over what the term \"software engineering\" means, and how computer science is defined.[38] David Parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.[39]The academic, political, and funding aspects of computer science tend to depend on whether a department formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. Both types of departments tend to make efforts to bridge the field educationally if not across all research.A number of computer scientists have argued for the distinction of three separate paradigms in computer science. Peter Wegner argued that those paradigms are science, technology, and mathematics.[40] Peter Denning's working group argued that they are theory, abstraction .[42]As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.[43][44] CSAB, formerly called Computing Sciences Accreditation Board\u2014which is made up of representatives of the Association for Computing Machinery [45]\u2014identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human\u2013computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.[43]Theoretical Computer Science is mathematical and abstract in spirit, but it derives its motivation from practical and everyday computation. Its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies. All studies related to mathematical, logic and formal concepts and methods could be considered as theoretical computer science, provided that the motivation is clearly drawn from the field of computing.Data structures and algorithms is the study of commonly used computational methods and their computational efficiency.According to Peter Denning, the fundamental question underlying computer science is, \"What can be  automated?\"[12] Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. The second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.The famous P = NP? problem, one of the Millennium Prize Problems,[46] is an open problem in the theory of computation.Information theory is related to the quantification of information. This was developed by Claude Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.[47] Coding theory is the study of the properties of codes  and their fitness for a specific application. Codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. Codes are studied for the purpose of designing efficient and reliable data transmission methods.Programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. It is an active research area, with numerous dedicated academic journals.Formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.Computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory.[48] The field often involves disciplines of computer engineering and electrical engineering, selecting and interconnecting hardware components to create computers that meet functional, performance, and cost goals.Computer performance analysis is the study of work flowing through computers with the general goals of improving throughput, controlling response time, using resources efficiently, eliminating bottlenecks, and predicting performance under anticipated peak loads.[49]Concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi and the Parallel Random Access Machine model. A distributed system extends the idea of concurrency onto multiple computers connected through a network. Computers within the same distributed system have their own private memory, and information is often exchanged among themselves to achieve a common goal.This branch of computer science aims to manage networks between computers worldwide.Computer security is a branch of computer technology, whose objective includes protection of information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users. Cryptography is the practice and study of hiding  information. Modern cryptography is largely related to computer science, for many encryption and decryption algorithms are based on their computational complexity.A database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages.Computer graphics is the study of digital visual contents, and involves synthesis and manipulation of image data. The study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.Research that develops theories, principles, and guidelines for user interface designers, so they can create satisfactory user experiences with desktop, laptop, and mobile devices.Scientific computing  is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. In practical use, it is typically the application of computer simulation and other forms of computation to problems in various scientific disciplines.Artificial intelligence , artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. AI is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. The starting-point in the late 1940s was Alan Turing's question \"Can computers think?\", and the question remains effectively unanswered although the Turing test is still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.Software engineering is the study of designing, implementing, and modifying software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software\u2014it doesn't just deal with the creation or manufacture of new software, but its internal maintenance and arrangement. Both computer applications software engineers and computer systems software engineers are projected to be among the fastest growing occupations from 2008 to 2018.The philosopher of computing Bill Rapaport noted three Great Insights of Computer Science:[50]Conferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications.[51][52] One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.[53]Since computer science is a relatively new field, it is not as widely taught in schools and universities as other academic subjects. For example, in 2014, Code.org estimated that only 10 percent of high schools in the United States offered computer science education.[54] A 2010 report by Association for Computing Machinery  revealed that only 14 out of 50 states have adopted significant education standards for high school computer science.[55] However, computer science education is growing.[56] Some countries, such as Israel, New Zealand and South Korea, have already included computer science in their respective national secondary education curriculum.[57][58] Several countries are following suit.[59]In most countries, there is a significant gender gap in computer science education. For example, in the US about 20% of computer science degrees in 2012 were conferred to women.[60] This gender gap also exists in other Western countries.[61] However, in some parts of the world, the gap is small or nonexistent. In 2011, approximately half of all computer science degrees in Malaysia were conferred to women.[62] In 2001, women made up 54.5% of computer science graduates in Guyana.[61]"], "Mathematics": ["Mathematics  is the study of such topics as quantity,[1] structure,[2] space,[1] and change.[3][4][5] It has no generally accepted definition.[6][7]Mathematicians seek out patterns[8][9] and use them to formulate new conjectures. Mathematicians resolve the truth or falsity of conjectures by mathematical proof. When mathematical structures are good models of real phenomena, then mathematical reasoning can provide insight or predictions about nature. Through the use of abstraction and logic, mathematics developed from counting, calculation, measurement, and the systematic study of the shapes and motions of physical objects. Practical mathematics has been a human activity from as far back as written records exist. The research required to solve mathematical problems can take years or even centuries of sustained inquiry.Rigorous arguments first appeared in Greek mathematics, most notably in Euclid's Elements. Since the pioneering work of Giuseppe Peano , and others on axiomatic systems in the late 19th\u00a0century, it has become customary to view mathematical research as establishing truth by rigorous deduction from appropriately chosen axioms and definitions. Mathematics developed at a relatively slow pace until the Renaissance, when mathematical innovations interacting with new scientific discoveries led to a rapid increase in the rate of mathematical discovery that has continued to the present day.[10]Galileo Galilei  stated that \"as far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality.\"[15]Mathematics is essential in many fields, including natural science, engineering, medicine, finance and the social sciences. Applied mathematics has led to entirely new mathematical disciplines, such as statistics and game theory. Mathematicians also engage in pure mathematics, or mathematics for its own sake, without having any application in mind. There is no clear line separating pure and applied mathematics, and practical applications for what began as pure mathematics are often discovered.[16]The history of mathematics can be seen as an ever-increasing series of abstractions. The first abstraction, which is shared by many animals,[17] was probably that of numbers: the realization that a collection of two apples and a collection of two oranges  have something in common, namely quantity of their members.As evidenced by tallies found on bone, in addition to recognizing how to count physical objects, prehistoric peoples may have also recognized how to count abstract quantities, like time\u00a0\u2013 days, seasons, years.[18]Evidence for more complex mathematics does not appear until around 3000\u00a0BC, when the Babylonians and Egyptians began using arithmetic, algebra and geometry for taxation and other financial calculations, for building and construction, and for astronomy.[19] The earliest uses of mathematics were in trading, land measurement, painting and weaving patterns and the recording of time.In Babylonian mathematics, elementary arithmetic  first appears in the archaeological record. Numeracy pre-dated writing and numeral systems have been many and diverse, with the first known written numerals created by Egyptians in Middle Kingdom texts such as the Rhind Mathematical Papyrus.[citation needed]Between 600 and 300\u00a0BC the Ancient Greeks began a systematic study of mathematics in its own right with Greek mathematics.[20]During the Golden Age of Islam, especially during the 9th and 10th\u00a0centuries, mathematics saw many important innovations building on Greek mathematics: most of them include the contributions from Persian mathematicians such as Al-Khwarismi, Omar Khayyam and Sharaf al-D\u012bn al-\u1e6c\u016bs\u012b.Mathematics has since been greatly extended, and there has been a fruitful interaction between mathematics and science, to the benefit of both. Mathematical discoveries continue to be made today. According to Mikhail B. Sevryuk, in the January\u00a02006 issue of the Bulletin of the American Mathematical Society, \"The number of papers and books included in the Mathematical Reviews database since 1940  is now more than 1.9\u00a0million, and more than 75\u00a0thousand items are added to the database each year. The overwhelming majority of works in this ocean contain new mathematical theorems and their proofs.\"[21]The word mathematics comes from Ancient Greek \u03bc\u03ac\u03b8\u03b7\u03bc\u03b1 , Latin: ars mathematica, meant \"the mathematical art\".Similarly, one of the two main schools of thought in Pythagoreanism was known as the math\u0113matikoi \u2014which at the time meant \"teachers\" rather than \"mathematicians\" in the modern sense.In Latin, and in English until around 1700, the term mathematics more commonly meant \"astrology\"  rather than \"mathematics\"; the meaning gradually changed to its present one from about 1500 to 1800. This has resulted in several mistranslations. For example, Saint Augustine's warning that Christians should beware of mathematici, meaning astrologers, is sometimes mistranslated as a condemnation of mathematicians.[24]The apparent plural form in English, like the French plural form les math\u00e9matiques  and formed the noun mathematics anew, after the pattern of physics and metaphysics, which were inherited from Greek.[25] In English, the noun mathematics takes a singular verb. It is often shortened to maths or, in English-speaking North America, math.[26]Aristotle defined mathematics as \"the science of quantity\", and this definition prevailed until the 18th century.[27] Starting in the 19th\u00a0century, when the study of mathematics increased in rigor and began to address abstract topics such as group theory and projective geometry, which have no clear-cut relation to quantity and measurement, mathematicians and philosophers began to propose a variety of new definitions.[28] Some of these definitions emphasize the deductive character of much of mathematics, some emphasize its abstractness, some emphasize certain topics within mathematics. Today, no consensus on the definition of mathematics prevails, even among professionals.[6] There is not even consensus on whether mathematics is an art or a science.[7] A great many professional mathematicians take no interest in a definition of mathematics, or consider it undefinable.[6] Some just say, \"Mathematics is what mathematicians do.\"[6]Three leading types of definition of mathematics are called logicist, intuitionist, and formalist, each reflecting a different philosophical school of thought.[29] All have severe problems, none has widespread acceptance, and no reconciliation seems possible.[29]An early definition of mathematics in terms of logic was Benjamin Peirce's \"the science that draws necessary conclusions\" .[31]Intuitionist definitions, developing from the philosophy of mathematician L.E.J. Brouwer, identify mathematics with certain mental phenomena. An example of an intuitionist definition is \"Mathematics is the mental activity which consists in carrying out constructs one after the other.\"[29] A peculiarity of intuitionism is that it rejects some mathematical ideas considered valid according to other definitions. In particular, while other philosophies of mathematics allow objects that can be proved to exist even though they cannot be constructed, intuitionism allows only mathematical objects that one can actually construct.Formalist definitions identify mathematics with its symbols and the rules for operating on them. Haskell Curry defined mathematics simply as \"the science of formal systems\".[32] A formal system is a set of symbols, or tokens, and some rules telling how the tokens may be combined into formulas. In formal systems, the word axiom has a special meaning, different from the ordinary meaning of \"a self-evident truth\". In formal systems, an axiom is a combination of tokens that is included in a given formal system without needing to be derived using the rules of the system.The German mathematician Carl Friedrich Gauss referred to mathematics as \"the Queen of the Sciences\".[12] More recently, Marcus du Sautoy has called mathematics \"the Queen of Science\u00a0... the main driving force behind scientific discovery\".[33] In the original Latin Regina Scientiarum, as well as in German K\u00f6nigin der Wissenschaften, the word corresponding to science means a \"field of knowledge\", and this was the original meaning of \"science\" in English, also; mathematics is in this sense a field of knowledge. The specialization restricting the meaning of \"science\" to natural science follows the rise of Baconian science, which contrasted \"natural science\" to scholasticism, the Aristotelean method of inquiring from first principles. The role of empirical experimentation and observation is negligible in mathematics, compared to natural sciences such as biology, chemistry, or physics. Albert Einstein stated that \"as far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality.\"[15]Many philosophers believe that mathematics is not experimentally falsifiable, and thus not a science according to the definition of Karl Popper.[34] However, in the 1930s G\u00f6del's incompleteness theorems convinced many mathematicians[who?] that mathematics cannot be reduced to logic alone, and Karl Popper concluded that \"most mathematical theories are, like those of physics and biology, hypothetico-deductive: pure mathematics therefore turns out to be much closer to the natural sciences whose hypotheses are conjectures, than it seemed even recently.\"[35] Other thinkers, notably Imre Lakatos, have applied a version of falsificationism to mathematics itself.[36][37]An alternative view is that certain scientific fields  sciences. Experimental mathematics continues to grow in importance within mathematics, and computation and simulation are playing an increasing role in both the sciences and mathematics.The opinions of mathematicians on this matter are varied. Many mathematicians[38] feel that to call their area a science is to downplay the importance of its aesthetic side, and its history in the traditional seven liberal arts; others[who?] feel that to ignore its connection to the sciences is to turn a blind eye to the fact that the interface between mathematics and its applications in science and engineering has driven much development in mathematics. One way this difference of viewpoint plays out is in the philosophical debate as to whether mathematics is created . It is common to see universities divided into sections that include a division of Science and Mathematics, indicating that the fields are seen as being allied but that they do not coincide. In practice, mathematicians are typically grouped with scientists at the gross level but separated at finer levels. This is one of many issues considered in the philosophy of mathematics.[citation needed]Mathematics arises from many different kinds of problems. At first these were found in commerce, land measurement, architecture and later astronomy; today, all sciences suggest problems studied by mathematicians, and many problems arise within mathematics itself. For example, the physicist Richard Feynman invented the path integral formulation of quantum mechanics using a combination of mathematical reasoning and physical insight, and today's string theory, a still-developing scientific theory which attempts to unify the four fundamental forces of nature, continues to inspire new mathematics.[39]Some mathematics is relevant only in the area that inspired it, and is applied to solve further problems in that area. But often mathematics inspired by one area proves useful in many areas, and joins the general stock of mathematical concepts. A distinction is often made between pure mathematics and applied mathematics. However pure mathematics topics often turn out to have applications, e.g. number theory in cryptography. This remarkable fact, that even the \"purest\" mathematics often turns out to have practical applications, is what Eugene Wigner has called \"the unreasonable effectiveness of mathematics\".[40] As in most areas of study, the explosion of knowledge in the scientific age has led to specialization: there are now hundreds of specialized areas in mathematics and the latest Mathematics Subject Classification runs to 46\u00a0pages.[41] Several areas of applied mathematics have merged with related traditions outside of mathematics and become disciplines in their own right, including statistics, operations research, and computer science.For those who are mathematically inclined, there is often a definite aesthetic aspect to much of mathematics. Many mathematicians talk about the elegance of mathematics, its intrinsic aesthetics and inner beauty. Simplicity and generality are valued. There is beauty in a simple and elegant proof, such as Euclid's proof that there are infinitely many prime numbers, and in an elegant numerical method that speeds calculation, such as the fast Fourier transform. G.H. Hardy in A Mathematician's Apology expressed the belief that these aesthetic considerations are, in themselves, sufficient to justify the study of pure mathematics. He identified criteria such as significance, unexpectedness, inevitability, and economy as factors that contribute to a mathematical aesthetic.[42] Mathematicians often strive to find proofs that are particularly elegant, proofs from \"The Book\" of God according to Paul Erd\u0151s.[43][44] The popularity of recreational mathematics is another sign of the pleasure many find in solving mathematical questions.Most of the mathematical notation in use today was not invented until the 16th century.[45] Before that, mathematics was written out in words, limiting mathematical discovery.[46] Euler  with the physical object it corresponds to, mathematical symbols are abstract, lacking any physical analog.[48] Mathematical symbols are also more highly encrypted than regular words, meaning a single symbol can encode a number of different operations or ideas.[49]Mathematical language can be difficult to understand for beginners because even common terms, such as or and only, have a more precise meaning than they have in everyday speech, and other terms such as open and field refer to specific mathematical ideas, not covered by their laymen's meanings. Mathematical language also includes many technical terms such as homeomorphism and integrable that have no meaning outside of mathematics. Additionally, shorthand phrases such as iff for \"if and only if\" belong to mathematical jargon. There is a reason for special notation and technical vocabulary: mathematics requires more precision than everyday speech. Mathematicians refer to this precision of language and logic as \"rigor\".Mathematical proof is fundamentally a matter of rigor. Mathematicians want their theorems to follow from axioms by means of systematic reasoning. This is to avoid mistaken \"theorems\", based on fallible intuitions, of which many instances have occurred in the history of the subject.[b] The level of rigor expected in mathematics has varied over time: the Greeks expected detailed arguments, but at the time of Isaac Newton the methods employed were less rigorous. Problems inherent in the definitions used by Newton would lead to a resurgence of careful analysis and formal proof in the 19th\u00a0century. Misunderstanding the rigor is a cause for some of the common misconceptions of mathematics. Today, mathematicians continue to argue among themselves about computer-assisted proofs. Since large computations are hard to verify, such proofs may not be sufficiently rigorous.[50]Axioms in traditional thought were \"self-evident truths\", but that conception is problematic.[51] At a formal level, an axiom is just a string of symbols, which has an intrinsic meaning only in the context of all derivable formulas of an axiomatic system. It was the goal of Hilbert's program to put all of mathematics on a firm axiomatic basis, but according to G\u00f6del's incompleteness theorem every  nothing but set theory in some axiomatization, in the sense that every mathematical statement or proof could be cast into formulas within set theory.[52]Mathematics can, broadly speaking, be subdivided into the study of quantity, structure, space, and change , and more recently to the rigorous study of uncertainty. While some areas might seem unrelated, the Langlands program has found connections between areas previously thought unconnected, such as Galois groups, Riemann surfaces and number theory.In order to clarify the foundations of mathematics, the fields of mathematical logic and set theory were developed. Mathematical logic includes the mathematical study of logic and the applications of formal logic to other areas of mathematics; set theory is the branch of mathematics that studies sets or collections of objects. Category theory, which deals in an abstract way with mathematical structures and relationships between them, is still in development. The phrase \"crisis of foundations\" describes the search for a rigorous foundation for mathematics that took place from approximately 1900 to 1930.[53] Some disagreement about the foundations of mathematics continues to the present day. The crisis of foundations was stimulated by a number of controversies at the time, including the controversy over Cantor's set theory and the Brouwer\u2013Hilbert controversy.Mathematical logic is concerned with setting mathematics within a rigorous axiomatic framework, and studying the implications of such a framework. As such, it is home to G\u00f6del's incompleteness theorems which . Whatever finite collection of number-theoretical axioms is taken as a foundation, G\u00f6del showed how to construct a formal statement that is a true number-theoretical fact, but which does not follow from those axioms. Therefore, no formal system is a complete axiomatization of full number theory. Modern logic is divided into recursion theory, model theory, and proof theory, and is closely linked to theoretical computer science,[citation needed] as well as to category theory. In the context of recursion theory, the impossibility of a full axiomatization of number theory can also be formally demonstrated as a consequence of the MRDP theorem.Theoretical computer science includes computability theory, computational complexity theory, and information theory. Computability theory examines the limitations of various theoretical models of the computer, including the most well-known model\u00a0\u2013 the Turing machine. Complexity theory is the study of tractability by computer; some problems, although theoretically solvable by computer, are so expensive in terms of time or space that solving them is likely to remain practically unfeasible, even with the rapid advancement of computer hardware. A famous problem is the \"P = NP?\" problem, one of the Millennium Prize Problems.[54] Finally, information theory is concerned with the amount of data that can be stored on a given medium, and hence deals with concepts such as compression and entropy.The study of quantity starts with numbers, first the familiar natural numbers and integers  and arithmetical operations on them, which are characterized in arithmetic. The deeper properties of integers are studied in number theory, from which come such popular results as Fermat's Last Theorem. The twin prime conjecture and Goldbach's conjecture are two unsolved problems in number theory.As the number system is further developed, the integers are recognized as a subset of the rational numbers . These, in turn, are contained within the real numbers, which are used to represent continuous quantities. Real numbers are generalized to complex numbers. These are the first steps of a hierarchy of numbers that goes on to include quaternions and octonions. Consideration of the natural numbers also leads to the transfinite numbers, which formalize the concept of \"infinity\". According to the fundamental theorem of algebra all solutions of equations in one unknown with complex coefficients are complex numbers, regardless of degree. Another area of study is the size of sets, which is described with the cardinal numbers. These include the aleph numbers, which allow meaningful comparison of the size of infinitely large sets.Many mathematical objects, such as sets of numbers and functions, exhibit internal structure as a consequence of operations or relations that are defined on the set. Mathematics then studies properties of those sets that can be expressed in terms of that structure; for instance number theory studies properties of the set of integers that can be expressed in terms of arithmetic operations. Moreover, it frequently happens that different such structured sets  constitute the domain of abstract algebra.By its great generality, abstract algebra can often be applied to seemingly unrelated problems; for instance a number of ancient problems concerning compass and straightedge constructions were finally solved using Galois theory, which involves field theory and group theory. Another example of an algebraic theory is linear algebra, which is the general study of vector spaces, whose elements called vectors have both quantity and direction, and can be used to model  points in space. This is one example of the phenomenon that the originally unrelated areas of geometry and algebra have very strong interactions in modern mathematics. Combinatorics studies ways of enumerating the number of objects that fit a given structure.The study of space originates with geometry\u00a0\u2013 in particular, Euclidean geometry, which combines space and numbers, and encompasses the well-known Pythagorean theorem. Trigonometry is the branch of mathematics that deals with relationships between the sides and the angles of triangles and with the trigonometric functions. The modern study of space generalizes these ideas to include higher-dimensional geometry, non-Euclidean geometries  and topology. Quantity and space both play a role in analytic geometry, differential geometry, and algebraic geometry. Convex and discrete geometry were developed to solve problems in number theory and functional analysis but now are pursued with an eye on applications in optimization and computer science. Within differential geometry are the concepts of fiber bundles and calculus on manifolds, in particular, vector and tensor calculus. Within algebraic geometry is the description of geometric objects as solution sets of polynomial equations, combining the concepts of quantity and space, and also the study of topological groups, which combine structure and space. Lie groups are used to study space, structure, and change. Topology in all its many ramifications may have been the greatest growth area in 20th-century mathematics; it includes point-set topology, set-theoretic topology, algebraic topology and differential topology. In particular, instances of modern-day topology are metrizability theory, axiomatic set theory, homotopy theory, and Morse theory. Topology also includes the now solved Poincar\u00e9 conjecture, and the still unsolved areas of the Hodge conjecture. Other results in geometry and topology, including the four color theorem and Kepler conjecture, have been proved only with the help of computers.Understanding and describing change is a common theme in the natural sciences, and calculus was developed as a powerful tool to investigate it. Functions arise here, as a central concept describing a changing quantity. The rigorous study of real numbers and functions of a real variable is known as real analysis, with complex analysis the equivalent field for the complex numbers. Functional analysis focuses attention on  spaces of functions. One of many applications of functional analysis is quantum mechanics. Many problems lead naturally to relationships between a quantity and its rate of change, and these are studied as differential equations. Many phenomena in nature can be described by dynamical systems; chaos theory makes precise the ways in which many of these systems exhibit unpredictable yet still deterministic behavior.Applied mathematics concerns itself with mathematical methods that are typically used in science, engineering, business, and industry. Thus, \"applied mathematics\" is a mathematical science with specialized knowledge. The term applied mathematics also describes the professional specialty in which mathematicians work on practical problems; as a profession focused on practical problems, applied mathematics focuses on the \"formulation, study, and use of mathematical models\" in science, engineering, and other areas of mathematical practice.In the past, practical applications have motivated the development of mathematical theories, which then became the subject of study in pure mathematics, where mathematics is developed primarily for its own sake. Thus, the activity of applied mathematics is vitally connected with research in pure mathematics.Applied mathematics has significant overlap with the discipline of statistics, whose theory is formulated mathematically, especially with probability theory. Statisticians . When reconsidering data from experiments and samples or when analyzing data from observational studies, statisticians \"make sense of the data\" using the art of modelling and the theory of inference\u00a0\u2013 with model selection and estimation; the estimated models and consequential predictions should be tested on new data.[c]Statistical theory studies decision problems such as minimizing the risk  of a statistical action, such as using a procedure in, for example, parameter estimation, hypothesis testing, and selecting the best. In these traditional areas of mathematical statistics, a statistical-decision problem is formulated by minimizing an objective function, like expected loss or cost, under specific constraints: For example, designing a survey often involves minimizing the cost of estimating a population mean with a given level of confidence.[56] Because of its use of optimization, the mathematical theory of statistics shares concerns with other decision sciences, such as operations research, control theory, and mathematical economics.[57]Computational mathematics proposes and studies methods for solving mathematical problems that are typically too large for human numerical capacity. Numerical analysis studies methods for problems in analysis using functional analysis and approximation theory; numerical analysis includes the study of approximation and discretization broadly with special concern for rounding errors. Numerical analysis and, more broadly, scientific computing also study non-analytic topics of mathematical science, especially algorithmic matrix and graph theory. Other areas of computational mathematics include computer algebra and symbolic computation.Arguably the most prestigious award in mathematics is the Fields Medal,[58][59] established in 1936 and awarded every four years  to as many as four individuals. The Fields Medal is often considered a mathematical equivalent to the Nobel Prize.The Wolf Prize in Mathematics, instituted in 1978, recognizes lifetime achievement, and another major international award, the Abel Prize, was instituted in 2003. The Chern Medal was introduced in 2010 to recognize lifetime achievement. These accolades are awarded in recognition of a particular body of work, which may be innovational, or provide a solution to an outstanding problem in an established field.A famous list of 23 open problems, called \"Hilbert's problems\", was compiled in 1900 by German mathematician David Hilbert. This list achieved great celebrity among mathematicians, and at least nine of the problems have now been solved. A new list of seven important problems, titled the \"Millennium Prize Problems\", was published in 2000. A solution to each of these problems carries a $1\u00a0million reward, and only one  is duplicated in Hilbert's problems."], "Statistics": ["Statistics is a branch of mathematics dealing with the collection, analysis, interpretation, presentation, and organization of data.[1][2] In applying statistics to, for example, a scientific, industrial, or social problem, it is conventional to begin with a statistical population or a statistical model process to be studied. Populations can be diverse topics such as \"all people living in a country\" or \"every atom composing a crystal\". Statistics deals with all aspects of data including the planning of data collection in terms of the design of surveys and experiments.[1] See glossary of probability and statistics.When census data cannot be collected, statisticians collect data by developing specific experiment designs and survey samples. Representative sampling assures that inferences and conclusions can reasonably extend from the sample to the population as a whole. An experimental study involves taking measurements of the system under study, manipulating the system, and then taking additional measurements using the same procedure to determine if the manipulation has modified the values of the measurements. In contrast, an observational study does not involve experimental manipulation.Two main statistical methods are used in data analysis: descriptive statistics, which summarize data from a sample using indexes such as the mean or standard deviation, and inferential statistics, which draw conclusions from data that are subject to random variation  characterizes the extent to which members of the distribution depart from its center and each other. Inferences on mathematical statistics are made under the framework of probability theory, which deals with the analysis of random phenomena.A standard statistical procedure involves the test of the relationship between two statistical data sets, or a data set and synthetic data drawn from idealized model. A hypothesis is proposed for the statistical relationship between the two data sets, and this is compared as an alternative to an idealized null hypothesis of no relationship between two data sets. Rejecting or disproving the null hypothesis is done using statistical tests that quantify the sense in which the null can be proven false, given the data that are used in the test. Working from a null hypothesis, two basic forms of error are recognized: Type I errors .[4] Multiple problems have come to be associated with this framework: ranging from obtaining a sufficient sample size to specifying an adequate null hypothesis.[citation needed]Measurement processes that generate statistical data are also subject to error. Many of these errors are classified as random  can also be important. The presence of missing data or censoring may result in biased estimates and specific techniques have been developed to address these problems.Statistics can be said to have begun in ancient civilization, going back at least to the 5th century BC, but it was not until the 18th century that it started to draw more heavily from calculus and probability theory. In more recent years statistics has relied more on statistical software to produce tests such as descriptive analysis.[5]Some definitions are:Statistics is a mathematical body of science that pertains to the collection, analysis, interpretation or explanation, and presentation of data,[8] or as a branch of mathematics.[9] Some consider statistics to be a distinct mathematical science rather than a branch of mathematics. While many scientific investigations make use of data, statistics is concerned with the use of data in the context of uncertainty and decision making in the face of uncertainty.[10][11]Mathematical statistics is the application of mathematics to statistics. Mathematical techniques used for this include mathematical analysis, linear algebra, stochastic analysis, differential equations, and measure-theoretic probability theory.[12][13]In applying statistics to a problem, it is common practice to start with a population or process to be studied. Populations can be diverse topics such as \"all persons living in a country\" or \"every atom composing a crystal\".Ideally, statisticians compile data about the entire population .When a census is not feasible, a chosen subset of the population called a sample is studied. Once a sample that is representative of the population is determined, data is collected for the sample members in an observational or experimental setting. Again, descriptive statistics can be used to summarize the sample data. However, the drawing of the sample has been subject to an element of randomness, hence the established numerical descriptors from the sample are also due to uncertainty. To still draw meaningful conclusions about the entire population, inferential statistics is needed. It uses patterns in the sample data to draw inferences about the population represented, accounting for randomness. These inferences may take the form of: answering yes/no questions about the data . Inference can extend to forecasting, prediction and estimation of unobserved values either in or associated with the population being studied; it can include extrapolation and interpolation of time series or spatial data, and can also include data mining.When full census data cannot be collected, statisticians collect sample data by developing specific experiment designs and survey samples. Statistics itself also provides tools for prediction and forecasting through statistical models. The idea of making inferences based on sampled data began around the mid-1600's in connection with estimating populations and developing precursors of life insurance.[14]To use a sample as a guide to an entire population, it is important that it truly represents the overall population. Representative sampling assures that inferences and conclusions can safely extend from the sample to the population as a whole. A major problem lies in determining the extent that the sample chosen is actually representative. Statistics offers methods to estimate and correct for any bias within the sample and data collection procedures. There are also methods of experimental design for experiments that can lessen these issues at the outset of a study, strengthening its capability to discern truths about the population.Sampling theory is part of the mathematical discipline of probability theory. Probability is used in mathematical statistics to study the sampling distributions of sample statistics and, more generally, the properties of statistical procedures. The use of any statistical method is valid when the system or population under consideration satisfies the assumptions of the method. The difference in point of view between classic probability theory and sampling theory is, roughly, that probability theory starts from the given parameters of a total population to deduce probabilities that pertain to samples. Statistical inference, however, moves in the opposite direction\u2014inductively inferring from samples to the parameters of a larger or total population.A common goal for a statistical research project is to investigate causality, and in particular to draw a conclusion on the effect of changes in the values of predictors or independent variables on dependent variables. There are two major types of causal statistical studies: experimental studies and observational studies. In both types of studies, the effect of differences of an independent variable  that produce consistent estimators.The basic steps of a statistical experiment are:Experiments on human behavior have special concerns. The famous Hawthorne study examined changes to the working environment at the Hawthorne plant of the Western Electric Company. The researchers were interested in determining whether increased illumination would increase the productivity of the assembly line workers. The researchers first measured the productivity in the plant, then modified the illumination in an area of the plant and checked if the changes in illumination affected productivity. It turned out that productivity indeed improved  changed due to observation itself. Those in the Hawthorne study became more productive not because the lighting was changed but because they were being observed.[16]An example of an observational study is one that explores the association between smoking and lung cancer. This type of study typically uses a survey to collect observations about the area of interest and then performs statistical analysis. In this case, the researchers would collect observations of both smokers and non-smokers, perhaps through a cohort study, and then look for the number of cases of lung cancer in each group.[17] A case-control study is another type of observational study in which people with and without the outcome of interest  are invited to participate and their exposure histories are collected.Various attempts have been made to produce a taxonomy of levels of measurement. The psychophysicist Stanley Smith Stevens defined nominal, ordinal, interval, and ratio scales. Nominal measurements do not have meaningful rank order among values, and permit any one-to-one transformation. Ordinal measurements have imprecise differences between consecutive values, but have a meaningful order to those values, and permit any order-preserving transformation. Interval measurements have meaningful distances between measurements defined, but the zero value is arbitrary , and permit any linear transformation. Ratio measurements have both a meaningful zero value and the distances between different measurements defined, and permit any rescaling transformation.Because variables conforming only to nominal or ordinal measurements cannot be reasonably measured numerically, sometimes they are grouped together as categorical variables, whereas ratio and interval measurements are grouped together as quantitative variables, which can be either discrete or continuous, due to their numerical nature. Such distinctions can often be loosely correlated with data type in computer science, in that dichotomous categorical variables may be represented with the Boolean data type, polytomous categorical variables with arbitrarily assigned integers in the integral data type, and continuous variables with the real data type involving floating point computation. But the mapping of computer science data types to statistical data types depends on which categorization of the latter is being implemented.Other categorizations have been proposed. For example, Mosteller and Tukey .[21]The issue of whether or not it is appropriate to apply different kinds of statistical methods to data obtained from different kinds of measurement procedures is complicated by issues concerning the transformation of variables and the precise interpretation of research questions. \"The relationship between the data and what they describe merely reflects the fact that certain kinds of statistical statements may have truth values which are not invariant under some transformations. Whether or not a transformation is sensible to contemplate depends on the question one is trying to answer\" .[22]Consider independent identically distributed  random variables with a given probability distribution: standard statistical inference and estimation theory defines a random sample as the random vector given by the column vector of these IID variables.[23] The population being examined is described by a probability distribution that may have unknown parameters.A statistic is a random variable that is a function of the random sample, but not a function of unknown parameters. The probability distribution of the statistic, though, may have unknown parameters.Consider now a function of the unknown parameter: an estimator is a statistic used to estimate such function. Commonly used estimators include sample mean, unbiased sample variance and sample covariance.A random variable that is a function of the random sample and of the unknown parameter, but whose probability distribution does not depend on the unknown parameter is called a pivotal quantity or pivot. Widely used pivots include the z-score, the chi square statistic and Student's t-value.Between two estimators of a given parameter, the one with lower mean squared error is said to be more efficient. Furthermore, an estimator is said to be unbiased if its expected value is equal to the true value of the unknown parameter being estimated, and asymptotically unbiased if its expected value converges at the limit to the true value of such parameter.Other desirable properties for estimators include: UMVUE estimators that have the lowest variance for all possible values of the parameter to be estimated  and consistent estimators which converges in probability to the true value of such parameter.This still leaves the question of how to obtain estimators in a given situation and carry the computation, several methods have been proposed: the method of moments, the maximum likelihood method, the least squares method and the more recent method of estimating equations.Interpretation of statistical information can often involve the development of a null hypothesis which is usually  that no relationship exists among variables or that no change occurred over time.[24][25]The best illustration for a novice is the predicament encountered by a criminal trial. The null hypothesis, H0, asserts that the defendant is innocent, whereas the alternative hypothesis, H1, asserts that the defendant is guilty. The indictment comes because of suspicion of the guilt. The H0  stands in opposition to H1 and is maintained unless H1 is supported by evidence \"beyond a reasonable doubt\". However, \"failure to reject H0\" in this case does not imply innocence, but merely that the evidence was insufficient to convict. So the jury does not necessarily accept H0 but fails to reject H0. While one can not \"prove\" a null hypothesis, one can test how close it is to being true with a power test, which tests for type II errors.What statisticians call an alternative hypothesis is simply a hypothesis that contradicts the null hypothesis.Working from a null hypothesis, two basic forms of error are recognized:Standard deviation refers to the extent to which individual observations in a sample differ from a central value, such as the sample or population mean, while Standard error refers to an estimate of difference between sample mean and population mean.A statistical error is the amount by which an observation differs from its expected value, a residual is the amount an observation differs from the value the estimator of the expected value assumes on a given sample .Mean squared error is used for obtaining efficient estimators, a widely used class of estimators. Root mean square error is simply the square root of mean squared error.Many statistical methods seek to minimize the residual sum of squares, and these are called \"methods of least squares\" in contrast to Least absolute deviations. The latter gives equal weight to small and big errors, while the former gives more weight to large errors. Residual sum of squares is also differentiable, which provides a handy property for doing regression. Least squares applied to linear regression is called ordinary least squares method and least squares applied to nonlinear regression is called non-linear least squares. Also in a linear regression model the non deterministic part of the model is called error term, disturbance or more simply noise. Both linear regression and non-linear regression are addressed in polynomial least squares, which also describes the variance in a prediction of the dependent variable  curve.Measurement processes that generate statistical data are also subject to error. Many of these errors are classified as random  can also be important. The presence of missing data or censoring may result in biased estimates and specific techniques have been developed to address these problems.[26]Most studies only sample part of a population, so results don't fully represent the whole population. Any estimates obtained from the sample only approximate the population value. Confidence intervals allow statisticians to express how closely the sample estimate matches the true value in the whole population. Often they are expressed as 95% confidence intervals. Formally, a 95% confidence interval for a value is a range where, if the sampling and analysis were repeated under the same conditions  value in 95% of all possible cases. This does not imply that the probability that the true value is in the confidence interval is 95%. From the frequentist perspective, such a claim does not even make sense, as the true value is not a random variable. Either the true value is or is not within the given interval. However, it is true that, before any data are sampled and given a plan for how to construct the confidence interval, the probability is 95% that the yet-to-be-calculated interval will cover the true value: at this point, the limits of the interval are yet-to-be-observed random variables. One approach that does yield an interval that can be interpreted as having a given probability of containing the true value is to use a credible interval from Bayesian statistics: this approach depends on a different way of interpreting what is meant by \"probability\", that is as a Bayesian probability.In principle confidence intervals can be symmetrical or asymmetrical. An interval can be asymmetrical because it works as lower or upper bound for a parameter , but it can also be asymmetrical because the two sided interval is built violating symmetry around the estimate. Sometimes the bounds for a confidence interval are reached asymptotically and these are used to approximate the true bounds.Statistics rarely give a simple Yes/No type answer to the question under analysis. Interpretation often comes down to the level of statistical significance applied to the numbers and often refers to the probability of a value accurately rejecting the null hypothesis .The standard approach[23] is to test a null hypothesis against an alternative hypothesis. A critical region is the set of values of the estimator that leads to refuting the null hypothesis. The probability of type I error is therefore the probability that the estimator belongs to the critical region given that null hypothesis is true  and the probability of type II error is the probability that the estimator doesn't belong to the critical region given that the alternative hypothesis is true. The statistical power of a test is the probability that it correctly rejects the null hypothesis when the null hypothesis is false.Referring to statistical significance does not necessarily mean that the overall result is significant in real world terms. For example, in a large study of a drug it may be shown that the drug has a statistically significant but very small beneficial effect, such that the drug is unlikely to help the patient noticeably.While in principle the acceptable level of statistical significance may be subject to debate, the p-value is the smallest significance level that allows the test to reject the null hypothesis. This is logically equivalent to saying that the p-value is the probability, assuming the null hypothesis is true, of observing a result at least as extreme as the test statistic. Therefore, the smaller the p-value, the lower the probability of committing type I error.Some problems are usually associated with this framework :Some well-known statistical tests and procedures are:Misuse of statistics can produce subtle, but serious errors in description and interpretation\u2014subtle in the sense that even experienced professionals make such errors, and serious in the sense that they can lead to devastating decision errors. For instance, social policy, medical practice, and the reliability of structures like bridges all rely on the proper use of statistics.Even when statistical techniques are correctly applied, the results can be difficult to interpret for those lacking expertise. The statistical significance of a trend in the data\u2014which measures the extent to which a trend could be caused by random variation in the sample\u2014may or may not agree with an intuitive sense of its significance. The set of basic statistical skills  that people need to deal with information in their everyday lives properly is referred to as statistical literacy.There is a general perception that statistical knowledge is all-too-frequently intentionally misused by finding ways to interpret only the data that are favorable to the presenter.[28] A mistrust and misunderstanding of statistics is associated with the quotation, \"There are three kinds of lies: lies, damned lies, and statistics\". Misuse of statistics can be both inadvertent and intentional, and the book How to Lie with Statistics[28] outlines a range of considerations. In an attempt to shed light on the use and misuse of statistics, reviews of statistical techniques used in particular fields are conducted .[29]Ways to avoid misuse of statistics include using proper diagrams and avoiding bias.[30] Misuse can occur when conclusions are overgeneralized and claimed to be representative of more than they really are, often by either deliberately or unconsciously overlooking sampling bias.[31] Bar graphs are arguably the easiest diagrams to use and understand, and they can be made either by hand or with simple computer programs.[30] Unfortunately, most people do not look for bias or errors, so they are not noticed. Thus, people may often believe that something is true even if it is not well represented.[31] To make data gathered from statistics believable and accurate, the sample taken must be representative of the whole.[32] According to Huff, \"The dependability of a sample can be destroyed by [bias]... allow yourself some degree of skepticism.\"[33]To assist in the understanding of statistics Huff proposed a series of questions to be asked in each case:[34]The concept of correlation is particularly noteworthy for the potential confusion it can cause. Statistical analysis of a data set often reveals that two variablesStatistical methods date back at least to the 5th century BC.[citation needed]Some scholars pinpoint the origin of statistics to 1663, with the publication of Natural and Political Observations upon the Bills of Mortality by John Graunt.[35] Early applications of statistical thinking revolved around the needs of states to base policy on demographic and economic data, hence its stat- etymology. The scope of the discipline of statistics broadened in the early 19th century to include the collection and analysis of data in general. Today, statistics is widely employed in government, business, and natural and social sciences.Its mathematical foundations were laid in the 17th century with the development of the probability theory by Gerolamo Cardano, Blaise Pascal and Pierre de Fermat. Mathematical probability theory arose from the study of games of chance, although the concept of probability was already examined in medieval law and by philosophers such as Juan Caramuel.[36] The method of least squares was first described by Adrien-Marie Legendre in 1805.The modern field of statistics emerged in the late 19th and early 20th century in three stages.[37] The first wave, at the turn of the century, was led by the work of Francis Galton and Karl Pearson, who transformed statistics into a rigorous mathematical discipline used for analysis, not just in science, but in industry and politics as well. Galton's contributions included introducing the concepts of standard deviation, correlation, regression analysis and the application of these methods to the study of the variety of human characteristics\u2014height, weight, eyelash length among others.[38] Pearson developed the Pearson product-moment correlation coefficient, defined as a product-moment,[39] the method of moments for the fitting of distributions to samples and the Pearson distribution, among many other things.[40] Galton and Pearson founded Biometrika as the first journal of mathematical statistics and biostatistics , and the latter founded the world's first university statistics department at University College London.[41]Ronald Fisher coined the term null hypothesis during the Lady tasting tea experiment, which \"is never proved or established, but is possibly disproved, in the course of experimentation\".[42][43]The second wave of the 1910s and 20s was initiated by William Gosset, and reached its culmination in the insights of Ronald Fisher, who wrote the textbooks that were to define the academic discipline in universities around the world. Fisher's most important publications were his 1918 seminal paper The Correlation between Relatives on the Supposition of Mendelian Inheritance, which was the first to use the statistical term, variance, his classic 1925 work Statistical Methods for Research Workers and his 1935 The Design of Experiments,[44][45][46][47] where he developed rigorous design of experiments models. He originated the concepts of sufficiency, ancillary statistics, Fisher's linear discriminator and Fisher information.[48] In his 1930 book The Genetical Theory of Natural Selection he applied statistics to various biological concepts such as Fisher's principle[49]). Nevertheless, A. W. F. Edwards has remarked that it is \"probably the most celebrated argument in evolutionary biology\".[49] , the Fisherian runaway,[50][51][52][53][54][55] a concept in sexual selection about a positive feedback runaway affect found in evolution.The final wave, which mainly saw the refinement and expansion of earlier developments, emerged from the collaborative work between Egon Pearson and Jerzy Neyman in the 1930s. They introduced the concepts of \"Type II\" error, power of a test and confidence intervals. Jerzy Neyman in 1934 showed that stratified random sampling was in general a better method of estimation than purposive  sampling.[56]Today, statistical methods are applied in all fields that involve decision making, for making accurate inferences from a collated body of data and for making decisions in the face of uncertainty based on statistical methodology. The use of modern computers has expedited large-scale statistical computations, and has also made possible new methods that are impractical to perform manually. Statistics continues to be an area of active research, for example on the problem of how to analyze Big data.[57]\"Applied statistics\" comprises descriptive statistics and the application of inferential statistics.[58][59] Theoretical statistics concerns both the logical arguments underlying justification of approaches to statistical inference, as well encompassing mathematical statistics. Mathematical statistics includes not only the manipulation of probability distributions necessary for deriving results related to methods of estimation and inference, but also various aspects of computational statistics and the design of experiments.There are two applications for machine learning and data mining: data management and data analysis. Statistics tools are necessary for the data analysis.Statistics is applicable to a wide variety of academic disciplines, including natural and social sciences, government, and business. Statistical consultants can help organizations and companies that don't have in-house expertise relevant to their particular questions.The rapid and sustained increases in computing power starting from the second half of the 20th century have had a substantial impact on the practice of statistical science. Early statistical models were almost always from the class of linear models, but powerful computers, coupled with suitable numerical algorithms, caused an increased interest in nonlinear models  as well as the creation of new types, such as generalized linear models and multilevel models.Increased computing power has also led to the growing popularity of computationally intensive methods based on resampling, such as permutation tests and the bootstrap, while techniques such as Gibbs sampling have made use of Bayesian models more feasible. The computer revolution has implications for the future of statistics with new emphasis on \"experimental\" and \"empirical\" statistics. A large number of both general and special purpose statistical software are now available. Examples of available software capable of complex statistical computation include programs such as Mathematica, SAS, SPSS, and R.Traditionally, statistics was concerned with drawing inferences using a semi-standardized methodology that was \"required learning\" in most sciences. This has changed with use of statistics in non-inferential contexts. What was once considered a dry subject, taken in many fields as a degree-requirement, is now viewed enthusiastically.[according to whom?] Initially derided by some mathematical purists, it is now considered essential methodology in certain areas.Statistical techniques are used in a wide range of types of scientific and social research, including: biostatistics, computational biology, computational sociology, network biology, social science, sociology and social research. Some fields of inquiry use applied statistics so extensively that they have specialized terminology. These disciplines include:In addition, there are particular types of statistical analysis that have also developed their own specialised terminology and methodology:Statistics form a key basis tool in business and manufacturing as well. It is used to understand measurement systems variability, control processes , for summarizing data, and to make data-driven decisions. In these roles, it is a key tool, and perhaps the only reliable tool."], "Engineering and technology": ["Engineering is the creative application of science, mathematical methods, and empirical evidence to the innovation, design, construction, operation and maintenance of structures, machines, materials, devices, systems, processes, and organizations. The discipline of engineering encompasses a broad range of more specialized fields of engineering, each with a more specific emphasis on particular areas of applied mathematics, applied science, and types of application. See glossary of engineering.The term engineering is derived from the Latin ingenium, meaning \"cleverness\" and ingeniare, meaning \"to contrive, devise\".[1]The American Engineers' Council for Professional Development [2] has defined \"engineering\" as:Arthur M. Wellington , railway engineer and editor of Engineering News, put it more succintly:This is the source of the even more concise adage \"an engineer can do for a dollar what any fool can do for two.\"Engineering has existed since ancient times, when humans devised inventions such as the wedge, lever, wheel and pulley.The term engineering is derived from the word engineer, which itself dates back to 1390 when an engine'er . Notable examples of the obsolete usage which have survived to the present day are military engineering corps, e.g., the U.S. Army Corps of Engineers.The word \"engine\" itself is of even older origin, ultimately deriving from the Latin ingenium , meaning \"innate quality, especially mental power, hence a clever invention.\"[7]Later, as the design of civilian structures, such as bridges and buildings, matured as a technical discipline, the term civil engineering[4] entered the lexicon as a way to distinguish between those specializing in the construction of such non-military projects and those involved in the discipline of military engineering.The pyramids in Egypt, the Acropolis and the Parthenon in Greece, the Roman aqueducts, Via Appia and the Colosseum, Teotihuac\u00e1n, the Great Wall of China, the Brihadeeswarar Temple of Thanjavur, among many others, stand as a testament to the ingenuity and skill of ancient civil and military engineers. Other monuments, no longer standing, such as the Hanging Gardens of Babylon, and the Pharos of Alexandria were important engineering achievements of their time and were considered among the Seven Wonders of the Ancient World.The earliest civil engineer known by name is Imhotep.[4] As one of the officials of the Pharaoh, Djos\u00e8r, he probably designed and supervised the construction of the Pyramid of Djoser  at Saqqara in Egypt around 2630\u20132611 BC.[8] Ancient Greece developed machines in both civilian and military domains. The Antikythera mechanism, the first known mechanical computer,[9][10] and the mechanical inventions of Archimedes are examples of early mechanical engineering. Some of Archimedes' inventions as well as the Antikythera mechanism required sophisticated knowledge of differential gearing or epicyclic gearing, two key principles in machine theory that helped design the gear trains of the Industrial Revolution, and are still widely used today in diverse fields such as robotics and automotive engineering.[11]Ancient Chinese, Greek, Roman and Hungarian armies employed military machines and inventions such as artillery which was developed by the Greeks around the 4th century B.C.,[12] the trireme, the ballista and the catapult. In the Middle Ages, the trebuchet was developed.The first steam engine was built in 1698 by Thomas Savery.[13] The development of this device gave rise to the Industrial Revolution in the coming decades, allowing for the beginnings of mass production.With the rise of engineering as a profession in the 18th century, the term became more narrowly applied to fields in which mathematics and science were applied to these ends. Similarly, in addition to military and civil engineering, the fields then known as the mechanic arts became incorporated into engineering.The inventions of Thomas Newcomen and James Watt gave rise to modern mechanical engineering. The development of specialized machines and machine tools during the industrial revolution led to the rapid growth of mechanical engineering both in its birthplace Britain and abroad.[4]John Smeaton was the first self-proclaimed civil engineer and is often regarded as the \"father\" of civil engineering. He was an English civil engineer responsible for the design of bridges, canals, harbours, and lighthouses. He was also a capable mechanical engineer and an eminent physicist. Smeaton designed the third Eddystone Lighthouse  and developed a technique involving dovetailed blocks of granite in the building of the lighthouse. His lighthouse remained in use until 1877 and was dismantled and partially rebuilt at Plymouth Hoe where it is known as Smeaton's Tower. He is important in the history, rediscovery of, and development of modern cement, because he identified the compositional requirements needed to obtain \"hydraulicity\" in lime; work which led ultimately to the invention of Portland cement.The United States census of 1850 listed the occupation of \"engineer\" for the first time with a count of 2,000.[14] There were fewer than 50 engineering graduates in the U.S. before 1865. In 1870 there were a dozen U.S. mechanical engineering graduates, with that number increasing to 43 per year in 1875. In 1890, there were 6,000 engineers in civil, mining, mechanical and electrical.[15]There was no chair of applied mechanism and applied mechanics at Cambridge until 1875, and no chair of engineering at Oxford until 1907. Germany established technical universities earlier.[16]The foundations of electrical engineering in the 1800s included the experiments of Alessandro Volta, Michael Faraday, Georg Ohm and others and the invention of the electric telegraph in 1816 and the electric motor in 1872. The theoretical work of James Maxwell  and Heinrich Hertz in the late 19th century gave rise to the field of electronics. The later inventions of the vacuum tube and the transistor further accelerated the development of electronics to such an extent that electrical and electronics engineers currently outnumber their colleagues of any other engineering specialty.[4] Chemical engineering developed in the late nineteenth century.[4] Industrial scale manufacturing demanded new materials and new processes and by 1880 the need for large scale production of chemicals was such that a new industry was created, dedicated to the development and large scale manufacturing of chemicals in new industrial plants.[4] The role of the chemical engineer was the design of these chemical plants and processes.[4]Aeronautical engineering deals with aircraft design process design while aerospace engineering is a more modern term that expands the reach of the discipline by including spacecraft design. Its origins can be traced back to the aviation pioneers around the start of the 20th century although the work of Sir George Cayley has recently been dated as being from the last decade of the 18th century. Early knowledge of aeronautical engineering was largely empirical with some concepts and skills imported from other branches of engineering.[17]The first PhD in engineering  awarded in the United States went to Josiah Willard Gibbs at Yale University in 1863; it was also the second PhD awarded in science in the U.S.[18]Only a decade after the successful flights by the Wright brothers, there was extensive development of aeronautical engineering through development of military aircraft that were used in World War I. Meanwhile, research to provide fundamental background science continued by combining theoretical physics with experiments.In 1990, with the rise of computer technology, the first search engine was built by computer engineer Alan Emtage.Engineering is a broad discipline which is often broken down into several sub-disciplines. Although an engineer will usually be trained in a specific discipline, he or she may become multi-disciplined through experience. Engineering is often characterized as having four main branches:[19][20][21] chemical engineering, civil engineering, electrical engineering, and mechanical engineering.Chemical engineering is the application of physics, chemistry, biology, and engineering principles in order to carry out chemical processes on a commercial scale, such as the manufacture of commodity chemicals, specialty chemicals, petroleum refining, microfabrication, fermentation, and biomolecule production.Civil engineering is the design and construction of public and private works, such as infrastructure , bridges, tunnels, dams, and buildings.[22][23] Civil engineering is traditionally broken into a number of sub-disciplines, including structural engineering, environmental engineering, and surveying. It is traditionally considered to be separate from military engineering.[24]Electrical engineering is the design, study, and manufacture of various electrical and electronic systems, such as Broadcast engineering, electrical circuits, generators, motors, electromagnetic/electromechanical devices, electronic devices, electronic circuits, optical fibers, optoelectronic devices, computer systems, telecommunications, instrumentation, controls, and electronics.Mechanical engineering is the design and manufacture of physical or mechanical systems, such as power and energy systems, aerospace/aircraft products, weapon systems, transportation products, engines, compressors, powertrains, kinematic chains, vacuum technology, vibration isolation equipment, manufacturing, and mechatronics.Beyond these \"Big 4\", a number of other branches are recognized, though many can be thought of as sub-disciplines of the four major branches, or as cross-curricular disciplines among multiple. Historically, naval engineering and mining engineering were major branches. Other engineering fields sometimes included as major branches[citation needed] are manufacturing engineering, acoustical engineering, corrosion engineering, instrumentation and control, aerospace, automotive, computer, electronic, petroleum, environmental, systems, audio, software, architectural, agricultural, biosystems, biomedical,[25] geological, textile, industrial, materials,[26] and nuclear engineering.[27] These and other branches of engineering are represented in the 36 licensed member institutions of the UK Engineering Council.New specialties sometimes combine with the traditional fields and form new branches \u2013 for example, Earth systems engineering and management involves a wide range of subject areas including engineering studies, environmental science, engineering ethics and philosophy of engineering.One who practices engineering is called an engineer, and those licensed to do so may have more formal designations such as Professional Engineer, Chartered Engineer, Incorporated Engineer, Ingenieur, European Engineer, or Designated Engineering Representative.In the engineering design process, engineers apply mathematics and sciences such as physics to find novel solutions to problems or to improve existing solutions. More than ever, engineers are now required to have a proficient knowledge of relevant sciences for their design projects. As a result, many engineers continue to learn new material throughout their career.If multiple solutions exist, engineers weigh each design choice based on their merit and choose the solution that best matches the requirements. The crucial and unique task of the engineer is to identify, understand, and interpret the constraints on a design in order to yield a successful result. It is generally insufficient to build a technically successful product, rather, it must also meet further requirements.Constraints may include available resources, physical, imaginative or technical limitations, flexibility for future modifications and additions, and other factors, such as requirements for cost, safety, marketability, productivity, and serviceability. By understanding the constraints, engineers derive specifications for the limits within which a viable object or system may be produced and operated.A general methodology and epistemology of engineering can be inferred from the historical case studies and comments provided by Walter Vincenti.[28] Though Vincenti's case studies are from the domain of aeronautical engineering, his conclusions can be transferred into many other branches of engineering, too.According to Billy Vaughn Koen, the \"engineering method is the use of heuristics to cause the best change in a poorly understood situation within the available resources.\" Koen argues that the definition of what makes one an engineer should not be based on what he produces, but rather how he goes about it.[29]Engineers use their knowledge of science, mathematics, logic, economics, and appropriate experience or tacit knowledge to find suitable solutions to a problem. Creating an appropriate mathematical model of a problem often allows them to analyze it , and to test potential solutions.Usually, multiple reasonable solutions exist, so engineers must evaluate the different design choices on their merits and choose the solution that best meets their requirements. Genrich Altshuller, after gathering statistics on a large number of patents, suggested that compromises are at the heart of \"low-level\" engineering designs, while at a higher level the best design is one which eliminates the core contradiction causing the problem.Engineers typically attempt to predict how well their designs will perform to their specifications prior to full-scale production. They use, among other things: prototypes, scale models, simulations, destructive tests, nondestructive tests, and stress tests. Testing ensures that products will perform as expected.Engineers take on the responsibility of producing designs that will perform as well as expected and will not cause unintended harm to the public at large. Engineers typically include a factor of safety in their designs to reduce the risk of unexpected failure. However, the greater the safety factor, the less efficient the design may be.[citation needed]The study of failed products is known as forensic engineering and can help the product designer in evaluating his or her design in the light of real conditions. The discipline is of greatest value after disasters, such as bridge collapses, when careful analysis is needed to establish the cause or causes of the failure.As with all modern scientific and technological endeavors, computers and software play an increasingly important role. As well as the typical business application software there are a number of computer aided applications  specifically for engineering. Computers can be used to generate models of fundamental physical processes, which can be solved using numerical methods.One of the most widely used design tools in the profession is computer-aided design  and CAE software such as finite element method analysis or analytic element method allows engineers to create models of designs that can be analyzed without having to make expensive and time-consuming physical prototypes.These allow products and components to be checked for flaws; assess fit and assembly; study ergonomics; and to analyze static and dynamic characteristics of systems such as stresses, temperatures, electromagnetic emissions, electrical currents and voltages, digital logic levels, fluid flows, and kinematics. Access and distribution of all this information is generally organized with the use of product data management software.[30]There are also many tools to support specific engineering tasks such as computer-aided manufacturing  and circuit schematics for electronic engineers; MRO applications for maintenance management; and AEC software for civil engineering.In recent years the use of computer software to aid the development of goods has collectively come to be known as product lifecycle management .[31]The engineering profession engages in a wide range of activities, from large collaboration at the societal level, and also smaller individual projects. Almost all engineering projects are obligated to some sort of financing agency: a company, a set of investors, or a government. The few types of engineering that are minimally constrained by such issues are pro bono engineering and open-design engineering.By its very nature engineering has interconnections with society, culture and human behavior. Every product or construction used by modern society is influenced by engineering. The results of engineering activity influence changes to the environment, society and economies, and its application brings with it a responsibility and public safety.Engineering projects can be subject to controversy. Examples from different engineering disciplines include the development of nuclear weapons, the Three Gorges Dam, the design and use of sport utility vehicles and the extraction of oil. In response, some western engineering companies have enacted serious corporate and social responsibility policies.Engineering is a key driver of innovation and human development. Sub-Saharan Africa, in particular, has a very small engineering capacity which results in many African nations being unable to develop crucial infrastructure without outside aid.[citation needed] The attainment of many of the Millennium Development Goals requires the achievement of sufficient engineering capacity to develop infrastructure and sustainable technological development.[32]All overseas development and relief NGOs make considerable use of engineers to apply solutions in disaster and development scenarios. A number of charitable organizations aim to use engineering directly for the good of mankind:Engineering companies in many established economies are facing significant challenges with regard to the number of professional engineers being trained, compared with the number retiring. This problem is very prominent in the UK where engineering has a poor image and low status.[34] There are many negative economic and political issues that this can cause, as well as ethical issues.[35] It is widely agreed that the engineering profession faces an \"image crisis\",[36] rather than it being fundamentally an unattractive career. Much work is needed to avoid huge problems in the UK and other western economies.Many engineering societies have established codes of practice and codes of ethics to guide members and inform the public at large. The National Society of Professional Engineers code of ethics states:In Canada, many engineers wear the Iron Ring as a symbol and reminder of the obligations and ethics associated with their profession.[38]There exists an overlap between the sciences and engineering practice; in engineering, one applies science. Both areas of endeavor rely on accurate observation of materials and phenomena. Both use mathematics and classification criteria to analyze and communicate observations.[citation needed]Scientists may also have to complete engineering tasks, such as designing experimental apparatus or building prototypes. Conversely, in the process of developing technology engineers sometimes find themselves exploring new phenomena, thus becoming, for the moment, scientists or more precisely \"engineering scientists\".[citation needed]In the book What Engineers Know and How They Know It,[42] Walter Vincenti asserts that engineering research has a character different from that of scientific research. First, it often deals with areas in which the basic physics or chemistry are well understood, but the problems themselves are too complex to solve in an exact manner.There is a \"real and important\" difference between engineering and physics as similar to any science field has to do with technology.[43][44] Physics is an exploratory science that seeks knowledge of principles while engineering uses knowledge for practical applications of principles. The former equates an understanding into a mathematical principle while the latter measures variables involved and creates technology.[45][46][47] For technology, physics is an auxiliary and in a way technology is considered as applied physics.[48] Though physics and engineering are interrelated, it does not mean that a physicist is trained to do an engineer's job. A physicist would typically require additional and relevant training.[49] Physicists and engineers engage in different lines of work.[50] But PhD physicists who specialize in sectors of technology and applied science are titled as Technology officer, R&D Engineers and System Engineers.[51]An example of this is the use of numerical approximations to the Navier\u2013Stokes equations to describe aerodynamic flow over an aircraft, or the use of Miner's rule to calculate fatigue damage. Second, engineering research employs many semi-empirical methods that are foreign to pure scientific research, one example being the method of parameter variation.[citation needed]As stated by Fung et al. in the revision to the classic engineering text Foundations of Solid Mechanics:Although engineering solutions make use of scientific principles, engineers must also take into account safety, efficiency, economy, reliability, and constructability or ease of fabrication as well as the environment, ethical and legal considerations such as patent infringement or liability in the case of failure of the solution.[citation needed]The study of the human body, albeit from different directions and for different purposes, is an important common link between medicine and some engineering disciplines. Medicine aims to sustain, repair, enhance and even replace functions of the human body, if necessary, through the use of technology.Modern medicine can replace several of the body's functions through the use of artificial organs and can significantly alter the function of the human body through artificial devices such as, for example, brain implants and pacemakers.[54][55] The fields of bionics and medical bionics are dedicated to the study of synthetic implants pertaining to natural systems.Conversely, some engineering disciplines view the human body as a biological machine worth studying and are dedicated to emulating many of its functions by replacing biology with technology. This has led to fields such as artificial intelligence, neural networks, fuzzy logic, and robotics. There are also substantial interdisciplinary interactions between engineering and medicine.[56][57]Both fields provide solutions to real world problems. This often requires moving forward before phenomena are completely understood in a more rigorous scientific sense and therefore experimentation and empirical knowledge is an integral part of both.Medicine, in part, studies the function of the human body. The human body, as a biological machine, has many functions that can be modeled using engineering methods.[58]The heart for example functions much like a pump,[59] the skeleton is like a linked structure with levers,[60] the brain produces electrical signals etc.[61] These similarities as well as the increasing importance and application of engineering principles in medicine, led to the development of the field of biomedical engineering that uses concepts developed in both disciplines.Newly emerging branches of science, such as systems biology, are adapting analytical tools traditionally used for engineering, such as systems modeling and computational analysis, to the description of biological systems.[58]There are connections between engineering and art, for example, architecture, landscape architecture and industrial design .[62][63][64]The Art Institute of Chicago, for instance, held an exhibition about the art of NASA's aerospace design.[65] Robert Maillart's bridge design is perceived by some to have been deliberately artistic.[66] At the University of South Florida, an engineering professor, through a grant with the National Science Foundation, has developed a course that connects art and engineering.[62][67]Among famous historical figures, Leonardo da Vinci is a well-known Renaissance artist and engineer, and a prime example of the nexus between art and engineering.[53][68]Business Engineering deals with the relationship between professional engineering, IT systems, business administration and change management. Engineering management or \"Management engineering\" is a specialized field of management concerned with engineering practice or the engineering industry sector. The demand for management-focused engineers , has resulted in the development of specialized engineering management degrees that develop the knowledge and skills needed for these roles. During an engineering management course, students will develop industrial engineering skills, knowledge, and expertise, alongside knowledge of business administration, management techniques, and strategic thinking. Engineers specializing in change management must have in-depth knowledge of the application of industrial and organizational psychology principles and methods. Professional engineers often train as certified management consultants in the very specialized field of management consulting applied to engineering practice or the engineering sector. This work often deals with large scale complex business transformation or Business process management initiatives in aerospace and defence, automotive, oil and gas, machinery, pharmaceutical, food and beverage, electrical & electronics, power distribution & generation, utilities and transportation systems. This combination of technical engineering practice, management consulting practice, industry sector knowledge, and change management expertise enables professional engineers who are also qualified as management consultants to lead major business transformation initiatives. These initiatives are typically sponsored by C-level executives.In political science, the term engineering has been borrowed for the study of the subjects of social engineering and political engineering, which deal with forming political and social structures using engineering methodology coupled with political science principles. Financial engineering has similarly borrowed the term."], "Medicine and health": ["Medicine is the science and practice of the diagnosis, treatment, and prevention of disease. Medicine encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. Contemporary medicine applies biomedical sciences, biomedical research, genetics, and medical technology to diagnose, treat, and prevent injury and disease, typically through pharmaceuticals or surgery, but also through therapies as diverse as psychotherapy, external splints and traction, medical devices, biologics, and ionizing radiation, amongst others.[1]Medicine has existed for thousands of years, during most of which it was an art . While stitching technique for sutures is an art learned through practice, the knowledge of what happens at the cellular and molecular level in the tissues being stitched arises through science.Prescientific forms of medicine are now known as traditional medicine and folk medicine. They remain commonly used with or instead of scientific medicine and are thus called alternative medicine. For example, evidence on the effectiveness of acupuncture is \"variable and inconsistent\" for any condition,[2] but is generally safe when done by an appropriately trained practitioner.[3] In contrast, treatments outside the bounds of safety and efficacy are termed quackery.Medicine  is the science and practice of the diagnosis, treatment, and prevention of disease.[4][5] The word \"medicine\" is derived from Latin medicus, meaning \"a physician\".[6][7]Medical availability and clinical practice varies across the world due to regional differences in culture and technology. Modern scientific medicine is highly developed in the Western world, while in developing countries such as parts of Africa or Asia, the population may rely more heavily on traditional medicine with limited evidence and efficacy and no required formal training for practitioners.[8] Even in the developed world however, evidence-based medicine is not universally used in clinical practice; for example, a 2007 survey of literature reviews found that about 49% of the interventions lacked sufficient evidence to support either benefit or harm.[9]In modern clinical practice, physicians personally assess patients in order to diagnose, treat, and prevent disease using clinical judgment. The doctor-patient relationship typically begins an interaction with an examination of the patient's medical history and medical record, followed by a medical interview[10] and a physical examination. Basic diagnostic medical devices , take a biopsy, or prescribe pharmaceutical drugs or other therapies. Differential diagnosis methods help to rule out conditions based on the information provided. During the encounter, properly informing the patient of all relevant facts is an important part of the relationship and the development of trust. The medical encounter is then documented in the medical record, which is a legal document in many jurisdictions.[11] Follow-ups may be shorter but follow the same general procedure, and specialists follow a similar process. The diagnosis and treatment may take only a few minutes or a few weeks depending upon the complexity of the issue.The components of the medical interview[10] and encounter are:The physical examination is the examination of the patient for medical signs of disease, which are objective and observable, in contrast to symptoms which are volunteered by the patient and not necessarily objectively observable.[12] The healthcare provider uses the senses of sight, hearing, touch, and sometimes smell , generally in that order although auscultation occurs prior to percussion and palpation for abdominal assessments.[13]The clinical examination involves the study of:It is to likely focus on areas of interest highlighted in the medical history and may not include everything listed above.The treatment plan may include ordering additional medical laboratory tests and medical imaging studies, starting therapy, referral to a specialist, or watchful observation. Follow-up may be advised. Depending upon the health insurance plan and the managed care system, various forms of \"utilization review\", such as prior authorization of tests, may place barriers on accessing expensive services.[14]The medical decision-making , along with an idea of what needs to be done to obtain a definitive diagnosis that would explain the patient's problem.On subsequent visits, the process may be repeated in an abbreviated manner to obtain any new history, symptoms, physical findings, and lab or imaging results or specialist consultations.Contemporary medicine is in general conducted within health care systems. Legal, credentialing and financing frameworks are established by individual governments, augmented on occasion by international organizations, such as churches. The characteristics of any given health care system have significant impact on the way medical care is provided.From ancient times, Christian emphasis on practical charity gave rise to the development of systematic nursing and hospitals and the Catholic Church today remains the largest non-government provider of medical services in the world.[15] Advanced industrial countries [16][17] and many developing countries provide medical services through a system of universal health care that aims to guarantee care for all through a single-payer health care system, or compulsory private or co-operative health insurance. This is intended to ensure that the entire population has access to medical care on the basis of need rather than ability to pay. Delivery may be via private medical practices or by state-owned hospitals and clinics, or by charities, most commonly by a combination of all three.Most tribal societies provide no guarantee of healthcare for the population as a whole. In such societies, healthcare is available to those that can afford to pay for it or have self-insured it  or who may be covered by care financed by the government or tribe directly.Transparency of information is another factor defining a delivery system. Access to information on conditions, treatments, quality, and pricing greatly affects the choice by patients/consumers and, therefore, the incentives of medical professionals. While the US healthcare system has come under fire for lack of openness,[18] new legislation may encourage greater openness. There is a perceived tension between the need for transparency on the one hand and such issues as patient confidentiality and the possible exploitation of information for commercial gain on the other.Provision of medical care is classified into primary, secondary, and tertiary care categories.Primary care medical services are provided by physicians, physician assistants, nurse practitioners, or other health professionals who have first contact with a patient seeking medical treatment or care. These occur in physician offices, clinics, nursing homes, schools, home visits, and other places close to patients. About 90% of medical visits can be treated by the primary care provider. These include treatment of acute and chronic illnesses, preventive care and health education for all ages and both sexes.Secondary care medical services are provided by medical specialists in their offices or clinics or at local community hospitals for a patient referred by a primary care provider who first diagnosed or treated the patient. Referrals are made for those patients who required the expertise or procedures performed by specialists. These include both ambulatory care and inpatient services, Emergency departments, intensive care medicine, surgery services, physical therapy, labor and delivery, endoscopy units, diagnostic laboratory and medical imaging services, hospice centers, etc. Some primary care providers may also take care of hospitalized patients and deliver babies in a secondary care setting.Tertiary care medical services are provided by specialist hospitals or regional centers equipped with diagnostic and treatment facilities not generally available at local hospitals. These include trauma centers, burn treatment centers, advanced neonatology unit services, organ transplants, high-risk pregnancy, radiation oncology, etc.Modern medical care also depends on information \u2013 still delivered in many health care settings on paper records, but increasingly nowadays by electronic means.In low-income countries, modern healthcare is often too expensive for the average person. International healthcare policy researchers have advocated that \"user fees\" be removed in these areas to ensure access, although even after removal, significant costs and barriers remain.[19]Separation of prescribing and dispensing is a practice in medicine and pharmacy in which the physician who provides a medical prescription is independent from the pharmacist who provides the prescription drug. In the Western world there are centuries of tradition for separating pharmacists from physicians. In Asian countries it is traditional for physicians to also provide drugs.[20]Working together as an interdisciplinary team, many highly trained health professionals besides medical practitioners are involved in the delivery of modern health care. Examples include: nurses, emergency medical technicians and paramedics, laboratory scientists, pharmacists, podiatrists, physiotherapists, respiratory therapists, speech therapists, occupational therapists, radiographers, dietitians, and bioengineers, surgeons, surgeon's assistant, surgical technologist.The scope and sciences underpinning human medicine overlap many other fields. Dentistry, while considered by some a separate discipline from medicine, is a medical field.A patient admitted to the hospital is usually under the care of a specific team based on their main presenting problem, e.g., the cardiology team, who then may interact with other specialties, e.g., surgical, radiology, to help diagnose or treat the main problem or any subsequent complications/developments.Physicians have many specializations and subspecializations into certain branches of medicine, which are listed below. There are variations from country to country regarding which specialties certain subspecialties are in.The main branches of medicine are:In the broadest meaning of \"medicine\", there are many different specialties. In the UK, most specialities have their own body or college, which have its own entrance examination. These are collectively known as the Royal Colleges, although not all currently use the term \"Royal\". The development of a speciality is often driven by new technology ; the new specialty leads to the formation of a unifying body of doctors and the prestige of administering their own examination.Within medical circles, specialities usually fit into one of two broad categories: \"Medicine\" and \"Surgery.\" \"Medicine\" refers to the practice of non-operative medicine, and most of its subspecialties require preliminary training in Internal Medicine. In the UK, this was traditionally evidenced by passing the examination for the Membership of the Royal College of Physicians .Surgery is an ancient medical specialty that uses operative manual and instrumental techniques on a patient to investigate or treat a pathological condition such as disease or injury, to help improve bodily function or appearance or to repair unwanted ruptured areas , although it is not a surgical discipline. Other medical specialties may employ surgical procedures, such as ophthalmology and dermatology, but are not considered surgical sub-specialties per se.Surgical training in the U.S. requires a minimum of five years of residency after medical school. Sub-specialties of surgery often require seven or more years. In addition, fellowships can last an additional one to three years. Because post-residency fellowships can be competitive, many trainees devote two additional years to research. Thus in some cases surgical training will not finish until more than a decade after medical school. Furthermore, surgical training can be very difficult and time-consuming.Internal medicine is the medical specialty dealing with the prevention, diagnosis, and treatment of adult diseases. According to some sources, an emphasis on internal structures is implied.[21] In North America, specialists in internal medicine are commonly called \"internists.\" Elsewhere, especially in Commonwealth nations, such specialists are often called physicians.[22] These terms, internist or physician , generally exclude practitioners of gynecology and obstetrics, pathology, psychiatry, and especially surgery and its subspecialities.Because their patients are often seriously ill or require complex investigations, internists do much of their work in hospitals. Formerly, many internists were not subspecialized; such general physicians would see any complex nonsurgical problem; this style of practice has become much less common. In modern urban practice, most internists are subspecialists: that is, they generally limit their medical practice to problems of one organ system or to one particular area of medical knowledge. For example, gastroenterologists and nephrologists specialize respectively in diseases of the gut and the kidneys.[23]In the Commonwealth of Nations and some other countries, specialist pediatricians and geriatricians are also described as specialist physicians  who have subspecialized by age of patient rather than by organ system. Elsewhere, especially in North America, general pediatrics is often a form of primary care.There are many subspecialities  of internal medicine:Training in internal medicine , varies considerably across the world: see the articles on medical education and physician for more details. In North America, it requires at least three years of residency training after medical school, which can then be followed by a one- to three-year fellowship in the subspecialties listed above. In general, resident work hours in medicine are less than those in surgery, averaging about 60 hours per week in the US. This difference does not apply in the UK where all doctors are now required by law to work less than 48 hours per week on average.The followings are some major medical specialties that do not directly fit into any of the above-mentioned groups:Some interdisciplinary sub-specialties of medicine include:Medical education and training varies around the world. It typically involves entry level education at a university medical school, followed by a period of supervised practice or internship, or residency. This can be followed by postgraduate vocational training. A variety of teaching methods have been employed in medical education, still itself a focus of active research. In Canada and the United States of America, a Doctor of Medicine degree, often abbreviated M.D., or a Doctor of Osteopathic Medicine degree, often abbreviated as D.O. and unique to the United States, must be completed in and delivered from a recognized university.Since knowledge, techniques, and medical technology continue to evolve at a rapid rate, many regulatory authorities require continuing medical education. Medical practitioners upgrade their knowledge in various ways, including medical journals, seminars, conferences, and online programs.In most countries, it is a legal requirement for a medical doctor to be licensed or registered. In general, this entails a medical degree from a university and accreditation by a medical board or an equivalent national organization, which may ask the applicant to pass exams. This restricts the considerable legal authority of the medical profession to physicians that are trained and qualified by national standards. It is also intended as an assurance to patients and as a safeguard against charlatans that practice inadequate medicine for personal gain. While the laws generally require medical doctors to be trained in \"evidence based\", Western, or Hippocratic Medicine, they are not intended to discourage different paradigms of health.In the European Union, the profession of doctor of medicine is regulated. A profession is said to be regulated when access and exercise is subject to the possession of a specific professional qualification. The regulated professions database contains a list of regulated professions for doctor of medicine in the EU member states, EEA countries and Switzerland. This list is covered by the Directive 2005/36/EC.Doctors who are negligent or intentionally harmful in their care of patients can face charges of medical malpractice and be subject to civil, criminal, or professional sanctions.Medical ethics is a system of moral principles that apply values and judgments to the practice of medicine. As a scholarly discipline, medical ethics encompasses its practical application in clinical settings as well as work on its history, philosophy, theology, and sociology. Six of the values that commonly apply to medical ethics discussions are:Values such as these do not give answers as to how to handle a particular situation, but provide a useful framework for understanding conflicts. When moral values are in conflict, the result may be an ethical dilemma or crisis. Sometimes, no good solution to a dilemma in medical ethics exists, and occasionally, the values of the medical community  conflict with the values of the individual patient, family, or larger non-medical community. Conflicts can also arise between health care providers, or among family members. For example, some argue that the principles of autonomy and beneficence clash when patients refuse blood transfusions, considering them life-saving; and truth-telling was not emphasized to a large extent before the HIV era.Prehistoric medicine incorporated plants . The field of medical anthropology examines the ways in which culture and society are organized around or impacted by issues of health, health care and related issues.Early records on medicine have been discovered from ancient Egyptian medicine, Babylonian Medicine, Ayurvedic medicine , and ancient Greek medicine and Roman medicine.In Egypt, Imhotep  is the first physician in history known by name. The oldest Egyptian medical text is the Kahun Gynaecological Papyrus from around 2000 BCE, which describes gynaecological diseases. The Edwin Smith Papyrus dating back to 1600 BCE is an early work on surgery, while the Ebers Papyrus dating back to 1500 BCE is akin to a textbook on medicine.[25]In China, archaeological evidence of medicine in Chinese dates back to the Bronze Age Shang Dynasty, based on seeds for herbalism and tools presumed to have been used for surgery.[26] The Huangdi Neijing, the progenitor of Chinese medicine, is a medical text written beginning in the 2nd century BCE and compiled in the 3rd century.[27]In India, the surgeon Sushruta described numerous surgical operations, including the earliest forms of plastic surgery.[28][dubious \u2013 discuss][29] Earliest records of dedicated hospitals come from Mihintale in Sri Lanka where evidence of dedicated medicinal treatment facilities for patients are found.[30][31]In Greece, the Greek physician Hippocrates, the \"father of modern medicine\",[32][33] laid the foundation for a rational approach to medicine. Hippocrates introduced the Hippocratic Oath for physicians, which is still relevant and in use today, and was the first to categorize illnesses as acute, chronic, endemic and epidemic, and use terms such as, \"exacerbation, relapse, resolution, crisis, paroxysm, peak, and convalescence\".[34][35] The Greek physician Galen was also one of the greatest surgeons of the ancient world and performed many audacious operations, including brain and eye surgeries. After the fall of the Western Roman Empire and the onset of the Early Middle Ages, the Greek tradition of medicine went into decline in Western Europe, although it continued uninterrupted in the Eastern Roman  Empire.Most of our knowledge of ancient Hebrew medicine during the 1st\u00a0millennium\u00a0BC comes from the Torah, i.e.\u00a0the Five Books of Moses, which contain various health related laws and rituals. The Hebrew contribution to the development of modern medicine started in the Byzantine Era, with the physician Asaph the Jew.[36]The concept of hospital as institution to offer medical care and possibility of a cure for the patients due to the ideals of Christian charity, rather than just merely a place to die, appeared in the Byzantine Empire.[37]Although the concept of uroscopy was known to Galen, he did not see the importance of using it to localize the disease. It was under the Byzantines with physicians such of Theophilus Protospatharius that they realized the potential in uroscopy to determine disease in a time when no microscope or stethoscope existed. That practice eventually spread to the rest of Europe.[38]After 750 CE, the Muslim world had the works of Hippocrates, Galen and Sushruta translated into Arabic, and Islamic physicians engaged in some significant medical research. Notable Islamic medical pioneers include the Persian polymath, Avicenna, who, along with Imhotep and Hippocrates, has also been called the \"father of medicine\".[39] He wrote The Canon of Medicine, considered one of the most famous books in the history of medicine.[40] Others include Abulcasis,[41] Avenzoar,[42] Ibn al-Nafis,[43] and Averroes.[44] Rhazes[45] was one of the first to question the Greek theory of humorism, which nevertheless remained influential in both medieval Western and medieval Islamic medicine.[46] Al-Risalah al-Dhahabiah by Ali al-Ridha, the eighth Imam of Shia Muslims, is revered as the most precious Islamic literature in the Science of Medicine.[47] The Persian Bimaristan hospitals were an early example of public hospitals.[48][49]In Europe, Charlemagne decreed that a hospital should be attached to each cathedral and monastery and the historian Geoffrey Blainey likened the activities of the Catholic Church in health care during the Middle Ages to an early version of a welfare state: \"It conducted hospitals for the old and orphanages for the young; hospices for the sick of all ages; places for the lepers; and hostels or inns where pilgrims could buy a cheap bed and meal\". It supplied food to the population during famine and distributed food to the poor. This welfare system the church funded through collecting taxes on a large scale and possessing large farmlands and estates. The Benedictine order was noted for setting up hospitals and infirmaries in their monasteries, growing medical herbs and becoming the chief medical care givers of their districts, as at the great Abbey of Cluny. The Church also established a network of cathedral schools and universities where medicine was studied. The Schola Medica Salernitana in Salerno, looking to the learning of Greek and Arab physicians, grew to be the finest medical school in Medieval Europe.[50]However, the fourteenth and fifteenth century Black Death devastated both the Middle East and Europe, and it has even been argued that Western Europe was generally more effective in recovering from the pandemic than the Middle East.[51] In the early modern period, important early figures in medicine and anatomy emerged in Europe, including Gabriele Falloppio and William Harvey.The major shift in medical thinking was the gradual rejection, especially during the Black Death in the 14th and 15th centuries, of what may be called the 'traditional authority' approach to science and medicine. This was the notion that because some prominent person in the past said something must be so, then that was the way it was, and anything one observed to the contrary was an anomaly . Physicians like Vesalius improved upon or disproved some of the theories from the past. The main tomes used both by medicine students and expert physicians were Materia Medica and Pharmacopoeia.Andreas Vesalius was the author of De humani corporis fabrica, an important book on human anatomy.[52] Bacteria and microorganisms were first observed with a microscope by Antonie van Leeuwenhoek in 1676, initiating the scientific field microbiology.[53] Independently from Ibn al-Nafis, Michael Servetus rediscovered the pulmonary circulation, but this discovery did not reach the public because it was written down for the first time in the \"Manuscript of Paris\"[54] in 1546, and later published in the theological work for which he paid with his life in 1553. Later this was described by Renaldus Columbus and Andrea Cesalpino. Herman Boerhaave is sometimes referred to as a \"father of physiology\" due to his exemplary teaching in Leiden and textbook 'Institutiones medicae' . Pierre Fauchard has been called \"the father of modern dentistry\".[55]Veterinary medicine was, for the first time, truly separated from human medicine in 1761, when the French veterinarian Claude Bourgelat founded the world's first veterinary school in Lyon, France. Before this, medical doctors treated both humans and other animals.Modern scientific biomedical research , Robert Koch's discoveries around 1880 of the transmission of disease by bacteria, and then the discovery of antibiotics around 1900.The post-18th century modernity period brought more groundbreaking researchers from Europe. From Germany and Austria, doctors Rudolf Virchow, Wilhelm Conrad R\u00f6ntgen, Karl Landsteiner and Otto Loewi made notable contributions. In the United Kingdom, Alexander Fleming, Joseph Lister, Francis Crick and Florence Nightingale are considered important. Spanish doctor Santiago Ram\u00f3n y Cajal is considered the father of modern neuroscience.From New Zealand and Australia came Maurice Wilkins, Howard Florey, and Frank Macfarlane Burnet.In the United States, William Williams Keen, William Coley, James D. Watson, Italy  and others did significant work. Russian Nikolai Korotkov also did significant work, as did Sir William Osler and Harvey Cushing.As science and technology developed, medicine became more reliant upon medications. Throughout history and in Europe right until the late 18th century, not only animal and plant products were used as medicine, but also human body parts and fluids.[56] Pharmacology developed in part from herbalism and some drugs are still derived from plants .[58] Vaccines were discovered by Edward Jenner and Louis Pasteur.The first antibiotic was arsphenamine  discovered by Paul Ehrlich in 1908 after he observed that bacteria took up toxic dyes that human cells did not. The first major class of antibiotics was the sulfa drugs, derived by German chemists originally from azo dyes.Pharmacology has become increasingly sophisticated; modern biotechnology allows drugs targeted towards specific physiological processes to be developed, sometimes designed for compatibility with the body to reduce side-effects. Genomics and knowledge of human genetics and human evolution is having increasingly significant influence on medicine, as the causative genes of most monogenic genetic disorders have now been identified, and the development of techniques in molecular biology, evolution, and genetics are influencing medical technology, practice and decision-making.Evidence-based medicine is a contemporary movement to establish the most effective algorithms of practice  through the use of systematic reviews and meta-analysis. The movement is facilitated by modern global information science, which allows as much of the available evidence as possible to be collected and analyzed according to standard protocols that are then disseminated to healthcare providers. The Cochrane Collaboration leads this movement. A 2001 review of 160 Cochrane systematic reviews revealed that, according to two readers, 21.3% of the reviews concluded insufficient evidence, 20% concluded evidence of no effect, and 22.5% concluded positive effect.[59]Traditional medicine  defines traditional medicine as \"the sum total of the knowledge, skills, and practices based on the theories, beliefs, and experiences indigenous to different cultures, whether explicable or not, used in the maintenance of health as well as in the prevention, diagnosis, improvement or treatment of physical and mental illness.\"[60]In some Asian and African countries, up to 80% of the population relies on traditional medicine for their primary health care needs. When adopted outside of its traditional culture, traditional medicine is often called alternative medicine.[60] Practices known as traditional medicines include Ayurveda, Siddha medicine, Unani, ancient Iranian medicine, Irani, Islamic medicine, traditional Chinese medicine, traditional Korean medicine, acupuncture, Muti, If\u00e1, and traditional African medicine.The WHO notes however that \"inappropriate use of traditional medicines or practices can have negative or dangerous effects\" and that \"further research is needed to ascertain the efficacy and safety\" of several of the practices and medicinal plants used by traditional medicine systems.[60] The line between alternative medicine and quackery is a contentious subject.Traditional medicine may include formalized aspects of folk medicine, that is to say longstanding remedies passed on and practised by lay people. Folk medicine consists of the healing practices and ideas of body physiology and health preservation known to some in a culture, transmitted informally as general knowledge, and practiced or applied by anyone in the culture having prior experience.[61] Folk medicine may also be referred to as traditional medicine, alternative medicine, indigenous medicine, or natural medicine. These terms are often considered interchangeable, even though some authors may prefer one or the other because of certain overtones they may be willing to highlight. In fact, out of these terms perhaps only indigenous medicine and traditional medicine have the same meaning as folk medicine, while the others should be understood rather in a modern or modernized context.[62]", "The following outline is provided as an overview of and topical guide to health sciences:Health sciences \u2013 are applied sciences that address the use of science, technology, engineering or mathematics in the delivery of healthcare to human beings.[1][2]"]}