{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import re, time\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_html(url):\n",
    "    \"\"\"\n",
    "    Return the raw HTML at the specified URL.\n",
    "\n",
    "    Args:\n",
    "        url (string): \n",
    "\n",
    "    Returns:\n",
    "        status_code (integer):\n",
    "        raw_html (string): the raw HTML content of the response, properly encoded according to the HTTP headers.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    return (response.status_code, response.text)\n",
    "    pass\n",
    "def get_people_list_data(url, key_words):\n",
    "    code, text = retrieve_html(url)\n",
    "    soup = BeautifulSoup(text,'html.parser')\n",
    "    next_page = set()\n",
    "    for link in soup.find('div',{'id':'bodyContent'}).find_all('a', href=True):\n",
    "        tar_url=link.attrs['href']\n",
    "        if tar_url.startswith('/wiki/') and tar_url.find(':') == -1:\n",
    "            next_page.add(tar_url)\n",
    "    data = dict()\n",
    "    for url in tqdm(next_page):\n",
    "        time.sleep(0.1)\n",
    "        code, html = retrieve_html(\"https://en.wikipedia.org\"+url)\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        if html.find('<th scope=\"row\">Born</th>') != -1 and any(key_word in html for key_word in key_words):\n",
    "            div = soup.find('div', {\"class\": \"mw-parser-output\"})\n",
    "            text = \"\"\n",
    "            for p in div.find_all(\"p\", recursive=False):\n",
    "                tmp = re.sub(\"(\\[[0-9]+\\])\", \"\", p.text)\n",
    "                tmp = re.sub(\"(\\(.*\\))\", \"\", tmp).rstrip().strip()\n",
    "                text += tmp\n",
    "            data[url[6:]] = text\n",
    "    return data\n",
    "def get_all_data(universities):\n",
    "    data = dict()\n",
    "    for key, value in universities.items():\n",
    "        print(key)\n",
    "        data[key] = get_people_list_data(value[0], value[1])\n",
    "    with open('data.json', 'w') as fp:\n",
    "        json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:09<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCLA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [08:30<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2123/2123 [10:48<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harvard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2828/2828 [15:19<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berklee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:41<00:00,  3.65it/s]\n"
     ]
    }
   ],
   "source": [
    "universities = dict()\n",
    "universities['CMU'] = (\"https://en.wikipedia.org/wiki/List_of_Carnegie_Mellon_University_people\", \\\n",
    "                       ['Carnegie_Mellon_University', 'CMU'])\n",
    "universities['UCLA'] = (\"https://en.wikipedia.org/wiki/List_of_University_of_California,_Los_Angeles_people\", \\\n",
    "                       ['University_of_California,_Los_Angeles', 'University of California at Los Angeles', 'UCLA'])\n",
    "universities['Stanford'] = (\"https://en.wikipedia.org/wiki/List_of_Stanford_University_people\", \\\n",
    "                       ['Stanford_University'])\n",
    "universities['Harvard'] = (\"https://en.wikipedia.org/wiki/List_of_Harvard_University_people\", \\\n",
    "                           ['Harvard_University'])\n",
    "universities['Berklee'] = (\"https://en.wikipedia.org/wiki/List_of_Berklee_College_of_Music_alumni\", \\\n",
    "                           ['Berklee_College_of_Music', 'Berklee'])\n",
    "get_all_data(universities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
